{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790345a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28223423",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2483290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# From 1 January, 2017 to 31 December, 2022\n",
    "df = yf.download(\"AAPL\", start=\"2017-01-01\", end=\"2022-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779daf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>28.950001</td>\n",
       "      <td>29.082500</td>\n",
       "      <td>28.690001</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>27.023701</td>\n",
       "      <td>115127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>28.962500</td>\n",
       "      <td>29.127501</td>\n",
       "      <td>28.937500</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>26.993452</td>\n",
       "      <td>84472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>28.980000</td>\n",
       "      <td>29.215000</td>\n",
       "      <td>28.952499</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>27.130732</td>\n",
       "      <td>88774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>29.195000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.117500</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>27.433187</td>\n",
       "      <td>127007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>29.487499</td>\n",
       "      <td>29.857500</td>\n",
       "      <td>29.485001</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>27.684460</td>\n",
       "      <td>134247600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2017-01-03  28.950001  29.082500  28.690001  29.037500  27.023701  115127600\n",
       "2017-01-04  28.962500  29.127501  28.937500  29.004999  26.993452   84472400\n",
       "2017-01-05  28.980000  29.215000  28.952499  29.152500  27.130732   88774400\n",
       "2017-01-06  29.195000  29.540001  29.117500  29.477501  27.433187  127007600\n",
       "2017-01-09  29.487499  29.857500  29.485001  29.747499  27.684460  134247600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822c01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features and target variables\n",
    "X = df.drop(['Close'], axis = 1)\n",
    "y = df[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566d5ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>28.950001</td>\n",
       "      <td>29.082500</td>\n",
       "      <td>28.690001</td>\n",
       "      <td>27.023701</td>\n",
       "      <td>115127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>28.962500</td>\n",
       "      <td>29.127501</td>\n",
       "      <td>28.937500</td>\n",
       "      <td>26.993452</td>\n",
       "      <td>84472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>28.980000</td>\n",
       "      <td>29.215000</td>\n",
       "      <td>28.952499</td>\n",
       "      <td>27.130732</td>\n",
       "      <td>88774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>29.195000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.117500</td>\n",
       "      <td>27.433187</td>\n",
       "      <td>127007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>29.487499</td>\n",
       "      <td>29.857500</td>\n",
       "      <td>29.485001</td>\n",
       "      <td>27.684460</td>\n",
       "      <td>134247600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low  Adj Close     Volume\n",
       "Date                                                             \n",
       "2017-01-03  28.950001  29.082500  28.690001  27.023701  115127600\n",
       "2017-01-04  28.962500  29.127501  28.937500  26.993452   84472400\n",
       "2017-01-05  28.980000  29.215000  28.952499  27.130732   88774400\n",
       "2017-01-06  29.195000  29.540001  29.117500  27.433187  127007600\n",
       "2017-01-09  29.487499  29.857500  29.485001  27.684460  134247600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a231106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>29.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>29.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>29.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>29.477501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>29.747499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Close\n",
       "Date                 \n",
       "2017-01-03  29.037500\n",
       "2017-01-04  29.004999\n",
       "2017-01-05  29.152500\n",
       "2017-01-06  29.477501\n",
       "2017-01-09  29.747499"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f430e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b6c91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Dataframe: (1510, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the Dataframe: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b402ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Null Values')\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dff8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns in a grid\n",
    "df_features = df.columns\n",
    "num_of_cols = 3\n",
    "num_of_rows = np.ceil(len(df_features) / num_of_cols)\n",
    "num_of_rows = int(num_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e56727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating distributions for all the continuous variables\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, feature in enumerate(df_features, 1):\n",
    "    plt.subplot(num_of_rows, num_of_cols, i)\n",
    "    sns.kdeplot(data=df, x=feature)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073ae139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Open      High       Low     Close  Adj Close    Volume\n",
      "Open       1.000000  0.999782  0.999723  0.999412   0.999390 -0.248745\n",
      "High       0.999782  1.000000  0.999685  0.999724   0.999715 -0.242900\n",
      "Low        0.999723  0.999685  1.000000  0.999734   0.999697 -0.256443\n",
      "Close      0.999412  0.999724  0.999734  1.000000   0.999972 -0.250022\n",
      "Adj Close  0.999390  0.999715  0.999697  0.999972   1.000000 -0.250061\n",
      "Volume    -0.248745 -0.242900 -0.256443 -0.250022  -0.250061  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb1cbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_features = X.columns\n",
    "min_max_scaler_instance = MinMaxScaler(feature_range = (0, 1))\n",
    "X = pd.DataFrame(min_max_scaler_instance.fit_transform(X), columns = X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "412ab855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split\n",
    "train_set_scaled, test_set_scaled, y_train_set, y_test_set = train_test_split(X, y, test_size = 0.2,\n",
    "                                                                              random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1d02956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    \"\"\"\n",
    "    This function will prepare the data, using the time steps, for training and testing.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f2d8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "time_steps = 30\n",
    "test_extended = pd.concat([train_set_scaled.tail(time_steps), test_set_scaled], axis = 0)\n",
    "y_test_extended = pd.concat([y_train_set.tail(time_steps), y_test_set], axis = 0)\n",
    "\n",
    "X_train, y_train = create_dataset(train_set_scaled, y_train_set, time_steps)\n",
    "X_test, y_test = create_dataset(test_extended, y_test_extended, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34755164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the actual vs predicted values for a model\n",
    "def plot_result(y_test, y_preds, time_steps, model_name = None):\n",
    "    # Plotting the actual test values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y_test[time_steps:], label='True', color='blue')\n",
    "\n",
    "    # Plotting the predicted values\n",
    "    plt.plot(y_preds[time_steps:], label='Predicted', color='red', linestyle='dashed')\n",
    "\n",
    "    if model_name != None:\n",
    "        plt.title(f'{model_name} - Actual vs Predicted')\n",
    "    else:\n",
    "        plt.title('Actual vs Predicted')\n",
    "\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a762b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f58c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModel:\n",
    "    def __init__(self, model_type='lstm', loss='mse', optimizer='adam', seed_value=42):\n",
    "        self.model_type = model_type\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.seed_value = seed_value\n",
    "        self.best_model_path = None\n",
    "        self.model = None\n",
    "\n",
    "    def _setup_seed(self):\n",
    "        np.random.seed(self.seed_value)\n",
    "        random.seed(self.seed_value)\n",
    "        tf.random.set_seed(self.seed_value)\n",
    "\n",
    "    def define_model(self, X):\n",
    "        X = X.copy()\n",
    "        self._setup_seed()\n",
    "\n",
    "        if self.model_type == 'lstm':\n",
    "            self.model = Sequential()\n",
    "            self.model.add(LSTM(64, input_shape=(X.shape[1], X.shape[2])))\n",
    "        elif self.model_type == 'bi_lstm':\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Bidirectional(LSTM(64), input_shape=(X.shape[1], X.shape[2])))\n",
    "        elif self.model_type == 'gru':\n",
    "            self.model = Sequential()\n",
    "            self.model.add(GRU(64, input_shape=(X.shape[1], X.shape[2])))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Choose 'lstm', 'bi_lstm', or 'gru'.\")\n",
    "\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, epochs=1000, patience=50, best_model_path = 'Best_Model.keras'):\n",
    "        self.best_model_path = best_model_path\n",
    "        self.define_model(X_train)\n",
    "        checkpoint = ModelCheckpoint(self.best_model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "    def predict(self, X_test, verbose=False, best_model = True):\n",
    "        if best_model == True:\n",
    "            self.model.load_weights(self.best_model_path)\n",
    "        else:\n",
    "            pass\n",
    "        return self.model.predict(X_test, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "840705fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35b1a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11bef5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6107.5278\n",
      "Epoch 1: val_loss improved from inf to 21994.57031, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 4s 34ms/step - loss: 6058.5923 - val_loss: 21994.5703\n",
      "Epoch 2/1000\n",
      "11/37 [=======>......................] - ETA: 0s - loss: 5036.5898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/37 [==========================>...] - ETA: 0s - loss: 5147.4126\n",
      "Epoch 2: val_loss improved from 21994.57031 to 20600.63672, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5113.2437 - val_loss: 20600.6367\n",
      "Epoch 3/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4657.9668\n",
      "Epoch 3: val_loss improved from 20600.63672 to 19773.83008, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4688.0776 - val_loss: 19773.8301\n",
      "Epoch 4/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4388.2100\n",
      "Epoch 4: val_loss improved from 19773.83008 to 19055.87305, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4379.5669 - val_loss: 19055.8730\n",
      "Epoch 5/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4105.5122\n",
      "Epoch 5: val_loss improved from 19055.87305 to 18391.71289, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4111.0342 - val_loss: 18391.7129\n",
      "Epoch 6/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3902.7417\n",
      "Epoch 6: val_loss improved from 18391.71289 to 17767.56836, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3868.1484 - val_loss: 17767.5684\n",
      "Epoch 7/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3651.6719\n",
      "Epoch 7: val_loss improved from 17767.56836 to 17184.01367, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3645.4431 - val_loss: 17184.0137\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3442.1875\n",
      "Epoch 8: val_loss improved from 17184.01367 to 16621.90039, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3442.1875 - val_loss: 16621.9004\n",
      "Epoch 9/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3270.9392\n",
      "Epoch 9: val_loss improved from 16621.90039 to 16096.22852, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3252.9126 - val_loss: 16096.2285\n",
      "Epoch 10/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3114.7085\n",
      "Epoch 10: val_loss improved from 16096.22852 to 15588.48047, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3079.6589 - val_loss: 15588.4805\n",
      "Epoch 11/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2889.4507\n",
      "Epoch 11: val_loss improved from 15588.48047 to 15109.71875, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2918.9160 - val_loss: 15109.7188\n",
      "Epoch 12/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2769.7419\n",
      "Epoch 12: val_loss improved from 15109.71875 to 14648.68848, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2771.4480 - val_loss: 14648.6885\n",
      "Epoch 13/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2668.0608\n",
      "Epoch 13: val_loss improved from 14648.68848 to 14206.91406, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2635.6848 - val_loss: 14206.9141\n",
      "Epoch 14/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2481.3374\n",
      "Epoch 14: val_loss improved from 14206.91406 to 13794.29297, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2509.7703 - val_loss: 13794.2930\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2395.2788\n",
      "Epoch 15: val_loss improved from 13794.29297 to 13392.56543, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2395.2788 - val_loss: 13392.5654\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2289.3826\n",
      "Epoch 16: val_loss improved from 13392.56543 to 13016.27637, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2289.3826 - val_loss: 13016.2764\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2193.6001\n",
      "Epoch 17: val_loss improved from 13016.27637 to 12647.22266, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2193.6001 - val_loss: 12647.2227\n",
      "Epoch 18/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2038.2983\n",
      "Epoch 18: val_loss improved from 12647.22266 to 12306.80762, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2104.7566 - val_loss: 12306.8076\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2025.3423\n",
      "Epoch 19: val_loss improved from 12306.80762 to 11972.25293, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2025.3423 - val_loss: 11972.2529\n",
      "Epoch 20/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1952.3507\n",
      "Epoch 20: val_loss improved from 11972.25293 to 11660.90527, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1952.0736 - val_loss: 11660.9053\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1885.9136\n",
      "Epoch 21: val_loss improved from 11660.90527 to 11367.25781, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1885.9136 - val_loss: 11367.2578\n",
      "Epoch 22/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 1799.4248\n",
      "Epoch 22: val_loss improved from 11367.25781 to 11089.09375, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1826.2474 - val_loss: 11089.0938\n",
      "Epoch 23/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1771.6091\n",
      "Epoch 23: val_loss improved from 11089.09375 to 10826.59668, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1772.1440 - val_loss: 10826.5967\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1723.9950\n",
      "Epoch 24: val_loss improved from 10826.59668 to 10567.99023, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1723.9950 - val_loss: 10567.9902\n",
      "Epoch 25/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1693.1691\n",
      "Epoch 25: val_loss improved from 10567.99023 to 10328.88867, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1680.2725 - val_loss: 10328.8887\n",
      "Epoch 26/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1624.9668\n",
      "Epoch 26: val_loss improved from 10328.88867 to 10106.97559, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1641.2202 - val_loss: 10106.9756\n",
      "Epoch 27/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1619.0461\n",
      "Epoch 27: val_loss improved from 10106.97559 to 9886.36816, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1606.9874 - val_loss: 9886.3682\n",
      "Epoch 28/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1579.1061\n",
      "Epoch 28: val_loss improved from 9886.36816 to 9689.44336, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1575.9200 - val_loss: 9689.4434\n",
      "Epoch 29/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1553.9044\n",
      "Epoch 29: val_loss improved from 9689.44336 to 9499.90625, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1548.9330 - val_loss: 9499.9062\n",
      "Epoch 30/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1539.0811\n",
      "Epoch 30: val_loss improved from 9499.90625 to 9323.95898, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1524.7858 - val_loss: 9323.9590\n",
      "Epoch 31/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1475.1415\n",
      "Epoch 31: val_loss improved from 9323.95898 to 9163.29395, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1503.4929 - val_loss: 9163.2939\n",
      "Epoch 32/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1486.8678\n",
      "Epoch 32: val_loss improved from 9163.29395 to 9005.12988, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1485.0992 - val_loss: 9005.1299\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1469.0374\n",
      "Epoch 33: val_loss improved from 9005.12988 to 8853.80664, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1469.0374 - val_loss: 8853.8066\n",
      "Epoch 34/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1464.5048\n",
      "Epoch 34: val_loss improved from 8853.80664 to 8722.10742, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1454.6289 - val_loss: 8722.1074\n",
      "Epoch 35/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1446.4033\n",
      "Epoch 35: val_loss improved from 8722.10742 to 8585.05762, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1442.7997 - val_loss: 8585.0576\n",
      "Epoch 36/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 1433.9789\n",
      "Epoch 36: val_loss improved from 8585.05762 to 8469.27344, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1431.9122 - val_loss: 8469.2734\n",
      "Epoch 37/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1412.4493\n",
      "Epoch 37: val_loss improved from 8469.27344 to 8361.94141, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1422.8762 - val_loss: 8361.9414\n",
      "Epoch 38/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1414.5739\n",
      "Epoch 38: val_loss improved from 8361.94141 to 8262.35059, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1413.9192 - val_loss: 8262.3506\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1374.2301\n",
      "Epoch 39: val_loss improved from 8262.35059 to 8149.36084, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1374.2301 - val_loss: 8149.3608\n",
      "Epoch 40/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1308.8010\n",
      "Epoch 40: val_loss improved from 8149.36084 to 8053.00928, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1298.7915 - val_loss: 8053.0093\n",
      "Epoch 41/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1171.1028\n",
      "Epoch 41: val_loss improved from 8053.00928 to 7839.89160, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1177.8687 - val_loss: 7839.8916\n",
      "Epoch 42/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1086.6073\n",
      "Epoch 42: val_loss improved from 7839.89160 to 7573.19434, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 1111.4550 - val_loss: 7573.1943\n",
      "Epoch 43/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 984.1166\n",
      "Epoch 43: val_loss improved from 7573.19434 to 7301.27734, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 981.2380 - val_loss: 7301.2773\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 927.0733\n",
      "Epoch 44: val_loss improved from 7301.27734 to 7036.13818, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 927.0733 - val_loss: 7036.1382\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 879.0335\n",
      "Epoch 45: val_loss improved from 7036.13818 to 6784.93262, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 879.0335 - val_loss: 6784.9326\n",
      "Epoch 46/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 840.0283\n",
      "Epoch 46: val_loss improved from 6784.93262 to 6550.69873, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 835.1017 - val_loss: 6550.6987\n",
      "Epoch 47/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 804.8591\n",
      "Epoch 47: val_loss improved from 6550.69873 to 6319.87158, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 793.5549 - val_loss: 6319.8716\n",
      "Epoch 48/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 747.7789\n",
      "Epoch 48: val_loss improved from 6319.87158 to 6109.42822, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 752.6456 - val_loss: 6109.4282\n",
      "Epoch 49/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 702.5378\n",
      "Epoch 49: val_loss improved from 6109.42822 to 5894.82715, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 716.0328 - val_loss: 5894.8271\n",
      "Epoch 50/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 679.3441\n",
      "Epoch 50: val_loss improved from 5894.82715 to 5691.25049, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 678.8736 - val_loss: 5691.2505\n",
      "Epoch 51/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 639.3221\n",
      "Epoch 51: val_loss improved from 5691.25049 to 5493.24170, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 644.3503 - val_loss: 5493.2417\n",
      "Epoch 52/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 635.6711\n",
      "Epoch 52: val_loss improved from 5493.24170 to 5298.92529, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 612.0388 - val_loss: 5298.9253\n",
      "Epoch 53/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 565.0933\n",
      "Epoch 53: val_loss improved from 5298.92529 to 5125.85693, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 586.8588 - val_loss: 5125.8569\n",
      "Epoch 54/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 548.3620\n",
      "Epoch 54: val_loss improved from 5125.85693 to 4958.71826, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 560.2082 - val_loss: 4958.7183\n",
      "Epoch 55/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 531.0133\n",
      "Epoch 55: val_loss improved from 4958.71826 to 4778.68115, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 525.6805 - val_loss: 4778.6812\n",
      "Epoch 56/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 500.5764\n",
      "Epoch 56: val_loss improved from 4778.68115 to 4612.40234, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 497.4424 - val_loss: 4612.4023\n",
      "Epoch 57/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 477.9534\n",
      "Epoch 57: val_loss improved from 4612.40234 to 4451.53027, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 472.2473 - val_loss: 4451.5303\n",
      "Epoch 58/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 460.7276\n",
      "Epoch 58: val_loss improved from 4451.53027 to 4292.81494, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 446.0565 - val_loss: 4292.8149\n",
      "Epoch 59/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 422.5669\n",
      "Epoch 59: val_loss improved from 4292.81494 to 4141.31152, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 417.2585 - val_loss: 4141.3115\n",
      "Epoch 60/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 399.9305\n",
      "Epoch 60: val_loss improved from 4141.31152 to 3994.71729, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 397.6941 - val_loss: 3994.7173\n",
      "Epoch 61/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 376.3586\n",
      "Epoch 61: val_loss improved from 3994.71729 to 3855.58643, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 374.8337 - val_loss: 3855.5864\n",
      "Epoch 62/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 356.8860\n",
      "Epoch 62: val_loss improved from 3855.58643 to 3717.35132, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 351.3173 - val_loss: 3717.3513\n",
      "Epoch 63/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 321.6581\n",
      "Epoch 63: val_loss improved from 3717.35132 to 3592.21191, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 343.0190 - val_loss: 3592.2119\n",
      "Epoch 64/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 316.0064\n",
      "Epoch 64: val_loss improved from 3592.21191 to 3467.91943, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 320.1638 - val_loss: 3467.9194\n",
      "Epoch 65/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 291.8304\n",
      "Epoch 65: val_loss improved from 3467.91943 to 3343.23853, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 295.2802 - val_loss: 3343.2385\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 281.8969\n",
      "Epoch 66: val_loss improved from 3343.23853 to 3225.47485, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 278.9265 - val_loss: 3225.4749\n",
      "Epoch 67/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 256.7445\n",
      "Epoch 67: val_loss improved from 3225.47485 to 3113.00952, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 260.5231 - val_loss: 3113.0095\n",
      "Epoch 68/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 256.1036\n",
      "Epoch 68: val_loss improved from 3113.00952 to 3002.89673, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 243.6719 - val_loss: 3002.8967\n",
      "Epoch 69/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 229.1477\n",
      "Epoch 69: val_loss improved from 3002.89673 to 2903.06934, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 228.2800 - val_loss: 2903.0693\n",
      "Epoch 70/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 212.1976\n",
      "Epoch 70: val_loss improved from 2903.06934 to 2802.38184, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 214.9274 - val_loss: 2802.3818\n",
      "Epoch 71/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 204.2453\n",
      "Epoch 71: val_loss improved from 2802.38184 to 2703.74951, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 202.2431 - val_loss: 2703.7495\n",
      "Epoch 72/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 190.8068\n",
      "Epoch 72: val_loss improved from 2703.74951 to 2611.67847, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 189.0273 - val_loss: 2611.6785\n",
      "Epoch 73/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 178.9765\n",
      "Epoch 73: val_loss improved from 2611.67847 to 2523.58008, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 178.8877 - val_loss: 2523.5801\n",
      "Epoch 74/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 164.3986\n",
      "Epoch 74: val_loss improved from 2523.58008 to 2438.90576, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 167.9299 - val_loss: 2438.9058\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 157.9185\n",
      "Epoch 75: val_loss improved from 2438.90576 to 2355.42334, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 157.9185 - val_loss: 2355.4233\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 149.2314\n",
      "Epoch 76: val_loss improved from 2355.42334 to 2277.53394, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 149.2314 - val_loss: 2277.5339\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 139.1332\n",
      "Epoch 77: val_loss improved from 2277.53394 to 2203.33105, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 139.1332 - val_loss: 2203.3311\n",
      "Epoch 78/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 135.7338\n",
      "Epoch 78: val_loss improved from 2203.33105 to 2131.16602, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 132.7473 - val_loss: 2131.1660\n",
      "Epoch 79/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 125.4832\n",
      "Epoch 79: val_loss improved from 2131.16602 to 2063.64966, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 124.3271 - val_loss: 2063.6497\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 116.6875\n",
      "Epoch 80: val_loss improved from 2063.64966 to 2000.38965, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 116.6875 - val_loss: 2000.3896\n",
      "Epoch 81/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 115.1239\n",
      "Epoch 81: val_loss improved from 2000.38965 to 1934.22144, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 114.4406 - val_loss: 1934.2214\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 107.8152\n",
      "Epoch 82: val_loss improved from 1934.22144 to 1874.19788, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 107.8152 - val_loss: 1874.1979\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 100.0777\n",
      "Epoch 83: val_loss improved from 1874.19788 to 1815.81897, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 100.0777 - val_loss: 1815.8190\n",
      "Epoch 84/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 89.6666\n",
      "Epoch 84: val_loss improved from 1815.81897 to 1760.13416, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 92.5915 - val_loss: 1760.1342\n",
      "Epoch 85/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 93.2709\n",
      "Epoch 85: val_loss improved from 1760.13416 to 1706.55957, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 88.6986 - val_loss: 1706.5596\n",
      "Epoch 86/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 82.2049\n",
      "Epoch 86: val_loss improved from 1706.55957 to 1658.06421, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 86.3392 - val_loss: 1658.0642\n",
      "Epoch 87/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 77.9809\n",
      "Epoch 87: val_loss improved from 1658.06421 to 1610.91553, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 79.7585 - val_loss: 1610.9155\n",
      "Epoch 88/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 79.9802\n",
      "Epoch 88: val_loss improved from 1610.91553 to 1563.20789, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 76.4439 - val_loss: 1563.2079\n",
      "Epoch 89/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 71.7529\n",
      "Epoch 89: val_loss improved from 1563.20789 to 1520.15137, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 71.5239 - val_loss: 1520.1514\n",
      "Epoch 90/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 70.3572\n",
      "Epoch 90: val_loss improved from 1520.15137 to 1480.01990, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 70.6922 - val_loss: 1480.0199\n",
      "Epoch 91/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 69.8876\n",
      "Epoch 91: val_loss improved from 1480.01990 to 1440.06653, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 69.3778 - val_loss: 1440.0665\n",
      "Epoch 92/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 65.3650\n",
      "Epoch 92: val_loss improved from 1440.06653 to 1401.12439, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 65.8929 - val_loss: 1401.1244\n",
      "Epoch 93/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 62.1810\n",
      "Epoch 93: val_loss improved from 1401.12439 to 1362.65417, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 61.0288 - val_loss: 1362.6542\n",
      "Epoch 94/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 57.1372\n",
      "Epoch 94: val_loss improved from 1362.65417 to 1329.57385, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 58.1472 - val_loss: 1329.5739\n",
      "Epoch 95/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 58.6307\n",
      "Epoch 95: val_loss improved from 1329.57385 to 1295.62915, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 56.3502 - val_loss: 1295.6292\n",
      "Epoch 96/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 54.8713\n",
      "Epoch 96: val_loss improved from 1295.62915 to 1265.06445, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 54.1056 - val_loss: 1265.0645\n",
      "Epoch 97/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 50.3257\n",
      "Epoch 97: val_loss improved from 1265.06445 to 1238.28735, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 51.6054 - val_loss: 1238.2874\n",
      "Epoch 98/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 50.0730\n",
      "Epoch 98: val_loss improved from 1238.28735 to 1210.54297, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 49.5065 - val_loss: 1210.5430\n",
      "Epoch 99/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 46.9941\n",
      "Epoch 99: val_loss improved from 1210.54297 to 1181.88379, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 47.3706 - val_loss: 1181.8838\n",
      "Epoch 100/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 45.5596\n",
      "Epoch 100: val_loss improved from 1181.88379 to 1156.77380, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 46.6736 - val_loss: 1156.7738\n",
      "Epoch 101/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 51.7599\n",
      "Epoch 101: val_loss improved from 1156.77380 to 1126.92712, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 51.2172 - val_loss: 1126.9271\n",
      "Epoch 102/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 41.2137\n",
      "Epoch 102: val_loss improved from 1126.92712 to 1099.05115, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 41.3898 - val_loss: 1099.0511\n",
      "Epoch 103/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 38.9714\n",
      "Epoch 103: val_loss improved from 1099.05115 to 1071.55310, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 39.2054 - val_loss: 1071.5531\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 36.4795\n",
      "Epoch 104: val_loss improved from 1071.55310 to 1045.97729, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 36.4795 - val_loss: 1045.9773\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 36.0325\n",
      "Epoch 105: val_loss improved from 1045.97729 to 1019.72113, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 36.0325 - val_loss: 1019.7211\n",
      "Epoch 106/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 34.0805\n",
      "Epoch 106: val_loss improved from 1019.72113 to 994.94550, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 33.9654 - val_loss: 994.9455\n",
      "Epoch 107/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 31.5385\n",
      "Epoch 107: val_loss improved from 994.94550 to 972.81012, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 32.6976 - val_loss: 972.8101\n",
      "Epoch 108/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 31.1892\n",
      "Epoch 108: val_loss improved from 972.81012 to 950.93188, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 31.3893 - val_loss: 950.9319\n",
      "Epoch 109/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 28.8457\n",
      "Epoch 109: val_loss improved from 950.93188 to 929.19177, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 29.9172 - val_loss: 929.1918\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 28.8054\n",
      "Epoch 110: val_loss improved from 929.19177 to 908.44330, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 28.8054 - val_loss: 908.4433\n",
      "Epoch 111/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 28.5857\n",
      "Epoch 111: val_loss improved from 908.44330 to 887.95978, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 28.3500 - val_loss: 887.9598\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 27.9516\n",
      "Epoch 112: val_loss improved from 887.95978 to 868.50342, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 27.9516 - val_loss: 868.5034\n",
      "Epoch 113/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 26.2554\n",
      "Epoch 113: val_loss improved from 868.50342 to 851.24158, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 27.1565 - val_loss: 851.2416\n",
      "Epoch 114/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 25.8098\n",
      "Epoch 114: val_loss improved from 851.24158 to 831.81329, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 25.5750 - val_loss: 831.8133\n",
      "Epoch 115/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 25.3341\n",
      "Epoch 115: val_loss improved from 831.81329 to 814.87775, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 25.0147 - val_loss: 814.8777\n",
      "Epoch 116/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 24.1879\n",
      "Epoch 116: val_loss improved from 814.87775 to 797.73431, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 23.9132 - val_loss: 797.7343\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 22.8571\n",
      "Epoch 117: val_loss improved from 797.73431 to 781.07654, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 22.8571 - val_loss: 781.0765\n",
      "Epoch 118/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 22.6899\n",
      "Epoch 118: val_loss improved from 781.07654 to 764.98383, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 22.6240 - val_loss: 764.9838\n",
      "Epoch 119/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 22.1223\n",
      "Epoch 119: val_loss improved from 764.98383 to 750.19287, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 22.2091 - val_loss: 750.1929\n",
      "Epoch 120/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 20.9029\n",
      "Epoch 120: val_loss improved from 750.19287 to 734.45123, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 21.4665 - val_loss: 734.4512\n",
      "Epoch 121/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 20.6925\n",
      "Epoch 121: val_loss improved from 734.45123 to 720.38062, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 20.5384 - val_loss: 720.3806\n",
      "Epoch 122/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 22.1451\n",
      "Epoch 122: val_loss improved from 720.38062 to 704.66766, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 21.7417 - val_loss: 704.6677\n",
      "Epoch 123/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 19.2845\n",
      "Epoch 123: val_loss improved from 704.66766 to 691.32501, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 19.5695 - val_loss: 691.3250\n",
      "Epoch 124/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 20.2409\n",
      "Epoch 124: val_loss improved from 691.32501 to 679.53009, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 19.8120 - val_loss: 679.5301\n",
      "Epoch 125/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.1442\n",
      "Epoch 125: val_loss improved from 679.53009 to 665.27313, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 18.2057 - val_loss: 665.2731\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 17.4855\n",
      "Epoch 126: val_loss improved from 665.27313 to 651.31024, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 17.4855 - val_loss: 651.3102\n",
      "Epoch 127/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 18.2189\n",
      "Epoch 127: val_loss improved from 651.31024 to 639.07690, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 17.9116 - val_loss: 639.0769\n",
      "Epoch 128/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 16.9256\n",
      "Epoch 128: val_loss improved from 639.07690 to 628.20355, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 16.9052 - val_loss: 628.2036\n",
      "Epoch 129/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 17.3332\n",
      "Epoch 129: val_loss improved from 628.20355 to 614.29376, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 17.2549 - val_loss: 614.2938\n",
      "Epoch 130/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.4020\n",
      "Epoch 130: val_loss improved from 614.29376 to 603.35071, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 16.9623 - val_loss: 603.3507\n",
      "Epoch 131/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 15.2429\n",
      "Epoch 131: val_loss improved from 603.35071 to 592.76825, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 15.3070 - val_loss: 592.7682\n",
      "Epoch 132/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 15.0391\n",
      "Epoch 132: val_loss improved from 592.76825 to 580.17035, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 15.0416 - val_loss: 580.1703\n",
      "Epoch 133/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.6683\n",
      "Epoch 133: val_loss improved from 580.17035 to 568.15790, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 15.2248 - val_loss: 568.1579\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.6681\n",
      "Epoch 134: val_loss improved from 568.15790 to 559.84747, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 14.6681 - val_loss: 559.8475\n",
      "Epoch 135/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.0016\n",
      "Epoch 135: val_loss improved from 559.84747 to 550.65320, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 13.9089 - val_loss: 550.6532\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.4855\n",
      "Epoch 136: val_loss improved from 550.65320 to 537.95117, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 14.4855 - val_loss: 537.9512\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 13.8870\n",
      "Epoch 137: val_loss improved from 537.95117 to 531.58789, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 13.8870 - val_loss: 531.5879\n",
      "Epoch 138/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.2021\n",
      "Epoch 138: val_loss improved from 531.58789 to 521.65405, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 13.1126 - val_loss: 521.6541\n",
      "Epoch 139/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.8789\n",
      "Epoch 139: val_loss improved from 521.65405 to 512.59772, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 12.7656 - val_loss: 512.5977\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.0241\n",
      "Epoch 140: val_loss improved from 512.59772 to 500.78943, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 12.0241 - val_loss: 500.7894\n",
      "Epoch 141/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.9604\n",
      "Epoch 141: val_loss improved from 500.78943 to 490.82193, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.7404 - val_loss: 490.8219\n",
      "Epoch 142/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11.6767\n",
      "Epoch 142: val_loss improved from 490.82193 to 482.53802, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.7081 - val_loss: 482.5380\n",
      "Epoch 143/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.1203\n",
      "Epoch 143: val_loss improved from 482.53802 to 473.49286, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.1363 - val_loss: 473.4929\n",
      "Epoch 144/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.2147\n",
      "Epoch 144: val_loss improved from 473.49286 to 464.44336, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 10.4573 - val_loss: 464.4434\n",
      "Epoch 145/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10.7104\n",
      "Epoch 145: val_loss improved from 464.44336 to 456.35916, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.6329 - val_loss: 456.3592\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1741\n",
      "Epoch 146: val_loss improved from 456.35916 to 446.11063, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 10.1741 - val_loss: 446.1106\n",
      "Epoch 147/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.7963\n",
      "Epoch 147: val_loss improved from 446.11063 to 439.36169, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 9.6120 - val_loss: 439.3617\n",
      "Epoch 148/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 9.8868 \n",
      "Epoch 148: val_loss improved from 439.36169 to 430.84195, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.6784 - val_loss: 430.8419\n",
      "Epoch 149/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.0389\n",
      "Epoch 149: val_loss improved from 430.84195 to 424.99252, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.8656 - val_loss: 424.9925\n",
      "Epoch 150/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.4806\n",
      "Epoch 150: val_loss improved from 424.99252 to 417.66827, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.5302 - val_loss: 417.6683\n",
      "Epoch 151/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.5449\n",
      "Epoch 151: val_loss improved from 417.66827 to 407.44830, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.4149 - val_loss: 407.4483\n",
      "Epoch 152/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 8.8115\n",
      "Epoch 152: val_loss improved from 407.44830 to 400.69812, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 8.9688 - val_loss: 400.6981\n",
      "Epoch 153/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.4151\n",
      "Epoch 153: val_loss improved from 400.69812 to 395.18381, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.4235 - val_loss: 395.1838\n",
      "Epoch 154/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.3533\n",
      "Epoch 154: val_loss improved from 395.18381 to 388.00497, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 8.6605 - val_loss: 388.0050\n",
      "Epoch 155/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.6108\n",
      "Epoch 155: val_loss improved from 388.00497 to 381.73611, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.5478 - val_loss: 381.7361\n",
      "Epoch 156/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.2215\n",
      "Epoch 156: val_loss improved from 381.73611 to 377.59949, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 9.0282 - val_loss: 377.5995\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.3959\n",
      "Epoch 157: val_loss improved from 377.59949 to 370.28549, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.3959 - val_loss: 370.2855\n",
      "Epoch 158/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.8223\n",
      "Epoch 158: val_loss improved from 370.28549 to 364.01099, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.7405 - val_loss: 364.0110\n",
      "Epoch 159/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.5492\n",
      "Epoch 159: val_loss improved from 364.01099 to 358.76996, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.4580 - val_loss: 358.7700\n",
      "Epoch 160/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.7908\n",
      "Epoch 160: val_loss improved from 358.76996 to 353.13132, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.6811 - val_loss: 353.1313\n",
      "Epoch 161/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.3458\n",
      "Epoch 161: val_loss improved from 353.13132 to 348.31543, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.3062 - val_loss: 348.3154\n",
      "Epoch 162/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.8716\n",
      "Epoch 162: val_loss improved from 348.31543 to 342.26932, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.7358 - val_loss: 342.2693\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6790\n",
      "Epoch 163: val_loss improved from 342.26932 to 337.15982, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.6790 - val_loss: 337.1598\n",
      "Epoch 164/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.9995\n",
      "Epoch 164: val_loss improved from 337.15982 to 332.86145, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.8736 - val_loss: 332.8615\n",
      "Epoch 165/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.9932\n",
      "Epoch 165: val_loss improved from 332.86145 to 329.19186, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.0982 - val_loss: 329.1919\n",
      "Epoch 166/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 8.1953\n",
      "Epoch 166: val_loss improved from 329.19186 to 323.54083, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.7535 - val_loss: 323.5408\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.3625\n",
      "Epoch 167: val_loss improved from 323.54083 to 318.54666, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.3625 - val_loss: 318.5467\n",
      "Epoch 168/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.6798\n",
      "Epoch 168: val_loss improved from 318.54666 to 314.85788, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.8505 - val_loss: 314.8579\n",
      "Epoch 169/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.8343\n",
      "Epoch 169: val_loss improved from 314.85788 to 311.12466, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.8793 - val_loss: 311.1247\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.6999\n",
      "Epoch 170: val_loss improved from 311.12466 to 306.68045, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.6999 - val_loss: 306.6805\n",
      "Epoch 171/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.7275\n",
      "Epoch 171: val_loss improved from 306.68045 to 305.14655, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.8552 - val_loss: 305.1465\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.2478\n",
      "Epoch 172: val_loss improved from 305.14655 to 299.17346, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 6.2478 - val_loss: 299.1735\n",
      "Epoch 173/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.4966\n",
      "Epoch 173: val_loss improved from 299.17346 to 296.22742, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.6160 - val_loss: 296.2274\n",
      "Epoch 174/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4476\n",
      "Epoch 174: val_loss improved from 296.22742 to 292.04590, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.3924 - val_loss: 292.0459\n",
      "Epoch 175/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.6957\n",
      "Epoch 175: val_loss improved from 292.04590 to 288.59476, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.5173 - val_loss: 288.5948\n",
      "Epoch 176/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.6984\n",
      "Epoch 176: val_loss improved from 288.59476 to 284.94638, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.8418 - val_loss: 284.9464\n",
      "Epoch 177/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.2098\n",
      "Epoch 177: val_loss improved from 284.94638 to 281.88974, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3834 - val_loss: 281.8897\n",
      "Epoch 178/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.3608\n",
      "Epoch 178: val_loss improved from 281.88974 to 279.97455, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.4851 - val_loss: 279.9745\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.5514\n",
      "Epoch 179: val_loss improved from 279.97455 to 276.42526, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.5514 - val_loss: 276.4253\n",
      "Epoch 180/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.5926\n",
      "Epoch 180: val_loss improved from 276.42526 to 272.26981, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.5841 - val_loss: 272.2698\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.9189\n",
      "Epoch 181: val_loss improved from 272.26981 to 269.58249, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 4.9189 - val_loss: 269.5825\n",
      "Epoch 182/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8526\n",
      "Epoch 182: val_loss improved from 269.58249 to 267.79855, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.9721 - val_loss: 267.7986\n",
      "Epoch 183/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.3237\n",
      "Epoch 183: val_loss improved from 267.79855 to 264.47784, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.3758 - val_loss: 264.4778\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4714\n",
      "Epoch 184: val_loss improved from 264.47784 to 261.72015, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 5.4714 - val_loss: 261.7202\n",
      "Epoch 185/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 5.3759\n",
      "Epoch 185: val_loss improved from 261.72015 to 260.70200, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.0801 - val_loss: 260.7020\n",
      "Epoch 186/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.1684\n",
      "Epoch 186: val_loss improved from 260.70200 to 258.87939, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 5.1245 - val_loss: 258.8794\n",
      "Epoch 187/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 5.2101\n",
      "Epoch 187: val_loss improved from 258.87939 to 256.08942, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 5.5445 - val_loss: 256.0894\n",
      "Epoch 188/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.6003\n",
      "Epoch 188: val_loss improved from 256.08942 to 252.76671, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.9217 - val_loss: 252.7667\n",
      "Epoch 189/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.9697\n",
      "Epoch 189: val_loss improved from 252.76671 to 251.09125, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.1210 - val_loss: 251.0912\n",
      "Epoch 190/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7939\n",
      "Epoch 190: val_loss improved from 251.09125 to 249.81712, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 5.8559 - val_loss: 249.8171\n",
      "Epoch 191/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.0210\n",
      "Epoch 191: val_loss improved from 249.81712 to 247.66463, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.9164 - val_loss: 247.6646\n",
      "Epoch 192/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6628\n",
      "Epoch 192: val_loss did not improve from 247.66463\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7639 - val_loss: 248.0313\n",
      "Epoch 193/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.8834\n",
      "Epoch 193: val_loss improved from 247.66463 to 244.80803, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8738 - val_loss: 244.8080\n",
      "Epoch 194/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8872\n",
      "Epoch 194: val_loss improved from 244.80803 to 242.75829, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.7949 - val_loss: 242.7583\n",
      "Epoch 195/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4559\n",
      "Epoch 195: val_loss improved from 242.75829 to 241.94720, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.4434 - val_loss: 241.9472\n",
      "Epoch 196/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.7540\n",
      "Epoch 196: val_loss improved from 241.94720 to 239.74420, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.7196 - val_loss: 239.7442\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3173\n",
      "Epoch 197: val_loss improved from 239.74420 to 237.72244, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3173 - val_loss: 237.7224\n",
      "Epoch 198/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8946\n",
      "Epoch 198: val_loss improved from 237.72244 to 236.45767, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 4.9027 - val_loss: 236.4577\n",
      "Epoch 199/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3443\n",
      "Epoch 199: val_loss improved from 236.45767 to 234.65224, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3524 - val_loss: 234.6522\n",
      "Epoch 200/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4796\n",
      "Epoch 200: val_loss improved from 234.65224 to 233.67578, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.4801 - val_loss: 233.6758\n",
      "Epoch 201/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8365\n",
      "Epoch 201: val_loss improved from 233.67578 to 233.05719, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.7608 - val_loss: 233.0572\n",
      "Epoch 202/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.2279\n",
      "Epoch 202: val_loss improved from 233.05719 to 231.06291, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.1980 - val_loss: 231.0629\n",
      "Epoch 203/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.5473 \n",
      "Epoch 203: val_loss did not improve from 231.06291\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.5380 - val_loss: 233.8869\n",
      "Epoch 204/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.8053\n",
      "Epoch 204: val_loss improved from 231.06291 to 228.89781, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.7491 - val_loss: 228.8978\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0236\n",
      "Epoch 205: val_loss improved from 228.89781 to 227.44435, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.0236 - val_loss: 227.4444\n",
      "Epoch 206/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.1120\n",
      "Epoch 206: val_loss improved from 227.44435 to 226.45729, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.0798 - val_loss: 226.4573\n",
      "Epoch 207/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.0187\n",
      "Epoch 207: val_loss improved from 226.45729 to 225.28239, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.9876 - val_loss: 225.2824\n",
      "Epoch 208/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.8733\n",
      "Epoch 208: val_loss improved from 225.28239 to 222.92216, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.8945 - val_loss: 222.9222\n",
      "Epoch 209/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1759\n",
      "Epoch 209: val_loss did not improve from 222.92216\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 5.1274 - val_loss: 223.8754\n",
      "Epoch 210/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4259\n",
      "Epoch 210: val_loss did not improve from 222.92216\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.4869 - val_loss: 223.5795\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3611\n",
      "Epoch 211: val_loss improved from 222.92216 to 220.90614, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3611 - val_loss: 220.9061\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4577\n",
      "Epoch 212: val_loss improved from 220.90614 to 218.15201, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.4577 - val_loss: 218.1520\n",
      "Epoch 213/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.3358\n",
      "Epoch 213: val_loss improved from 218.15201 to 216.41615, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4956 - val_loss: 216.4162\n",
      "Epoch 214/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.4596\n",
      "Epoch 214: val_loss did not improve from 216.41615\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.3423 - val_loss: 217.7686\n",
      "Epoch 215/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2402\n",
      "Epoch 215: val_loss improved from 216.41615 to 213.38550, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2742 - val_loss: 213.3855\n",
      "Epoch 216/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9915\n",
      "Epoch 216: val_loss improved from 213.38550 to 212.27280, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0073 - val_loss: 212.2728\n",
      "Epoch 217/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.1430\n",
      "Epoch 217: val_loss did not improve from 212.27280\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 10.8394 - val_loss: 213.8213\n",
      "Epoch 218/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9596\n",
      "Epoch 218: val_loss did not improve from 212.27280\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8851 - val_loss: 213.3846\n",
      "Epoch 219/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3859\n",
      "Epoch 219: val_loss improved from 212.27280 to 211.93976, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3691 - val_loss: 211.9398\n",
      "Epoch 220/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3287\n",
      "Epoch 220: val_loss did not improve from 211.93976\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3308 - val_loss: 212.3873\n",
      "Epoch 221/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2991\n",
      "Epoch 221: val_loss improved from 211.93976 to 208.26091, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2916 - val_loss: 208.2609\n",
      "Epoch 222/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8342\n",
      "Epoch 222: val_loss did not improve from 208.26091\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9679 - val_loss: 208.9656\n",
      "Epoch 223/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4509\n",
      "Epoch 223: val_loss improved from 208.26091 to 205.09694, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.4279 - val_loss: 205.0969\n",
      "Epoch 224/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3485\n",
      "Epoch 224: val_loss did not improve from 205.09694\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3095 - val_loss: 205.9337\n",
      "Epoch 225/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3397\n",
      "Epoch 225: val_loss improved from 205.09694 to 204.68193, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3503 - val_loss: 204.6819\n",
      "Epoch 226/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8344\n",
      "Epoch 226: val_loss did not improve from 204.68193\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8754 - val_loss: 207.8624\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5334\n",
      "Epoch 227: val_loss improved from 204.68193 to 201.80142, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.5334 - val_loss: 201.8014\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5165\n",
      "Epoch 228: val_loss did not improve from 201.80142\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5165 - val_loss: 201.8945\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4572\n",
      "Epoch 229: val_loss improved from 201.80142 to 200.04921, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.4572 - val_loss: 200.0492\n",
      "Epoch 230/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.1727\n",
      "Epoch 230: val_loss improved from 200.04921 to 199.47949, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3286 - val_loss: 199.4795\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.6041\n",
      "Epoch 231: val_loss improved from 199.47949 to 198.45580, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.6041 - val_loss: 198.4558\n",
      "Epoch 232/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.3580\n",
      "Epoch 232: val_loss did not improve from 198.45580\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4436 - val_loss: 198.7415\n",
      "Epoch 233/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.3848\n",
      "Epoch 233: val_loss improved from 198.45580 to 197.43401, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2271 - val_loss: 197.4340\n",
      "Epoch 234/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0681\n",
      "Epoch 234: val_loss improved from 197.43401 to 197.42885, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0215 - val_loss: 197.4288\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1472\n",
      "Epoch 235: val_loss improved from 197.42885 to 195.91277, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1472 - val_loss: 195.9128\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7484\n",
      "Epoch 236: val_loss improved from 195.91277 to 193.79152, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7484 - val_loss: 193.7915\n",
      "Epoch 237/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8714\n",
      "Epoch 237: val_loss improved from 193.79152 to 193.12209, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9830 - val_loss: 193.1221\n",
      "Epoch 238/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0038\n",
      "Epoch 238: val_loss improved from 193.12209 to 192.24545, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9246 - val_loss: 192.2455\n",
      "Epoch 239/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1238\n",
      "Epoch 239: val_loss improved from 192.24545 to 192.07173, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0720 - val_loss: 192.0717\n",
      "Epoch 240/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8318\n",
      "Epoch 240: val_loss improved from 192.07173 to 191.25684, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.8023 - val_loss: 191.2568\n",
      "Epoch 241/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0015\n",
      "Epoch 241: val_loss improved from 191.25684 to 188.66510, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0444 - val_loss: 188.6651\n",
      "Epoch 242/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7993\n",
      "Epoch 242: val_loss improved from 188.66510 to 187.91325, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7863 - val_loss: 187.9133\n",
      "Epoch 243/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9885\n",
      "Epoch 243: val_loss improved from 187.91325 to 187.33356, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0964 - val_loss: 187.3336\n",
      "Epoch 244/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6603\n",
      "Epoch 244: val_loss improved from 187.33356 to 186.99954, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6949 - val_loss: 186.9995\n",
      "Epoch 245/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8270\n",
      "Epoch 245: val_loss improved from 186.99954 to 185.92671, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7511 - val_loss: 185.9267\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8218\n",
      "Epoch 246: val_loss improved from 185.92671 to 185.29385, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.8218 - val_loss: 185.2939\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0512\n",
      "Epoch 247: val_loss improved from 185.29385 to 183.25658, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0512 - val_loss: 183.2566\n",
      "Epoch 248/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0157\n",
      "Epoch 248: val_loss improved from 183.25658 to 182.55475, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0987 - val_loss: 182.5547\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9063\n",
      "Epoch 249: val_loss did not improve from 182.55475\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.9063 - val_loss: 183.2395\n",
      "Epoch 250/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1468\n",
      "Epoch 250: val_loss improved from 182.55475 to 182.25429, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.1304 - val_loss: 182.2543\n",
      "Epoch 251/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.2553\n",
      "Epoch 251: val_loss improved from 182.25429 to 180.34482, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.1006 - val_loss: 180.3448\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9306\n",
      "Epoch 252: val_loss improved from 180.34482 to 180.14055, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 29ms/step - loss: 3.9306 - val_loss: 180.1405\n",
      "Epoch 253/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8464\n",
      "Epoch 253: val_loss improved from 180.14055 to 179.51074, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.8172 - val_loss: 179.5107\n",
      "Epoch 254/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3498\n",
      "Epoch 254: val_loss did not improve from 179.51074\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3242 - val_loss: 179.7325\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3814\n",
      "Epoch 255: val_loss improved from 179.51074 to 178.41290, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3814 - val_loss: 178.4129\n",
      "Epoch 256/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.7882\n",
      "Epoch 256: val_loss did not improve from 178.41290\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.7231 - val_loss: 180.4998\n",
      "Epoch 257/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1723\n",
      "Epoch 257: val_loss improved from 178.41290 to 176.75203, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2061 - val_loss: 176.7520\n",
      "Epoch 258/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6196\n",
      "Epoch 258: val_loss improved from 176.75203 to 174.17239, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.6160 - val_loss: 174.1724\n",
      "Epoch 259/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7550\n",
      "Epoch 259: val_loss did not improve from 174.17239\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7276 - val_loss: 174.9491\n",
      "Epoch 260/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2105\n",
      "Epoch 260: val_loss improved from 174.17239 to 173.43893, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1531 - val_loss: 173.4389\n",
      "Epoch 261/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1342\n",
      "Epoch 261: val_loss improved from 173.43893 to 172.42639, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0819 - val_loss: 172.4264\n",
      "Epoch 262/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5347\n",
      "Epoch 262: val_loss improved from 172.42639 to 172.37666, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4430 - val_loss: 172.3767\n",
      "Epoch 263/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4484\n",
      "Epoch 263: val_loss did not improve from 172.37666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5401 - val_loss: 173.9106\n",
      "Epoch 264/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7401\n",
      "Epoch 264: val_loss improved from 172.37666 to 169.88686, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8865 - val_loss: 169.8869\n",
      "Epoch 265/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4886\n",
      "Epoch 265: val_loss improved from 169.88686 to 169.10568, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5238 - val_loss: 169.1057\n",
      "Epoch 266/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3696\n",
      "Epoch 266: val_loss improved from 169.10568 to 167.50415, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.3496 - val_loss: 167.5042\n",
      "Epoch 267/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6541\n",
      "Epoch 267: val_loss improved from 167.50415 to 166.91843, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.6137 - val_loss: 166.9184\n",
      "Epoch 268/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0664\n",
      "Epoch 268: val_loss did not improve from 166.91843\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.9898 - val_loss: 168.2666\n",
      "Epoch 269/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6813\n",
      "Epoch 269: val_loss improved from 166.91843 to 165.89381, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.7297 - val_loss: 165.8938\n",
      "Epoch 270/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.7091\n",
      "Epoch 270: val_loss improved from 165.89381 to 164.89014, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7540 - val_loss: 164.8901\n",
      "Epoch 271/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.2647\n",
      "Epoch 271: val_loss improved from 164.89014 to 163.26704, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.2550 - val_loss: 163.2670\n",
      "Epoch 272/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8987\n",
      "Epoch 272: val_loss improved from 163.26704 to 161.09372, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8722 - val_loss: 161.0937\n",
      "Epoch 273/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8436\n",
      "Epoch 273: val_loss improved from 161.09372 to 160.68739, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7633 - val_loss: 160.6874\n",
      "Epoch 274/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.7421\n",
      "Epoch 274: val_loss improved from 160.68739 to 159.80470, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7278 - val_loss: 159.8047\n",
      "Epoch 275/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.6101\n",
      "Epoch 275: val_loss did not improve from 159.80470\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.6057 - val_loss: 161.6250\n",
      "Epoch 276/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0151\n",
      "Epoch 276: val_loss improved from 159.80470 to 158.90059, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.9583 - val_loss: 158.9006\n",
      "Epoch 277/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8758\n",
      "Epoch 277: val_loss did not improve from 158.90059\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.9440 - val_loss: 159.1816\n",
      "Epoch 278/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0869\n",
      "Epoch 278: val_loss improved from 158.90059 to 155.70589, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9241 - val_loss: 155.7059\n",
      "Epoch 279/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.8973\n",
      "Epoch 279: val_loss did not improve from 155.70589\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.6768 - val_loss: 158.1103\n",
      "Epoch 280/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6186\n",
      "Epoch 280: val_loss improved from 155.70589 to 155.20955, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.7495 - val_loss: 155.2095\n",
      "Epoch 281/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6229\n",
      "Epoch 281: val_loss improved from 155.20955 to 154.99359, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5823 - val_loss: 154.9936\n",
      "Epoch 282/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6412\n",
      "Epoch 282: val_loss improved from 154.99359 to 153.85965, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6093 - val_loss: 153.8596\n",
      "Epoch 283/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5150\n",
      "Epoch 283: val_loss improved from 153.85965 to 152.77000, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5485 - val_loss: 152.7700\n",
      "Epoch 284/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5030\n",
      "Epoch 284: val_loss did not improve from 152.77000\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4667 - val_loss: 155.8707\n",
      "Epoch 285/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3070\n",
      "Epoch 285: val_loss improved from 152.77000 to 150.66980, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4126 - val_loss: 150.6698\n",
      "Epoch 286/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5768\n",
      "Epoch 286: val_loss did not improve from 150.66980\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.6113 - val_loss: 155.2832\n",
      "Epoch 287/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5458\n",
      "Epoch 287: val_loss did not improve from 150.66980\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5360 - val_loss: 150.6709\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5696\n",
      "Epoch 288: val_loss improved from 150.66980 to 149.76021, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5696 - val_loss: 149.7602\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4362\n",
      "Epoch 289: val_loss improved from 149.76021 to 147.88176, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4362 - val_loss: 147.8818\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7102\n",
      "Epoch 290: val_loss improved from 147.88176 to 147.06467, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7102 - val_loss: 147.0647\n",
      "Epoch 291/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8107\n",
      "Epoch 291: val_loss improved from 147.06467 to 146.29881, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7854 - val_loss: 146.2988\n",
      "Epoch 292/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2900\n",
      "Epoch 292: val_loss improved from 146.29881 to 144.32372, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3146 - val_loss: 144.3237\n",
      "Epoch 293/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3234\n",
      "Epoch 293: val_loss improved from 144.32372 to 144.25735, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4519 - val_loss: 144.2574\n",
      "Epoch 294/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3616\n",
      "Epoch 294: val_loss improved from 144.25735 to 143.17857, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3061 - val_loss: 143.1786\n",
      "Epoch 295/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5016\n",
      "Epoch 295: val_loss did not improve from 143.17857\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.5397 - val_loss: 144.3928\n",
      "Epoch 296/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3518\n",
      "Epoch 296: val_loss improved from 143.17857 to 142.00684, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3797 - val_loss: 142.0068\n",
      "Epoch 297/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4555\n",
      "Epoch 297: val_loss did not improve from 142.00684\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.3598 - val_loss: 144.0006\n",
      "Epoch 298/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2966\n",
      "Epoch 298: val_loss did not improve from 142.00684\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.3524 - val_loss: 145.0550\n",
      "Epoch 299/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3248\n",
      "Epoch 299: val_loss improved from 142.00684 to 137.22975, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.3734 - val_loss: 137.2298\n",
      "Epoch 300/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.6064\n",
      "Epoch 300: val_loss did not improve from 137.22975\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.6815 - val_loss: 140.3654\n",
      "Epoch 301/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5733\n",
      "Epoch 301: val_loss did not improve from 137.22975\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.5655 - val_loss: 138.9726\n",
      "Epoch 302/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.6331\n",
      "Epoch 302: val_loss improved from 137.22975 to 136.94205, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.6191 - val_loss: 136.9420\n",
      "Epoch 303/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7267\n",
      "Epoch 303: val_loss improved from 136.94205 to 135.82646, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.8223 - val_loss: 135.8265\n",
      "Epoch 304/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3468\n",
      "Epoch 304: val_loss improved from 135.82646 to 134.70470, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.3668 - val_loss: 134.7047\n",
      "Epoch 305/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.7196\n",
      "Epoch 305: val_loss did not improve from 134.70470\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.6721 - val_loss: 137.4271\n",
      "Epoch 306/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.6316\n",
      "Epoch 306: val_loss did not improve from 134.70470\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.7083 - val_loss: 134.9223\n",
      "Epoch 307/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2388\n",
      "Epoch 307: val_loss did not improve from 134.70470\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 3.3689 - val_loss: 135.1254\n",
      "Epoch 308/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8315\n",
      "Epoch 308: val_loss did not improve from 134.70470\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.7533 - val_loss: 138.2568\n",
      "Epoch 309/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5280\n",
      "Epoch 309: val_loss did not improve from 134.70470\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.5284 - val_loss: 135.7273\n",
      "Epoch 310/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8562\n",
      "Epoch 310: val_loss improved from 134.70470 to 131.70061, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0800 - val_loss: 131.7006\n",
      "Epoch 311/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.0592\n",
      "Epoch 311: val_loss improved from 131.70061 to 131.23721, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0700 - val_loss: 131.2372\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2520\n",
      "Epoch 312: val_loss improved from 131.23721 to 129.37163, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.2520 - val_loss: 129.3716\n",
      "Epoch 313/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4277\n",
      "Epoch 313: val_loss improved from 129.37163 to 127.47462, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4143 - val_loss: 127.4746\n",
      "Epoch 314/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4820\n",
      "Epoch 314: val_loss did not improve from 127.47462\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5123 - val_loss: 128.5918\n",
      "Epoch 315/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2962\n",
      "Epoch 315: val_loss did not improve from 127.47462\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3460 - val_loss: 129.9468\n",
      "Epoch 316/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4920\n",
      "Epoch 316: val_loss improved from 127.47462 to 124.92609, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4268 - val_loss: 124.9261\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3881\n",
      "Epoch 317: val_loss did not improve from 124.92609\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3881 - val_loss: 125.6741\n",
      "Epoch 318/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4398\n",
      "Epoch 318: val_loss did not improve from 124.92609\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6356 - val_loss: 130.8180\n",
      "Epoch 319/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2539\n",
      "Epoch 319: val_loss improved from 124.92609 to 121.10387, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2409 - val_loss: 121.1039\n",
      "Epoch 320/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5411\n",
      "Epoch 320: val_loss did not improve from 121.10387\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5128 - val_loss: 131.9565\n",
      "Epoch 321/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4031\n",
      "Epoch 321: val_loss did not improve from 121.10387\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3946 - val_loss: 131.4267\n",
      "Epoch 322/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1927\n",
      "Epoch 322: val_loss did not improve from 121.10387\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1779 - val_loss: 122.1993\n",
      "Epoch 323/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1176\n",
      "Epoch 323: val_loss did not improve from 121.10387\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1266 - val_loss: 123.0007\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3771\n",
      "Epoch 324: val_loss did not improve from 121.10387\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3771 - val_loss: 128.4132\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2982\n",
      "Epoch 325: val_loss improved from 121.10387 to 120.55941, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2982 - val_loss: 120.5594\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1407\n",
      "Epoch 326: val_loss did not improve from 120.55941\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1407 - val_loss: 121.4916\n",
      "Epoch 327/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0239\n",
      "Epoch 327: val_loss improved from 120.55941 to 114.56265, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2177 - val_loss: 114.5627\n",
      "Epoch 328/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2072\n",
      "Epoch 328: val_loss did not improve from 114.56265\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3362 - val_loss: 122.3742\n",
      "Epoch 329/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4430\n",
      "Epoch 329: val_loss did not improve from 114.56265\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3875 - val_loss: 118.3589\n",
      "Epoch 330/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0939\n",
      "Epoch 330: val_loss did not improve from 114.56265\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1402 - val_loss: 118.7595\n",
      "Epoch 331/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1477\n",
      "Epoch 331: val_loss improved from 114.56265 to 113.91743, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1561 - val_loss: 113.9174\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1199\n",
      "Epoch 332: val_loss did not improve from 113.91743\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1199 - val_loss: 115.1355\n",
      "Epoch 333/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1324\n",
      "Epoch 333: val_loss did not improve from 113.91743\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1088 - val_loss: 118.8567\n",
      "Epoch 334/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2359\n",
      "Epoch 334: val_loss did not improve from 113.91743\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2968 - val_loss: 118.7849\n",
      "Epoch 335/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0001\n",
      "Epoch 335: val_loss improved from 113.91743 to 112.81801, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1092 - val_loss: 112.8180\n",
      "Epoch 336/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1470\n",
      "Epoch 336: val_loss improved from 112.81801 to 110.50062, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1720 - val_loss: 110.5006\n",
      "Epoch 337/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9530\n",
      "Epoch 337: val_loss did not improve from 110.50062\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9487 - val_loss: 111.9565\n",
      "Epoch 338/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3116\n",
      "Epoch 338: val_loss did not improve from 110.50062\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3464 - val_loss: 112.5833\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5691\n",
      "Epoch 339: val_loss improved from 110.50062 to 107.84763, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5691 - val_loss: 107.8476\n",
      "Epoch 340/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9996\n",
      "Epoch 340: val_loss did not improve from 107.84763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9363 - val_loss: 109.8357\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1176\n",
      "Epoch 341: val_loss did not improve from 107.84763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1176 - val_loss: 108.1891\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0531\n",
      "Epoch 342: val_loss did not improve from 107.84763\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0531 - val_loss: 108.8820\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1562\n",
      "Epoch 343: val_loss improved from 107.84763 to 106.17274, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1562 - val_loss: 106.1727\n",
      "Epoch 344/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1590\n",
      "Epoch 344: val_loss did not improve from 106.17274\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1277 - val_loss: 109.2448\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3577\n",
      "Epoch 345: val_loss improved from 106.17274 to 104.97241, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3577 - val_loss: 104.9724\n",
      "Epoch 346/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2989\n",
      "Epoch 346: val_loss improved from 104.97241 to 103.57294, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3495 - val_loss: 103.5729\n",
      "Epoch 347/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9149\n",
      "Epoch 347: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9541 - val_loss: 109.2400\n",
      "Epoch 348/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4993\n",
      "Epoch 348: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4274 - val_loss: 106.4513\n",
      "Epoch 349/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0714\n",
      "Epoch 349: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1894 - val_loss: 105.2342\n",
      "Epoch 350/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8183\n",
      "Epoch 350: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8608 - val_loss: 106.3945\n",
      "Epoch 351/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6379\n",
      "Epoch 351: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8048 - val_loss: 104.0962\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1237\n",
      "Epoch 352: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1237 - val_loss: 110.4639\n",
      "Epoch 353/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4869\n",
      "Epoch 353: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4292 - val_loss: 108.6748\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6167\n",
      "Epoch 354: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6167 - val_loss: 105.8500\n",
      "Epoch 355/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3212\n",
      "Epoch 355: val_loss did not improve from 103.57294\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2852 - val_loss: 105.7192\n",
      "Epoch 356/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2796\n",
      "Epoch 356: val_loss improved from 103.57294 to 102.08245, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2054 - val_loss: 102.0825\n",
      "Epoch 357/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6459\n",
      "Epoch 357: val_loss did not improve from 102.08245\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6257 - val_loss: 115.5475\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2643\n",
      "Epoch 358: val_loss did not improve from 102.08245\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2643 - val_loss: 103.5649\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9751\n",
      "Epoch 359: val_loss improved from 102.08245 to 99.77516, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9751 - val_loss: 99.7752\n",
      "Epoch 360/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2149\n",
      "Epoch 360: val_loss did not improve from 99.77516\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1672 - val_loss: 104.9503\n",
      "Epoch 361/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1944\n",
      "Epoch 361: val_loss did not improve from 99.77516\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1980 - val_loss: 106.2667\n",
      "Epoch 362/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0026\n",
      "Epoch 362: val_loss did not improve from 99.77516\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1610 - val_loss: 108.6559\n",
      "Epoch 363/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2082\n",
      "Epoch 363: val_loss did not improve from 99.77516\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2283 - val_loss: 100.6138\n",
      "Epoch 364/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0595\n",
      "Epoch 364: val_loss improved from 99.77516 to 98.70020, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0046 - val_loss: 98.7002\n",
      "Epoch 365/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0835\n",
      "Epoch 365: val_loss did not improve from 98.70020\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0236 - val_loss: 99.8390\n",
      "Epoch 366/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0257\n",
      "Epoch 366: val_loss did not improve from 98.70020\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.0728 - val_loss: 98.7210\n",
      "Epoch 367/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0942\n",
      "Epoch 367: val_loss did not improve from 98.70020\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1574 - val_loss: 100.1883\n",
      "Epoch 368/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8611\n",
      "Epoch 368: val_loss did not improve from 98.70020\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9135 - val_loss: 99.3825\n",
      "Epoch 369/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1108\n",
      "Epoch 369: val_loss improved from 98.70020 to 92.70922, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1854 - val_loss: 92.7092\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0382\n",
      "Epoch 370: val_loss did not improve from 92.70922\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0382 - val_loss: 97.6827\n",
      "Epoch 371/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0615\n",
      "Epoch 371: val_loss did not improve from 92.70922\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0262 - val_loss: 98.7868\n",
      "Epoch 372/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1200\n",
      "Epoch 372: val_loss did not improve from 92.70922\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1634 - val_loss: 101.7453\n",
      "Epoch 373/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0057\n",
      "Epoch 373: val_loss did not improve from 92.70922\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0405 - val_loss: 96.7221\n",
      "Epoch 374/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8605\n",
      "Epoch 374: val_loss improved from 92.70922 to 91.70719, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8337 - val_loss: 91.7072\n",
      "Epoch 375/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9743\n",
      "Epoch 375: val_loss did not improve from 91.70719\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9736 - val_loss: 98.0553\n",
      "Epoch 376/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8466\n",
      "Epoch 376: val_loss did not improve from 91.70719\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8073 - val_loss: 95.2664\n",
      "Epoch 377/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9400\n",
      "Epoch 377: val_loss did not improve from 91.70719\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9692 - val_loss: 95.0810\n",
      "Epoch 378/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8391\n",
      "Epoch 378: val_loss improved from 91.70719 to 90.66290, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8511 - val_loss: 90.6629\n",
      "Epoch 379/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9176\n",
      "Epoch 379: val_loss did not improve from 90.66290\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9489 - val_loss: 92.5201\n",
      "Epoch 380/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7451\n",
      "Epoch 380: val_loss improved from 90.66290 to 89.37635, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7195 - val_loss: 89.3764\n",
      "Epoch 381/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8170\n",
      "Epoch 381: val_loss did not improve from 89.37635\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7673 - val_loss: 89.5052\n",
      "Epoch 382/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1846\n",
      "Epoch 382: val_loss did not improve from 89.37635\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3222 - val_loss: 97.2881\n",
      "Epoch 383/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1866\n",
      "Epoch 383: val_loss did not improve from 89.37635\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1179 - val_loss: 90.9828\n",
      "Epoch 384/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7997\n",
      "Epoch 384: val_loss did not improve from 89.37635\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8535 - val_loss: 95.3292\n",
      "Epoch 385/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7765\n",
      "Epoch 385: val_loss improved from 89.37635 to 87.74908, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7831 - val_loss: 87.7491\n",
      "Epoch 386/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1030\n",
      "Epoch 386: val_loss did not improve from 87.74908\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1551 - val_loss: 89.8716\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4184\n",
      "Epoch 387: val_loss did not improve from 87.74908\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4184 - val_loss: 89.2010\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8095\n",
      "Epoch 388: val_loss did not improve from 87.74908\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8095 - val_loss: 88.7382\n",
      "Epoch 389/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0813\n",
      "Epoch 389: val_loss did not improve from 87.74908\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0087 - val_loss: 94.8444\n",
      "Epoch 390/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3478\n",
      "Epoch 390: val_loss improved from 87.74908 to 85.70772, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3143 - val_loss: 85.7077\n",
      "Epoch 391/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1606\n",
      "Epoch 391: val_loss did not improve from 85.70772\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1219 - val_loss: 85.9491\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7246\n",
      "Epoch 392: val_loss improved from 85.70772 to 82.36919, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7246 - val_loss: 82.3692\n",
      "Epoch 393/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0443\n",
      "Epoch 393: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1891 - val_loss: 93.1363\n",
      "Epoch 394/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7722\n",
      "Epoch 394: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7713 - val_loss: 82.9211\n",
      "Epoch 395/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9042\n",
      "Epoch 395: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9227 - val_loss: 84.6560\n",
      "Epoch 396/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8169\n",
      "Epoch 396: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8199 - val_loss: 93.9389\n",
      "Epoch 397/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8765\n",
      "Epoch 397: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8689 - val_loss: 95.9857\n",
      "Epoch 398/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9343\n",
      "Epoch 398: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9736 - val_loss: 90.4082\n",
      "Epoch 399/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5950\n",
      "Epoch 399: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6309 - val_loss: 83.5484\n",
      "Epoch 400/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6067\n",
      "Epoch 400: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6190 - val_loss: 88.3650\n",
      "Epoch 401/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6987\n",
      "Epoch 401: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7331 - val_loss: 83.8604\n",
      "Epoch 402/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7650\n",
      "Epoch 402: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7514 - val_loss: 98.5884\n",
      "Epoch 403/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7734\n",
      "Epoch 403: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6934 - val_loss: 87.1395\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6952\n",
      "Epoch 404: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6952 - val_loss: 83.7615\n",
      "Epoch 405/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7736\n",
      "Epoch 405: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8430 - val_loss: 88.3143\n",
      "Epoch 406/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9515\n",
      "Epoch 406: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0471 - val_loss: 85.0003\n",
      "Epoch 407/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8238\n",
      "Epoch 407: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8465 - val_loss: 82.5839\n",
      "Epoch 408/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7205\n",
      "Epoch 408: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7352 - val_loss: 83.0495\n",
      "Epoch 409/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6557\n",
      "Epoch 409: val_loss did not improve from 82.36919\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6439 - val_loss: 88.5923\n",
      "Epoch 410/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7455\n",
      "Epoch 410: val_loss improved from 82.36919 to 80.60435, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8248 - val_loss: 80.6043\n",
      "Epoch 411/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7499\n",
      "Epoch 411: val_loss did not improve from 80.60435\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6869 - val_loss: 92.4688\n",
      "Epoch 412/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7564\n",
      "Epoch 412: val_loss did not improve from 80.60435\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7943 - val_loss: 84.0864\n",
      "Epoch 413/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0621\n",
      "Epoch 413: val_loss did not improve from 80.60435\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0286 - val_loss: 92.9136\n",
      "Epoch 414/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7373\n",
      "Epoch 414: val_loss improved from 80.60435 to 79.30244, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8811 - val_loss: 79.3024\n",
      "Epoch 415/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6433\n",
      "Epoch 415: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7238 - val_loss: 81.2970\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6547\n",
      "Epoch 416: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6547 - val_loss: 84.9903\n",
      "Epoch 417/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5348\n",
      "Epoch 417: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5473 - val_loss: 80.5240\n",
      "Epoch 418/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4481\n",
      "Epoch 418: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4566 - val_loss: 80.3465\n",
      "Epoch 419/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7275\n",
      "Epoch 419: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6960 - val_loss: 81.9864\n",
      "Epoch 420/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5573\n",
      "Epoch 420: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5247 - val_loss: 86.0900\n",
      "Epoch 421/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5764\n",
      "Epoch 421: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5862 - val_loss: 86.2485\n",
      "Epoch 422/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5267\n",
      "Epoch 422: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5757 - val_loss: 81.6639\n",
      "Epoch 423/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9188\n",
      "Epoch 423: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9103 - val_loss: 81.7937\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7656\n",
      "Epoch 424: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7656 - val_loss: 90.9191\n",
      "Epoch 425/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6448\n",
      "Epoch 425: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6850 - val_loss: 82.7967\n",
      "Epoch 426/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5503\n",
      "Epoch 426: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5484 - val_loss: 82.1817\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4844\n",
      "Epoch 427: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.4844 - val_loss: 79.5428\n",
      "Epoch 428/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5765\n",
      "Epoch 428: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5800 - val_loss: 80.4724\n",
      "Epoch 429/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.0248\n",
      "Epoch 429: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2661 - val_loss: 86.6273\n",
      "Epoch 430/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8851\n",
      "Epoch 430: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9001 - val_loss: 81.8348\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7841\n",
      "Epoch 431: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7841 - val_loss: 81.6372\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6487\n",
      "Epoch 432: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6487 - val_loss: 80.2132\n",
      "Epoch 433/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6518\n",
      "Epoch 433: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8080 - val_loss: 82.5859\n",
      "Epoch 434/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5219\n",
      "Epoch 434: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5017 - val_loss: 81.3355\n",
      "Epoch 435/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6125\n",
      "Epoch 435: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6133 - val_loss: 82.1398\n",
      "Epoch 436/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9563\n",
      "Epoch 436: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0013 - val_loss: 79.8374\n",
      "Epoch 437/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2523\n",
      "Epoch 437: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1736 - val_loss: 89.1507\n",
      "Epoch 438/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6256\n",
      "Epoch 438: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5369 - val_loss: 81.5540\n",
      "Epoch 439/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5167\n",
      "Epoch 439: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5221 - val_loss: 86.5964\n",
      "Epoch 440/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4081\n",
      "Epoch 440: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4402 - val_loss: 82.2986\n",
      "Epoch 441/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6542\n",
      "Epoch 441: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5755 - val_loss: 86.5281\n",
      "Epoch 442/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4524\n",
      "Epoch 442: val_loss did not improve from 79.30244\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5399 - val_loss: 83.7427\n",
      "Epoch 443/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4396\n",
      "Epoch 443: val_loss improved from 79.30244 to 77.11640, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4396 - val_loss: 77.1164\n",
      "Epoch 444/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4817\n",
      "Epoch 444: val_loss did not improve from 77.11640\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4367 - val_loss: 86.3099\n",
      "Epoch 445/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8285\n",
      "Epoch 445: val_loss did not improve from 77.11640\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8409 - val_loss: 86.7221\n",
      "Epoch 446/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7111\n",
      "Epoch 446: val_loss did not improve from 77.11640\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6137 - val_loss: 80.1106\n",
      "Epoch 447/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8994\n",
      "Epoch 447: val_loss did not improve from 77.11640\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8273 - val_loss: 81.8816\n",
      "Epoch 448/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8877\n",
      "Epoch 448: val_loss did not improve from 77.11640\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8672 - val_loss: 93.6283\n",
      "Epoch 449/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6862\n",
      "Epoch 449: val_loss improved from 77.11640 to 76.93041, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6764 - val_loss: 76.9304\n",
      "Epoch 450/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5077\n",
      "Epoch 450: val_loss did not improve from 76.93041\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4926 - val_loss: 83.2304\n",
      "Epoch 451/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7219\n",
      "Epoch 451: val_loss did not improve from 76.93041\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7023 - val_loss: 79.0679\n",
      "Epoch 452/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4430\n",
      "Epoch 452: val_loss improved from 76.93041 to 73.60612, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4663 - val_loss: 73.6061\n",
      "Epoch 453/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7441\n",
      "Epoch 453: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6987 - val_loss: 76.0004\n",
      "Epoch 454/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3421\n",
      "Epoch 454: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3268 - val_loss: 77.7757\n",
      "Epoch 455/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3076\n",
      "Epoch 455: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3417 - val_loss: 78.6710\n",
      "Epoch 456/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4465\n",
      "Epoch 456: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4282 - val_loss: 77.4125\n",
      "Epoch 457/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6429\n",
      "Epoch 457: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5987 - val_loss: 82.1311\n",
      "Epoch 458/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5155\n",
      "Epoch 458: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5417 - val_loss: 82.1885\n",
      "Epoch 459/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.3645\n",
      "Epoch 459: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3644 - val_loss: 76.9878\n",
      "Epoch 460/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5421\n",
      "Epoch 460: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5324 - val_loss: 84.0144\n",
      "Epoch 461/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5647\n",
      "Epoch 461: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5486 - val_loss: 80.1109\n",
      "Epoch 462/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5787\n",
      "Epoch 462: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6221 - val_loss: 80.3528\n",
      "Epoch 463/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5799\n",
      "Epoch 463: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5799 - val_loss: 78.4872\n",
      "Epoch 464/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5698\n",
      "Epoch 464: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4901 - val_loss: 80.4376\n",
      "Epoch 465/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4391\n",
      "Epoch 465: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4235 - val_loss: 80.0789\n",
      "Epoch 466/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5819\n",
      "Epoch 466: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5600 - val_loss: 81.2801\n",
      "Epoch 467/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6295\n",
      "Epoch 467: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6163 - val_loss: 74.0603\n",
      "Epoch 468/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3541\n",
      "Epoch 468: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3682 - val_loss: 75.0401\n",
      "Epoch 469/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3890\n",
      "Epoch 469: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4442 - val_loss: 76.6485\n",
      "Epoch 470/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3070\n",
      "Epoch 470: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3451 - val_loss: 78.1963\n",
      "Epoch 471/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5560\n",
      "Epoch 471: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5781 - val_loss: 74.6423\n",
      "Epoch 472/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5975\n",
      "Epoch 472: val_loss did not improve from 73.60612\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6159 - val_loss: 81.7799\n",
      "Epoch 473/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5941\n",
      "Epoch 473: val_loss improved from 73.60612 to 73.16084, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6129 - val_loss: 73.1608\n",
      "Epoch 474/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9113\n",
      "Epoch 474: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8806 - val_loss: 86.9283\n",
      "Epoch 475/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4736\n",
      "Epoch 475: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4736 - val_loss: 79.0488\n",
      "Epoch 476/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3348\n",
      "Epoch 476: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5077 - val_loss: 79.5787\n",
      "Epoch 477/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6640\n",
      "Epoch 477: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6640 - val_loss: 78.7285\n",
      "Epoch 478/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4652\n",
      "Epoch 478: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4652 - val_loss: 75.9974\n",
      "Epoch 479/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5149\n",
      "Epoch 479: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4906 - val_loss: 73.5220\n",
      "Epoch 480/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4355\n",
      "Epoch 480: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4717 - val_loss: 75.2761\n",
      "Epoch 481/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3327\n",
      "Epoch 481: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3794 - val_loss: 73.7274\n",
      "Epoch 482/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3583\n",
      "Epoch 482: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3279 - val_loss: 75.1305\n",
      "Epoch 483/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4863\n",
      "Epoch 483: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4859 - val_loss: 75.3264\n",
      "Epoch 484/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7428\n",
      "Epoch 484: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7158 - val_loss: 82.0381\n",
      "Epoch 485/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6775\n",
      "Epoch 485: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.6524 - val_loss: 79.4886\n",
      "Epoch 486/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4306\n",
      "Epoch 486: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4655 - val_loss: 76.0991\n",
      "Epoch 487/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2614\n",
      "Epoch 487: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2480 - val_loss: 76.5376\n",
      "Epoch 488/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1746\n",
      "Epoch 488: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2520 - val_loss: 102.8675\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5078\n",
      "Epoch 489: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.5078 - val_loss: 98.7923\n",
      "Epoch 490/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3967\n",
      "Epoch 490: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3414 - val_loss: 93.4516\n",
      "Epoch 491/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8657\n",
      "Epoch 491: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.9343 - val_loss: 95.2671\n",
      "Epoch 492/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9957\n",
      "Epoch 492: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9957 - val_loss: 79.5231\n",
      "Epoch 493/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0631\n",
      "Epoch 493: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1003 - val_loss: 83.6893\n",
      "Epoch 494/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1759\n",
      "Epoch 494: val_loss did not improve from 73.16084\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1408 - val_loss: 74.0879\n",
      "Epoch 495/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7448\n",
      "Epoch 495: val_loss improved from 73.16084 to 67.85339, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7448 - val_loss: 67.8534\n",
      "Epoch 496/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6620\n",
      "Epoch 496: val_loss did not improve from 67.85339\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6620 - val_loss: 69.1774\n",
      "Epoch 497/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6063\n",
      "Epoch 497: val_loss did not improve from 67.85339\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5501 - val_loss: 72.3927\n",
      "Epoch 498/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5826\n",
      "Epoch 498: val_loss improved from 67.85339 to 67.22262, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6903 - val_loss: 67.2226\n",
      "Epoch 499/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6012\n",
      "Epoch 499: val_loss did not improve from 67.22262\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6489 - val_loss: 67.3596\n",
      "Epoch 500/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7533\n",
      "Epoch 500: val_loss did not improve from 67.22262\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7426 - val_loss: 72.5072\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6359\n",
      "Epoch 501: val_loss improved from 67.22262 to 66.97412, saving model to Best_LSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6359 - val_loss: 66.9741\n",
      "Epoch 502/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5621\n",
      "Epoch 502: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5943 - val_loss: 68.9395\n",
      "Epoch 503/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5829\n",
      "Epoch 503: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5403 - val_loss: 70.9577\n",
      "Epoch 504/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5407\n",
      "Epoch 504: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5407 - val_loss: 69.1916\n",
      "Epoch 505/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4994\n",
      "Epoch 505: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4986 - val_loss: 67.6136\n",
      "Epoch 506/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2971\n",
      "Epoch 506: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3079 - val_loss: 81.9652\n",
      "Epoch 507/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5363\n",
      "Epoch 507: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5363 - val_loss: 71.9599\n",
      "Epoch 508/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4701\n",
      "Epoch 508: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4566 - val_loss: 72.8467\n",
      "Epoch 509/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2763\n",
      "Epoch 509: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2936 - val_loss: 72.5333\n",
      "Epoch 510/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6234\n",
      "Epoch 510: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5584 - val_loss: 67.8041\n",
      "Epoch 511/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6944\n",
      "Epoch 511: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6767 - val_loss: 68.5869\n",
      "Epoch 512/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5600\n",
      "Epoch 512: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5359 - val_loss: 69.1598\n",
      "Epoch 513/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2244\n",
      "Epoch 513: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.2858 - val_loss: 71.6878\n",
      "Epoch 514/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2641\n",
      "Epoch 514: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2862 - val_loss: 71.4538\n",
      "Epoch 515/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4976\n",
      "Epoch 515: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4158 - val_loss: 72.7227\n",
      "Epoch 516/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1547\n",
      "Epoch 516: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2309 - val_loss: 76.2799\n",
      "Epoch 517/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.3441\n",
      "Epoch 517: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.3488 - val_loss: 74.7980\n",
      "Epoch 518/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5287\n",
      "Epoch 518: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.5481 - val_loss: 71.5583\n",
      "Epoch 519/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5483\n",
      "Epoch 519: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.5171 - val_loss: 68.1844\n",
      "Epoch 520/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5431\n",
      "Epoch 520: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4827 - val_loss: 71.3660\n",
      "Epoch 521/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2547\n",
      "Epoch 521: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2488 - val_loss: 75.0690\n",
      "Epoch 522/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7024\n",
      "Epoch 522: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7036 - val_loss: 76.7944\n",
      "Epoch 523/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6116\n",
      "Epoch 523: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5828 - val_loss: 78.1729\n",
      "Epoch 524/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2154\n",
      "Epoch 524: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2225 - val_loss: 75.7081\n",
      "Epoch 525/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2841\n",
      "Epoch 525: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3790 - val_loss: 78.5208\n",
      "Epoch 526/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2708\n",
      "Epoch 526: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2700 - val_loss: 81.0212\n",
      "Epoch 527/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.1934\n",
      "Epoch 527: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.2675 - val_loss: 71.6341\n",
      "Epoch 528/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.3343\n",
      "Epoch 528: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2972 - val_loss: 71.9376\n",
      "Epoch 529/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0776\n",
      "Epoch 529: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.1648 - val_loss: 71.0727\n",
      "Epoch 530/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1514\n",
      "Epoch 530: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2005 - val_loss: 73.9321\n",
      "Epoch 531/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4431\n",
      "Epoch 531: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4431 - val_loss: 74.6562\n",
      "Epoch 532/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3771\n",
      "Epoch 532: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3693 - val_loss: 74.6243\n",
      "Epoch 533/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.1799\n",
      "Epoch 533: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1799 - val_loss: 73.5966\n",
      "Epoch 534/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3463\n",
      "Epoch 534: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4198 - val_loss: 71.2976\n",
      "Epoch 535/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3935\n",
      "Epoch 535: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3935 - val_loss: 75.9003\n",
      "Epoch 536/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.2375\n",
      "Epoch 536: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2375 - val_loss: 73.0702\n",
      "Epoch 537/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2226\n",
      "Epoch 537: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3025 - val_loss: 71.4949\n",
      "Epoch 538/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5863\n",
      "Epoch 538: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5863 - val_loss: 71.5399\n",
      "Epoch 539/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4073\n",
      "Epoch 539: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.4091 - val_loss: 72.2739\n",
      "Epoch 540/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3451\n",
      "Epoch 540: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.3336 - val_loss: 75.4461\n",
      "Epoch 541/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4422\n",
      "Epoch 541: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.4422 - val_loss: 77.0859\n",
      "Epoch 542/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3363\n",
      "Epoch 542: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3520 - val_loss: 77.7602\n",
      "Epoch 543/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2205\n",
      "Epoch 543: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2077 - val_loss: 74.5212\n",
      "Epoch 544/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3523\n",
      "Epoch 544: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3463 - val_loss: 71.6660\n",
      "Epoch 545/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1944\n",
      "Epoch 545: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2083 - val_loss: 69.8443\n",
      "Epoch 546/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2113\n",
      "Epoch 546: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2144 - val_loss: 71.5651\n",
      "Epoch 547/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1103\n",
      "Epoch 547: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1110 - val_loss: 70.5105\n",
      "Epoch 548/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2096\n",
      "Epoch 548: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1917 - val_loss: 71.3139\n",
      "Epoch 549/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.1850\n",
      "Epoch 549: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.1464 - val_loss: 83.1591\n",
      "Epoch 550/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1184\n",
      "Epoch 550: val_loss did not improve from 66.97412\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1231 - val_loss: 73.9733\n",
      "Epoch 551/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2200\n",
      "Epoch 551: val_loss did not improve from 66.97412\n",
      "Restoring model weights from the end of the best epoch: 501.\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.2345 - val_loss: 67.8285\n",
      "Epoch 551: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "lstm_adam_model = TimeSeriesModel(model_type='lstm')\n",
    "# Training the model\n",
    "lstm_adam_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_LSTM_Model_ADAM_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3933d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = lstm_adam_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5eeb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.514209414520915\n",
      "R2 Score: 0.6078051228392574\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "548dd7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'LSTM - ADAM Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e435c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1772.6560\n",
      "Epoch 1: val_loss improved from inf to 7312.22119, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 4s 35ms/step - loss: 1729.2675 - val_loss: 7312.2212\n",
      "Epoch 2/1000\n",
      "11/37 [=======>......................] - ETA: 0s - loss: 1246.8459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/37 [===========================>..] - ETA: 0s - loss: 1346.1215\n",
      "Epoch 2: val_loss did not improve from 7312.22119\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1327.1902 - val_loss: 8092.1450\n",
      "Epoch 3/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1194.2075\n",
      "Epoch 3: val_loss improved from 7312.22119 to 3277.69507, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1184.5939 - val_loss: 3277.6951\n",
      "Epoch 4/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 557.2372\n",
      "Epoch 4: val_loss improved from 3277.69507 to 462.17197, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 489.0082 - val_loss: 462.1720\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 19.3009\n",
      "Epoch 5: val_loss improved from 462.17197 to 303.90161, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 19.3009 - val_loss: 303.9016\n",
      "Epoch 6/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 15.0513\n",
      "Epoch 6: val_loss improved from 303.90161 to 165.31134, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 14.9291 - val_loss: 165.3113\n",
      "Epoch 7/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.4920\n",
      "Epoch 7: val_loss did not improve from 165.31134\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.4018 - val_loss: 305.3103\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 17.0429\n",
      "Epoch 8: val_loss improved from 165.31134 to 133.09973, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 17.0429 - val_loss: 133.0997\n",
      "Epoch 9/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7548\n",
      "Epoch 9: val_loss improved from 133.09973 to 120.75627, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.6325 - val_loss: 120.7563\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9817\n",
      "Epoch 10: val_loss improved from 120.75627 to 86.98051, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 9.9817 - val_loss: 86.9805\n",
      "Epoch 11/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.6470 \n",
      "Epoch 11: val_loss improved from 86.98051 to 75.21713, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 9.1822 - val_loss: 75.2171\n",
      "Epoch 12/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8306\n",
      "Epoch 12: val_loss did not improve from 75.21713\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7870 - val_loss: 85.2718\n",
      "Epoch 13/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9383\n",
      "Epoch 13: val_loss did not improve from 75.21713\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9476 - val_loss: 77.1414\n",
      "Epoch 14/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8180\n",
      "Epoch 14: val_loss did not improve from 75.21713\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7408 - val_loss: 94.4860\n",
      "Epoch 15/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.9378\n",
      "Epoch 15: val_loss did not improve from 75.21713\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.2406 - val_loss: 115.5268\n",
      "Epoch 16/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4883\n",
      "Epoch 16: val_loss improved from 75.21713 to 61.50795, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5678 - val_loss: 61.5080\n",
      "Epoch 17/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.4260\n",
      "Epoch 17: val_loss did not improve from 61.50795\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.4032 - val_loss: 93.6277\n",
      "Epoch 18/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3145\n",
      "Epoch 18: val_loss improved from 61.50795 to 59.63807, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.2130 - val_loss: 59.6381\n",
      "Epoch 19/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0692\n",
      "Epoch 19: val_loss improved from 59.63807 to 58.02593, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.0025 - val_loss: 58.0259\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0319\n",
      "Epoch 20: val_loss improved from 58.02593 to 54.07628, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0319 - val_loss: 54.0763\n",
      "Epoch 21/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8149\n",
      "Epoch 21: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.1812 - val_loss: 65.1289\n",
      "Epoch 22/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1040\n",
      "Epoch 22: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1783 - val_loss: 62.2545\n",
      "Epoch 23/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.6278\n",
      "Epoch 23: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4750 - val_loss: 64.2610\n",
      "Epoch 24/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8851\n",
      "Epoch 24: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8587 - val_loss: 77.8975\n",
      "Epoch 25/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.2652\n",
      "Epoch 25: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.0413 - val_loss: 67.9838\n",
      "Epoch 26/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.2210\n",
      "Epoch 26: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1973 - val_loss: 55.7607\n",
      "Epoch 27/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.4875\n",
      "Epoch 27: val_loss did not improve from 54.07628\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.3267 - val_loss: 61.8210\n",
      "Epoch 28/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2914\n",
      "Epoch 28: val_loss improved from 54.07628 to 48.41357, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.2176 - val_loss: 48.4136\n",
      "Epoch 29/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6084\n",
      "Epoch 29: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.4745 - val_loss: 51.2567\n",
      "Epoch 30/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8200\n",
      "Epoch 30: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7599 - val_loss: 49.8165\n",
      "Epoch 31/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3276\n",
      "Epoch 31: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3955 - val_loss: 71.1005\n",
      "Epoch 32/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3518\n",
      "Epoch 32: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0315 - val_loss: 50.8696\n",
      "Epoch 33/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2978\n",
      "Epoch 33: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2170 - val_loss: 52.2847\n",
      "Epoch 34/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5607\n",
      "Epoch 34: val_loss did not improve from 48.41357\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4739 - val_loss: 52.5913\n",
      "Epoch 35/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5100\n",
      "Epoch 35: val_loss improved from 48.41357 to 43.85564, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5351 - val_loss: 43.8556\n",
      "Epoch 36/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.6609\n",
      "Epoch 36: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5666 - val_loss: 52.9183\n",
      "Epoch 37/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2140\n",
      "Epoch 37: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1366 - val_loss: 51.2608\n",
      "Epoch 38/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7923\n",
      "Epoch 38: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7712 - val_loss: 70.9139\n",
      "Epoch 39/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.3690\n",
      "Epoch 39: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.2262 - val_loss: 52.7609\n",
      "Epoch 40/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3016\n",
      "Epoch 40: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.2186 - val_loss: 55.5469\n",
      "Epoch 41/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5895\n",
      "Epoch 41: val_loss did not improve from 43.85564\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4.6651 - val_loss: 78.1509\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6980\n",
      "Epoch 42: val_loss improved from 43.85564 to 42.74129, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.7848 - val_loss: 42.7413\n",
      "Epoch 43/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5685\n",
      "Epoch 43: val_loss did not improve from 42.74129\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.5156 - val_loss: 49.6892\n",
      "Epoch 44/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9775\n",
      "Epoch 44: val_loss did not improve from 42.74129\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4.0378 - val_loss: 44.2822\n",
      "Epoch 45/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5963\n",
      "Epoch 45: val_loss improved from 42.74129 to 40.05478, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4871 - val_loss: 40.0548\n",
      "Epoch 46/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1933\n",
      "Epoch 46: val_loss did not improve from 40.05478\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1817 - val_loss: 42.0186\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1379\n",
      "Epoch 47: val_loss did not improve from 40.05478\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1379 - val_loss: 49.0274\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2412\n",
      "Epoch 48: val_loss improved from 40.05478 to 39.40477, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2412 - val_loss: 39.4048\n",
      "Epoch 49/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6037\n",
      "Epoch 49: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.5600 - val_loss: 46.9437\n",
      "Epoch 50/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2226\n",
      "Epoch 50: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.1681 - val_loss: 48.8887\n",
      "Epoch 51/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8820\n",
      "Epoch 51: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8119 - val_loss: 47.2984\n",
      "Epoch 52/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6293\n",
      "Epoch 52: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.6234 - val_loss: 46.6595\n",
      "Epoch 53/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7808\n",
      "Epoch 53: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7397 - val_loss: 47.4263\n",
      "Epoch 54/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.9013\n",
      "Epoch 54: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0945 - val_loss: 85.4256\n",
      "Epoch 55/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9643\n",
      "Epoch 55: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.8859 - val_loss: 44.8815\n",
      "Epoch 56/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2554\n",
      "Epoch 56: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1552 - val_loss: 39.6579\n",
      "Epoch 57/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3110\n",
      "Epoch 57: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2717 - val_loss: 43.9018\n",
      "Epoch 58/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3369\n",
      "Epoch 58: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3333 - val_loss: 52.7958\n",
      "Epoch 59/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1080\n",
      "Epoch 59: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9990 - val_loss: 47.6527\n",
      "Epoch 60/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1248\n",
      "Epoch 60: val_loss did not improve from 39.40477\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0655 - val_loss: 52.6855\n",
      "Epoch 61/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2455\n",
      "Epoch 61: val_loss improved from 39.40477 to 39.08888, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2166 - val_loss: 39.0889\n",
      "Epoch 62/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9913\n",
      "Epoch 62: val_loss did not improve from 39.08888\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8324 - val_loss: 44.9458\n",
      "Epoch 63/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8513\n",
      "Epoch 63: val_loss did not improve from 39.08888\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8004 - val_loss: 39.1901\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0880\n",
      "Epoch 64: val_loss did not improve from 39.08888\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0880 - val_loss: 42.6191\n",
      "Epoch 65/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.0344\n",
      "Epoch 65: val_loss did not improve from 39.08888\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0061 - val_loss: 42.3450\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7698\n",
      "Epoch 66: val_loss improved from 39.08888 to 38.78963, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7091 - val_loss: 38.7896\n",
      "Epoch 67/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3664\n",
      "Epoch 67: val_loss did not improve from 38.78963\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3006 - val_loss: 46.3871\n",
      "Epoch 68/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3020\n",
      "Epoch 68: val_loss did not improve from 38.78963\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1748 - val_loss: 39.8025\n",
      "Epoch 69/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1416\n",
      "Epoch 69: val_loss did not improve from 38.78963\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0982 - val_loss: 48.1593\n",
      "Epoch 70/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6960\n",
      "Epoch 70: val_loss improved from 38.78963 to 38.08374, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.6448 - val_loss: 38.0837\n",
      "Epoch 71/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0906\n",
      "Epoch 71: val_loss improved from 38.08374 to 36.93076, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1311 - val_loss: 36.9308\n",
      "Epoch 72/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5440\n",
      "Epoch 72: val_loss did not improve from 36.93076\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5214 - val_loss: 46.9383\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5697\n",
      "Epoch 73: val_loss did not improve from 36.93076\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5697 - val_loss: 50.7852\n",
      "Epoch 74/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2824\n",
      "Epoch 74: val_loss improved from 36.93076 to 33.70569, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2702 - val_loss: 33.7057\n",
      "Epoch 75/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9582\n",
      "Epoch 75: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0810 - val_loss: 35.6804\n",
      "Epoch 76/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5838\n",
      "Epoch 76: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6157 - val_loss: 46.0857\n",
      "Epoch 77/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3336\n",
      "Epoch 77: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3406 - val_loss: 40.6506\n",
      "Epoch 78/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3801\n",
      "Epoch 78: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3459 - val_loss: 53.4878\n",
      "Epoch 79/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0049\n",
      "Epoch 79: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0089 - val_loss: 37.7130\n",
      "Epoch 80/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9431\n",
      "Epoch 80: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9096 - val_loss: 38.6404\n",
      "Epoch 81/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0001\n",
      "Epoch 81: val_loss did not improve from 33.70569\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9877 - val_loss: 34.4683\n",
      "Epoch 82/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4433\n",
      "Epoch 82: val_loss improved from 33.70569 to 33.46666, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.4904 - val_loss: 33.4667\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5361\n",
      "Epoch 83: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5361 - val_loss: 49.5201\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0667\n",
      "Epoch 84: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0667 - val_loss: 37.5086\n",
      "Epoch 85/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.1982\n",
      "Epoch 85: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3121 - val_loss: 40.6772\n",
      "Epoch 86/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2997\n",
      "Epoch 86: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2854 - val_loss: 39.0608\n",
      "Epoch 87/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2174\n",
      "Epoch 87: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4.2327 - val_loss: 35.5130\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3846\n",
      "Epoch 88: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3846 - val_loss: 44.7604\n",
      "Epoch 89/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3411\n",
      "Epoch 89: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.3253 - val_loss: 35.8518\n",
      "Epoch 90/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.9294\n",
      "Epoch 90: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.9954 - val_loss: 33.4870\n",
      "Epoch 91/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.2416\n",
      "Epoch 91: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2217 - val_loss: 33.7422\n",
      "Epoch 92/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2528\n",
      "Epoch 92: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1811 - val_loss: 40.2219\n",
      "Epoch 93/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4927\n",
      "Epoch 93: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.4490 - val_loss: 43.5599\n",
      "Epoch 94/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1921\n",
      "Epoch 94: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.2255 - val_loss: 37.2293\n",
      "Epoch 95/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3939\n",
      "Epoch 95: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2305 - val_loss: 35.6750\n",
      "Epoch 96/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7139\n",
      "Epoch 96: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9065 - val_loss: 37.0543\n",
      "Epoch 97/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2253\n",
      "Epoch 97: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2695 - val_loss: 41.6710\n",
      "Epoch 98/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8218\n",
      "Epoch 98: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9675 - val_loss: 34.4267\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8922\n",
      "Epoch 99: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8922 - val_loss: 47.6670\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1775\n",
      "Epoch 100: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1775 - val_loss: 42.7648\n",
      "Epoch 101/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5968\n",
      "Epoch 101: val_loss did not improve from 33.46666\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5513 - val_loss: 42.2290\n",
      "Epoch 102/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1159\n",
      "Epoch 102: val_loss improved from 33.46666 to 33.44797, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1690 - val_loss: 33.4480\n",
      "Epoch 103/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1967\n",
      "Epoch 103: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1388 - val_loss: 39.2516\n",
      "Epoch 104/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1689\n",
      "Epoch 104: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1379 - val_loss: 41.7815\n",
      "Epoch 105/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1578\n",
      "Epoch 105: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1228 - val_loss: 39.5670\n",
      "Epoch 106/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3542\n",
      "Epoch 106: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4167 - val_loss: 53.3524\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4733\n",
      "Epoch 107: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4733 - val_loss: 88.6779\n",
      "Epoch 108/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3909\n",
      "Epoch 108: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3671 - val_loss: 38.3279\n",
      "Epoch 109/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0518\n",
      "Epoch 109: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0400 - val_loss: 38.2430\n",
      "Epoch 110/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6341\n",
      "Epoch 110: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5866 - val_loss: 41.1689\n",
      "Epoch 111/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4884\n",
      "Epoch 111: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4798 - val_loss: 53.2580\n",
      "Epoch 112/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1572\n",
      "Epoch 112: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1369 - val_loss: 34.0051\n",
      "Epoch 113/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6096\n",
      "Epoch 113: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7198 - val_loss: 61.5908\n",
      "Epoch 114/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3767\n",
      "Epoch 114: val_loss did not improve from 33.44797\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2786 - val_loss: 34.2754\n",
      "Epoch 115/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2372\n",
      "Epoch 115: val_loss improved from 33.44797 to 30.44891, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2872 - val_loss: 30.4489\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2357\n",
      "Epoch 116: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3004 - val_loss: 38.2802\n",
      "Epoch 117/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1996\n",
      "Epoch 117: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1540 - val_loss: 38.5384\n",
      "Epoch 118/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4784\n",
      "Epoch 118: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4436 - val_loss: 47.6003\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1717\n",
      "Epoch 119: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1717 - val_loss: 47.9567\n",
      "Epoch 120/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0882\n",
      "Epoch 120: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0782 - val_loss: 36.5175\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0200\n",
      "Epoch 121: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0200 - val_loss: 34.8190\n",
      "Epoch 122/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2022\n",
      "Epoch 122: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1935 - val_loss: 31.9451\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2141\n",
      "Epoch 123: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2141 - val_loss: 36.6041\n",
      "Epoch 124/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1903\n",
      "Epoch 124: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1702 - val_loss: 33.7223\n",
      "Epoch 125/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0244\n",
      "Epoch 125: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0541 - val_loss: 34.8279\n",
      "Epoch 126/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0050\n",
      "Epoch 126: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0071 - val_loss: 34.4231\n",
      "Epoch 127/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1941\n",
      "Epoch 127: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2936 - val_loss: 38.0932\n",
      "Epoch 128/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0070\n",
      "Epoch 128: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9881 - val_loss: 43.4911\n",
      "Epoch 129/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4289\n",
      "Epoch 129: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3774 - val_loss: 31.1522\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0833\n",
      "Epoch 130: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0833 - val_loss: 38.4122\n",
      "Epoch 131/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1608\n",
      "Epoch 131: val_loss did not improve from 30.44891\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0843 - val_loss: 50.2006\n",
      "Epoch 132/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5580\n",
      "Epoch 132: val_loss improved from 30.44891 to 29.72973, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5029 - val_loss: 29.7297\n",
      "Epoch 133/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4207\n",
      "Epoch 133: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.3156 - val_loss: 31.0939\n",
      "Epoch 134/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3540\n",
      "Epoch 134: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3378 - val_loss: 36.0212\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6584\n",
      "Epoch 135: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.6584 - val_loss: 30.2963\n",
      "Epoch 136/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2472\n",
      "Epoch 136: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1643 - val_loss: 42.5563\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0860\n",
      "Epoch 137: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0860 - val_loss: 52.2936\n",
      "Epoch 138/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3112\n",
      "Epoch 138: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3260 - val_loss: 34.7066\n",
      "Epoch 139/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6736\n",
      "Epoch 139: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5188 - val_loss: 33.6663\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1776\n",
      "Epoch 140: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1776 - val_loss: 31.1575\n",
      "Epoch 141/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3353\n",
      "Epoch 141: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3271 - val_loss: 31.5561\n",
      "Epoch 142/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4160\n",
      "Epoch 142: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4606 - val_loss: 36.4391\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2682\n",
      "Epoch 143: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2682 - val_loss: 33.8076\n",
      "Epoch 144/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0514\n",
      "Epoch 144: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1065 - val_loss: 31.8837\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2504\n",
      "Epoch 145: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2504 - val_loss: 34.0383\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3200\n",
      "Epoch 146: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3200 - val_loss: 31.1178\n",
      "Epoch 147/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8898\n",
      "Epoch 147: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1778 - val_loss: 38.9223\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3385\n",
      "Epoch 148: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3385 - val_loss: 32.9690\n",
      "Epoch 149/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0982\n",
      "Epoch 149: val_loss did not improve from 29.72973\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0026 - val_loss: 42.2315\n",
      "Epoch 150/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0099\n",
      "Epoch 150: val_loss improved from 29.72973 to 29.42399, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0631 - val_loss: 29.4240\n",
      "Epoch 151/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5139\n",
      "Epoch 151: val_loss did not improve from 29.42399\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4490 - val_loss: 37.7606\n",
      "Epoch 152/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8809\n",
      "Epoch 152: val_loss did not improve from 29.42399\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9270 - val_loss: 29.6500\n",
      "Epoch 153/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1916\n",
      "Epoch 153: val_loss improved from 29.42399 to 28.65857, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2279 - val_loss: 28.6586\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2421\n",
      "Epoch 154: val_loss did not improve from 28.65857\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2421 - val_loss: 44.8012\n",
      "Epoch 155/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4543\n",
      "Epoch 155: val_loss did not improve from 28.65857\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3317 - val_loss: 33.1390\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2804\n",
      "Epoch 156: val_loss did not improve from 28.65857\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2804 - val_loss: 32.3660\n",
      "Epoch 157/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9444\n",
      "Epoch 157: val_loss did not improve from 28.65857\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.9241 - val_loss: 31.7254\n",
      "Epoch 158/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2254\n",
      "Epoch 158: val_loss improved from 28.65857 to 28.48152, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1788 - val_loss: 28.4815\n",
      "Epoch 159/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0182\n",
      "Epoch 159: val_loss did not improve from 28.48152\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9853 - val_loss: 35.6935\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1053\n",
      "Epoch 160: val_loss did not improve from 28.48152\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1053 - val_loss: 32.2980\n",
      "Epoch 161/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1253\n",
      "Epoch 161: val_loss improved from 28.48152 to 27.34260, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2242 - val_loss: 27.3426\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9119\n",
      "Epoch 162: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9119 - val_loss: 33.9947\n",
      "Epoch 163/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0867\n",
      "Epoch 163: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1249 - val_loss: 35.2589\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2873\n",
      "Epoch 164: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2873 - val_loss: 30.6492\n",
      "Epoch 165/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9113\n",
      "Epoch 165: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9584 - val_loss: 32.6413\n",
      "Epoch 166/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0359\n",
      "Epoch 166: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0608 - val_loss: 42.7279\n",
      "Epoch 167/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9746\n",
      "Epoch 167: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9844 - val_loss: 31.5004\n",
      "Epoch 168/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8997\n",
      "Epoch 168: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 2.8940 - val_loss: 29.7675\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9474\n",
      "Epoch 169: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9474 - val_loss: 33.2042\n",
      "Epoch 170/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8090\n",
      "Epoch 170: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8863 - val_loss: 30.8800\n",
      "Epoch 171/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0208\n",
      "Epoch 171: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0771 - val_loss: 27.6180\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2852\n",
      "Epoch 172: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2852 - val_loss: 30.7805\n",
      "Epoch 173/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9542\n",
      "Epoch 173: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9996 - val_loss: 32.4180\n",
      "Epoch 174/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2625\n",
      "Epoch 174: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1682 - val_loss: 33.9235\n",
      "Epoch 175/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0479\n",
      "Epoch 175: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0113 - val_loss: 33.1563\n",
      "Epoch 176/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3360\n",
      "Epoch 176: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2901 - val_loss: 29.4364\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9691\n",
      "Epoch 177: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9691 - val_loss: 30.1849\n",
      "Epoch 178/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2208\n",
      "Epoch 178: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2014 - val_loss: 33.6828\n",
      "Epoch 179/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1998\n",
      "Epoch 179: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1974 - val_loss: 31.8826\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0323\n",
      "Epoch 180: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.0323 - val_loss: 30.6492\n",
      "Epoch 181/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9215\n",
      "Epoch 181: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8798 - val_loss: 35.9594\n",
      "Epoch 182/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4527\n",
      "Epoch 182: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2964 - val_loss: 30.0724\n",
      "Epoch 183/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1953\n",
      "Epoch 183: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1590 - val_loss: 31.6891\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0950\n",
      "Epoch 184: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0950 - val_loss: 27.6079\n",
      "Epoch 185/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2676\n",
      "Epoch 185: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2464 - val_loss: 34.0911\n",
      "Epoch 186/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9251\n",
      "Epoch 186: val_loss did not improve from 27.34260\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0975 - val_loss: 28.9437\n",
      "Epoch 187/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3654\n",
      "Epoch 187: val_loss improved from 27.34260 to 27.06268, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3945 - val_loss: 27.0627\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9839\n",
      "Epoch 188: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 2.9839 - val_loss: 30.7972\n",
      "Epoch 189/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9810\n",
      "Epoch 189: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9325 - val_loss: 29.5164\n",
      "Epoch 190/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.0755\n",
      "Epoch 190: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0443 - val_loss: 28.8851\n",
      "Epoch 191/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3497\n",
      "Epoch 191: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2662 - val_loss: 36.9673\n",
      "Epoch 192/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9838\n",
      "Epoch 192: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9509 - val_loss: 28.5082\n",
      "Epoch 193/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2981\n",
      "Epoch 193: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3876 - val_loss: 33.1776\n",
      "Epoch 194/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0110\n",
      "Epoch 194: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9707 - val_loss: 33.6897\n",
      "Epoch 195/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2364\n",
      "Epoch 195: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 3.1368 - val_loss: 32.4770\n",
      "Epoch 196/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0131\n",
      "Epoch 196: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0841 - val_loss: 32.4948\n",
      "Epoch 197/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9411\n",
      "Epoch 197: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9423 - val_loss: 39.8253\n",
      "Epoch 198/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8176\n",
      "Epoch 198: val_loss did not improve from 27.06268\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7662 - val_loss: 34.3032\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0835\n",
      "Epoch 199: val_loss improved from 27.06268 to 26.78157, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0835 - val_loss: 26.7816\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0168\n",
      "Epoch 200: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0168 - val_loss: 33.3227\n",
      "Epoch 201/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9978\n",
      "Epoch 201: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9432 - val_loss: 28.3945\n",
      "Epoch 202/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1249\n",
      "Epoch 202: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0404 - val_loss: 33.6650\n",
      "Epoch 203/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9973\n",
      "Epoch 203: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0040 - val_loss: 31.1563\n",
      "Epoch 204/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1997\n",
      "Epoch 204: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1268 - val_loss: 36.5707\n",
      "Epoch 205/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2297\n",
      "Epoch 205: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2323 - val_loss: 33.9602\n",
      "Epoch 206/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8852\n",
      "Epoch 206: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8640 - val_loss: 36.1722\n",
      "Epoch 207/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2422\n",
      "Epoch 207: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2114 - val_loss: 35.4293\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8953\n",
      "Epoch 208: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2.8953 - val_loss: 31.7952\n",
      "Epoch 209/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0543\n",
      "Epoch 209: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 3.0159 - val_loss: 29.3204\n",
      "Epoch 210/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8805\n",
      "Epoch 210: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9439 - val_loss: 39.8518\n",
      "Epoch 211/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0650\n",
      "Epoch 211: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0363 - val_loss: 37.8487\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9770\n",
      "Epoch 212: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9770 - val_loss: 29.3140\n",
      "Epoch 213/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9651\n",
      "Epoch 213: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8982 - val_loss: 28.2608\n",
      "Epoch 214/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0075\n",
      "Epoch 214: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9709 - val_loss: 27.4419\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1373\n",
      "Epoch 215: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1373 - val_loss: 30.2631\n",
      "Epoch 216/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9494\n",
      "Epoch 216: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9013 - val_loss: 28.8719\n",
      "Epoch 217/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2171\n",
      "Epoch 217: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2643 - val_loss: 34.1997\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0633\n",
      "Epoch 218: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0633 - val_loss: 29.5998\n",
      "Epoch 219/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8370\n",
      "Epoch 219: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8576 - val_loss: 41.1654\n",
      "Epoch 220/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0311\n",
      "Epoch 220: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0343 - val_loss: 29.4656\n",
      "Epoch 221/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1681\n",
      "Epoch 221: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1813 - val_loss: 29.2918\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1822\n",
      "Epoch 222: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.1822 - val_loss: 28.7640\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9151\n",
      "Epoch 223: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9151 - val_loss: 32.1739\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1283\n",
      "Epoch 224: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.1283 - val_loss: 31.5505\n",
      "Epoch 225/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9502\n",
      "Epoch 225: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9267 - val_loss: 27.5994\n",
      "Epoch 226/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0882\n",
      "Epoch 226: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.1144 - val_loss: 27.1899\n",
      "Epoch 227/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9186\n",
      "Epoch 227: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9204 - val_loss: 32.2057\n",
      "Epoch 228/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1376\n",
      "Epoch 228: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9995 - val_loss: 33.1541\n",
      "Epoch 229/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9370\n",
      "Epoch 229: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0852 - val_loss: 30.6190\n",
      "Epoch 230/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3548\n",
      "Epoch 230: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3184 - val_loss: 30.2033\n",
      "Epoch 231/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9047\n",
      "Epoch 231: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9169 - val_loss: 45.3668\n",
      "Epoch 232/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1320\n",
      "Epoch 232: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1344 - val_loss: 41.9136\n",
      "Epoch 233/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3216\n",
      "Epoch 233: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.3196 - val_loss: 30.6583\n",
      "Epoch 234/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6665\n",
      "Epoch 234: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5396 - val_loss: 35.8592\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9145\n",
      "Epoch 235: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9145 - val_loss: 34.6880\n",
      "Epoch 236/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9273\n",
      "Epoch 236: val_loss did not improve from 26.78157\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9150 - val_loss: 39.2420\n",
      "Epoch 237/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0979\n",
      "Epoch 237: val_loss improved from 26.78157 to 25.74780, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0601 - val_loss: 25.7478\n",
      "Epoch 238/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2978\n",
      "Epoch 238: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1554 - val_loss: 35.5468\n",
      "Epoch 239/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0587\n",
      "Epoch 239: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0388 - val_loss: 35.5748\n",
      "Epoch 240/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9318\n",
      "Epoch 240: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0015 - val_loss: 42.1401\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9478\n",
      "Epoch 241: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9478 - val_loss: 43.3292\n",
      "Epoch 242/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8335\n",
      "Epoch 242: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7861 - val_loss: 26.1418\n",
      "Epoch 243/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8269\n",
      "Epoch 243: val_loss did not improve from 25.74780\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8166 - val_loss: 25.8030\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8994\n",
      "Epoch 244: val_loss improved from 25.74780 to 25.64225, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8994 - val_loss: 25.6423\n",
      "Epoch 245/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0155\n",
      "Epoch 245: val_loss did not improve from 25.64225\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0235 - val_loss: 35.8898\n",
      "Epoch 246/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9325\n",
      "Epoch 246: val_loss did not improve from 25.64225\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9155 - val_loss: 34.8649\n",
      "Epoch 247/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9025\n",
      "Epoch 247: val_loss did not improve from 25.64225\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8750 - val_loss: 30.3947\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0860\n",
      "Epoch 248: val_loss did not improve from 25.64225\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0860 - val_loss: 34.5257\n",
      "Epoch 249/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.0537\n",
      "Epoch 249: val_loss did not improve from 25.64225\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0716 - val_loss: 27.1824\n",
      "Epoch 250/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0505\n",
      "Epoch 250: val_loss improved from 25.64225 to 25.62997, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0460 - val_loss: 25.6300\n",
      "Epoch 251/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9443\n",
      "Epoch 251: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8405 - val_loss: 38.1497\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2200\n",
      "Epoch 252: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.2200 - val_loss: 37.7014\n",
      "Epoch 253/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8707\n",
      "Epoch 253: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8266 - val_loss: 32.9764\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8650\n",
      "Epoch 254: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8650 - val_loss: 30.7186\n",
      "Epoch 255/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.1075\n",
      "Epoch 255: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9197 - val_loss: 30.1681\n",
      "Epoch 256/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8871\n",
      "Epoch 256: val_loss did not improve from 25.62997\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8845 - val_loss: 34.6044\n",
      "Epoch 257/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9466\n",
      "Epoch 257: val_loss improved from 25.62997 to 25.18581, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9433 - val_loss: 25.1858\n",
      "Epoch 258/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5017\n",
      "Epoch 258: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4513 - val_loss: 37.9018\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9370\n",
      "Epoch 259: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9370 - val_loss: 32.2497\n",
      "Epoch 260/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1477\n",
      "Epoch 260: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1091 - val_loss: 28.6979\n",
      "Epoch 261/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0714\n",
      "Epoch 261: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0250 - val_loss: 29.0510\n",
      "Epoch 262/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1419\n",
      "Epoch 262: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1389 - val_loss: 36.7407\n",
      "Epoch 263/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8668\n",
      "Epoch 263: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8595 - val_loss: 29.1350\n",
      "Epoch 264/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4331\n",
      "Epoch 264: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.4748 - val_loss: 26.5168\n",
      "Epoch 265/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9862\n",
      "Epoch 265: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9391 - val_loss: 27.7456\n",
      "Epoch 266/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7643\n",
      "Epoch 266: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8426 - val_loss: 32.2611\n",
      "Epoch 267/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0571\n",
      "Epoch 267: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0176 - val_loss: 32.3850\n",
      "Epoch 268/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8437\n",
      "Epoch 268: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0926 - val_loss: 34.9388\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8972\n",
      "Epoch 269: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8972 - val_loss: 32.2178\n",
      "Epoch 270/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9754\n",
      "Epoch 270: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9868 - val_loss: 32.4682\n",
      "Epoch 271/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9126\n",
      "Epoch 271: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9323 - val_loss: 27.4897\n",
      "Epoch 272/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9299\n",
      "Epoch 272: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9134 - val_loss: 33.6024\n",
      "Epoch 273/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9336\n",
      "Epoch 273: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8982 - val_loss: 33.8291\n",
      "Epoch 274/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9248\n",
      "Epoch 274: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8731 - val_loss: 31.4624\n",
      "Epoch 275/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.1065\n",
      "Epoch 275: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0266 - val_loss: 28.5366\n",
      "Epoch 276/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1263\n",
      "Epoch 276: val_loss did not improve from 25.18581\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0838 - val_loss: 29.7805\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9305\n",
      "Epoch 277: val_loss improved from 25.18581 to 24.31487, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9305 - val_loss: 24.3149\n",
      "Epoch 278/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8500\n",
      "Epoch 278: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0598 - val_loss: 29.7121\n",
      "Epoch 279/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0853\n",
      "Epoch 279: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9705 - val_loss: 26.5367\n",
      "Epoch 280/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8852\n",
      "Epoch 280: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9294 - val_loss: 26.3374\n",
      "Epoch 281/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9978\n",
      "Epoch 281: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8990 - val_loss: 28.9888\n",
      "Epoch 282/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9576\n",
      "Epoch 282: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9840 - val_loss: 26.7693\n",
      "Epoch 283/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7875\n",
      "Epoch 283: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0017 - val_loss: 29.2937\n",
      "Epoch 284/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.1415\n",
      "Epoch 284: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0639 - val_loss: 35.0753\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0265\n",
      "Epoch 285: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0265 - val_loss: 26.0168\n",
      "Epoch 286/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.0227\n",
      "Epoch 286: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0424 - val_loss: 29.9459\n",
      "Epoch 287/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0284\n",
      "Epoch 287: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.0944 - val_loss: 25.7311\n",
      "Epoch 288/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0855\n",
      "Epoch 288: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1239 - val_loss: 33.9798\n",
      "Epoch 289/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0992\n",
      "Epoch 289: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0083 - val_loss: 27.9541\n",
      "Epoch 290/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8085\n",
      "Epoch 290: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8282 - val_loss: 27.6087\n",
      "Epoch 291/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0169\n",
      "Epoch 291: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9682 - val_loss: 25.1280\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1255\n",
      "Epoch 292: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1255 - val_loss: 27.0220\n",
      "Epoch 293/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9381\n",
      "Epoch 293: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9702 - val_loss: 24.9145\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8666\n",
      "Epoch 294: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8666 - val_loss: 33.3650\n",
      "Epoch 295/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7809\n",
      "Epoch 295: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8764 - val_loss: 29.3598\n",
      "Epoch 296/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8094\n",
      "Epoch 296: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8136 - val_loss: 27.9036\n",
      "Epoch 297/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8288\n",
      "Epoch 297: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.7889 - val_loss: 30.7091\n",
      "Epoch 298/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0625\n",
      "Epoch 298: val_loss did not improve from 24.31487\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0263 - val_loss: 27.4338\n",
      "Epoch 299/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9085\n",
      "Epoch 299: val_loss improved from 24.31487 to 24.23083, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9245 - val_loss: 24.2308\n",
      "Epoch 300/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8531\n",
      "Epoch 300: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8445 - val_loss: 26.9673\n",
      "Epoch 301/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1088\n",
      "Epoch 301: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0739 - val_loss: 32.5406\n",
      "Epoch 302/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8095\n",
      "Epoch 302: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8071 - val_loss: 27.8007\n",
      "Epoch 303/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8040\n",
      "Epoch 303: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7590 - val_loss: 27.1249\n",
      "Epoch 304/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7926\n",
      "Epoch 304: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9254 - val_loss: 24.4994\n",
      "Epoch 305/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9541\n",
      "Epoch 305: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9546 - val_loss: 35.2798\n",
      "Epoch 306/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9794\n",
      "Epoch 306: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9241 - val_loss: 26.3681\n",
      "Epoch 307/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9543\n",
      "Epoch 307: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9574 - val_loss: 34.8467\n",
      "Epoch 308/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2994\n",
      "Epoch 308: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.2214 - val_loss: 27.3876\n",
      "Epoch 309/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9859\n",
      "Epoch 309: val_loss did not improve from 24.23083\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0641 - val_loss: 45.2449\n",
      "Epoch 310/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0852\n",
      "Epoch 310: val_loss improved from 24.23083 to 23.58992, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1226 - val_loss: 23.5899\n",
      "Epoch 311/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0178\n",
      "Epoch 311: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9556 - val_loss: 29.5403\n",
      "Epoch 312/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0471\n",
      "Epoch 312: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1654 - val_loss: 36.3150\n",
      "Epoch 313/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8340\n",
      "Epoch 313: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8544 - val_loss: 25.7911\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9849\n",
      "Epoch 314: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9849 - val_loss: 34.4822\n",
      "Epoch 315/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2548\n",
      "Epoch 315: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2014 - val_loss: 29.1288\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0610\n",
      "Epoch 316: val_loss did not improve from 23.58992\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0610 - val_loss: 28.7130\n",
      "Epoch 317/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9086\n",
      "Epoch 317: val_loss improved from 23.58992 to 22.82535, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9408 - val_loss: 22.8253\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0469\n",
      "Epoch 318: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0469 - val_loss: 24.8761\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0700\n",
      "Epoch 319: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0700 - val_loss: 28.8685\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9795\n",
      "Epoch 320: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9795 - val_loss: 27.4051\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1522\n",
      "Epoch 321: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1522 - val_loss: 35.3797\n",
      "Epoch 322/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9226\n",
      "Epoch 322: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9687 - val_loss: 30.0376\n",
      "Epoch 323/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7356\n",
      "Epoch 323: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6862 - val_loss: 28.5214\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9775\n",
      "Epoch 324: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9775 - val_loss: 44.7688\n",
      "Epoch 325/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9916\n",
      "Epoch 325: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9355 - val_loss: 25.1897\n",
      "Epoch 326/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0025\n",
      "Epoch 326: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9283 - val_loss: 29.3855\n",
      "Epoch 327/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9504\n",
      "Epoch 327: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9675 - val_loss: 36.5422\n",
      "Epoch 328/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8883\n",
      "Epoch 328: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8966 - val_loss: 30.4255\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7207\n",
      "Epoch 329: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7207 - val_loss: 24.4189\n",
      "Epoch 330/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9837\n",
      "Epoch 330: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0399 - val_loss: 27.3866\n",
      "Epoch 331/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9519\n",
      "Epoch 331: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8964 - val_loss: 36.0976\n",
      "Epoch 332/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9605\n",
      "Epoch 332: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8704 - val_loss: 28.4591\n",
      "Epoch 333/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8981\n",
      "Epoch 333: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8473 - val_loss: 34.9457\n",
      "Epoch 334/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8392\n",
      "Epoch 334: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8839 - val_loss: 27.9216\n",
      "Epoch 335/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0256\n",
      "Epoch 335: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.0630 - val_loss: 36.3762\n",
      "Epoch 336/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8440\n",
      "Epoch 336: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8914 - val_loss: 27.2128\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1051\n",
      "Epoch 337: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1051 - val_loss: 23.9231\n",
      "Epoch 338/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9176\n",
      "Epoch 338: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9420 - val_loss: 26.1415\n",
      "Epoch 339/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9288\n",
      "Epoch 339: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8743 - val_loss: 25.1334\n",
      "Epoch 340/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1082\n",
      "Epoch 340: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0553 - val_loss: 31.5141\n",
      "Epoch 341/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2379\n",
      "Epoch 341: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2100 - val_loss: 29.5056\n",
      "Epoch 342/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8390\n",
      "Epoch 342: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8496 - val_loss: 37.2241\n",
      "Epoch 343/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9387\n",
      "Epoch 343: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0039 - val_loss: 24.8079\n",
      "Epoch 344/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0574\n",
      "Epoch 344: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0702 - val_loss: 31.2340\n",
      "Epoch 345/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7501\n",
      "Epoch 345: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8568 - val_loss: 36.2098\n",
      "Epoch 346/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0319\n",
      "Epoch 346: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1828 - val_loss: 22.8841\n",
      "Epoch 347/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1569\n",
      "Epoch 347: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.1037 - val_loss: 25.1082\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8562\n",
      "Epoch 348: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8562 - val_loss: 29.4048\n",
      "Epoch 349/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8412\n",
      "Epoch 349: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8204 - val_loss: 27.2507\n",
      "Epoch 350/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9919\n",
      "Epoch 350: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9699 - val_loss: 26.3658\n",
      "Epoch 351/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8782\n",
      "Epoch 351: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9467 - val_loss: 27.4747\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0515\n",
      "Epoch 352: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0515 - val_loss: 24.7982\n",
      "Epoch 353/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1731\n",
      "Epoch 353: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1570 - val_loss: 35.0316\n",
      "Epoch 354/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9677\n",
      "Epoch 354: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9545 - val_loss: 24.8979\n",
      "Epoch 355/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8887\n",
      "Epoch 355: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7624 - val_loss: 32.4465\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9550\n",
      "Epoch 356: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9550 - val_loss: 24.1986\n",
      "Epoch 357/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8330\n",
      "Epoch 357: val_loss did not improve from 22.82535\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8027 - val_loss: 28.4805\n",
      "Epoch 358/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8016\n",
      "Epoch 358: val_loss improved from 22.82535 to 22.46926, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9011 - val_loss: 22.4693\n",
      "Epoch 359/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8241\n",
      "Epoch 359: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8821 - val_loss: 30.2611\n",
      "Epoch 360/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9050\n",
      "Epoch 360: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8516 - val_loss: 28.9686\n",
      "Epoch 361/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.0728\n",
      "Epoch 361: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0958 - val_loss: 34.2006\n",
      "Epoch 362/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1080\n",
      "Epoch 362: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0761 - val_loss: 22.6021\n",
      "Epoch 363/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9750\n",
      "Epoch 363: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0140 - val_loss: 26.7871\n",
      "Epoch 364/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9397\n",
      "Epoch 364: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9559 - val_loss: 22.7468\n",
      "Epoch 365/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8841\n",
      "Epoch 365: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.8740 - val_loss: 27.4480\n",
      "Epoch 366/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8717\n",
      "Epoch 366: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9233 - val_loss: 24.7235\n",
      "Epoch 367/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8264\n",
      "Epoch 367: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8692 - val_loss: 24.6614\n",
      "Epoch 368/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0863\n",
      "Epoch 368: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0707 - val_loss: 32.5395\n",
      "Epoch 369/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8854\n",
      "Epoch 369: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9384 - val_loss: 24.9252\n",
      "Epoch 370/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8726\n",
      "Epoch 370: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8885 - val_loss: 31.7097\n",
      "Epoch 371/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9883\n",
      "Epoch 371: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0167 - val_loss: 26.7404\n",
      "Epoch 372/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7520\n",
      "Epoch 372: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7641 - val_loss: 35.5636\n",
      "Epoch 373/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2119\n",
      "Epoch 373: val_loss did not improve from 22.46926\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1784 - val_loss: 37.2086\n",
      "Epoch 374/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8964\n",
      "Epoch 374: val_loss improved from 22.46926 to 22.19068, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9579 - val_loss: 22.1907\n",
      "Epoch 375/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0693\n",
      "Epoch 375: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0673 - val_loss: 34.4594\n",
      "Epoch 376/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1154\n",
      "Epoch 376: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0761 - val_loss: 24.9088\n",
      "Epoch 377/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0045\n",
      "Epoch 377: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9686 - val_loss: 29.6286\n",
      "Epoch 378/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8215\n",
      "Epoch 378: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8238 - val_loss: 23.3597\n",
      "Epoch 379/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8236\n",
      "Epoch 379: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7571 - val_loss: 31.4720\n",
      "Epoch 380/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9041\n",
      "Epoch 380: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8700 - val_loss: 28.2191\n",
      "Epoch 381/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0865\n",
      "Epoch 381: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1055 - val_loss: 28.0670\n",
      "Epoch 382/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7197\n",
      "Epoch 382: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9067 - val_loss: 23.6921\n",
      "Epoch 383/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8875\n",
      "Epoch 383: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8548 - val_loss: 27.0571\n",
      "Epoch 384/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0272\n",
      "Epoch 384: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0092 - val_loss: 26.1024\n",
      "Epoch 385/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9833\n",
      "Epoch 385: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9980 - val_loss: 38.1352\n",
      "Epoch 386/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0701\n",
      "Epoch 386: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0715 - val_loss: 24.0209\n",
      "Epoch 387/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1734\n",
      "Epoch 387: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0338 - val_loss: 26.3969\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0216\n",
      "Epoch 388: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0216 - val_loss: 24.3426\n",
      "Epoch 389/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8717\n",
      "Epoch 389: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7680 - val_loss: 28.0235\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8317\n",
      "Epoch 390: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8317 - val_loss: 22.7183\n",
      "Epoch 391/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9275\n",
      "Epoch 391: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8979 - val_loss: 24.9835\n",
      "Epoch 392/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8580\n",
      "Epoch 392: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7795 - val_loss: 23.6989\n",
      "Epoch 393/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8249\n",
      "Epoch 393: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9000 - val_loss: 24.0707\n",
      "Epoch 394/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8287\n",
      "Epoch 394: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8153 - val_loss: 29.0410\n",
      "Epoch 395/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9811\n",
      "Epoch 395: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9660 - val_loss: 31.4761\n",
      "Epoch 396/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8195\n",
      "Epoch 396: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7998 - val_loss: 24.5100\n",
      "Epoch 397/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0951\n",
      "Epoch 397: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0584 - val_loss: 30.9086\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7018\n",
      "Epoch 398: val_loss did not improve from 22.19068\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7018 - val_loss: 25.2797\n",
      "Epoch 399/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8410\n",
      "Epoch 399: val_loss improved from 22.19068 to 21.85882, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8478 - val_loss: 21.8588\n",
      "Epoch 400/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7336\n",
      "Epoch 400: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6877 - val_loss: 25.3655\n",
      "Epoch 401/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8481\n",
      "Epoch 401: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.9188 - val_loss: 24.6707\n",
      "Epoch 402/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9853\n",
      "Epoch 402: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9558 - val_loss: 27.3400\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8104\n",
      "Epoch 403: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8104 - val_loss: 23.2658\n",
      "Epoch 404/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8888\n",
      "Epoch 404: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8278 - val_loss: 22.0060\n",
      "Epoch 405/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6385\n",
      "Epoch 405: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7142 - val_loss: 23.5627\n",
      "Epoch 406/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7560\n",
      "Epoch 406: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7987 - val_loss: 23.2443\n",
      "Epoch 407/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7846\n",
      "Epoch 407: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7880 - val_loss: 23.1346\n",
      "Epoch 408/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9550\n",
      "Epoch 408: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9916 - val_loss: 24.7471\n",
      "Epoch 409/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8329\n",
      "Epoch 409: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7877 - val_loss: 37.1861\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9457\n",
      "Epoch 410: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9457 - val_loss: 24.2700\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8781\n",
      "Epoch 411: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8781 - val_loss: 24.9857\n",
      "Epoch 412/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8045\n",
      "Epoch 412: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8516 - val_loss: 23.3229\n",
      "Epoch 413/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8742\n",
      "Epoch 413: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8078 - val_loss: 30.2957\n",
      "Epoch 414/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7122\n",
      "Epoch 414: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7620 - val_loss: 24.5249\n",
      "Epoch 415/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8782\n",
      "Epoch 415: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8968 - val_loss: 22.6895\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8398\n",
      "Epoch 416: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8398 - val_loss: 25.1510\n",
      "Epoch 417/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7141\n",
      "Epoch 417: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7487 - val_loss: 26.2204\n",
      "Epoch 418/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9240\n",
      "Epoch 418: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9496 - val_loss: 22.9407\n",
      "Epoch 419/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8738\n",
      "Epoch 419: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8877 - val_loss: 30.9342\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0738\n",
      "Epoch 420: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0738 - val_loss: 30.7166\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7435\n",
      "Epoch 421: val_loss did not improve from 21.85882\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7435 - val_loss: 26.7481\n",
      "Epoch 422/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7677\n",
      "Epoch 422: val_loss improved from 21.85882 to 20.99080, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8907 - val_loss: 20.9908\n",
      "Epoch 423/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9448\n",
      "Epoch 423: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9025 - val_loss: 27.2480\n",
      "Epoch 424/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0219\n",
      "Epoch 424: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0005 - val_loss: 25.8508\n",
      "Epoch 425/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7218\n",
      "Epoch 425: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7845 - val_loss: 21.3367\n",
      "Epoch 426/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7732\n",
      "Epoch 426: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7683 - val_loss: 24.8333\n",
      "Epoch 427/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7056\n",
      "Epoch 427: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7039 - val_loss: 24.0832\n",
      "Epoch 428/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7837\n",
      "Epoch 428: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7988 - val_loss: 22.2861\n",
      "Epoch 429/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9020\n",
      "Epoch 429: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9391 - val_loss: 24.3136\n",
      "Epoch 430/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9410\n",
      "Epoch 430: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9427 - val_loss: 21.3634\n",
      "Epoch 431/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6065\n",
      "Epoch 431: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7543 - val_loss: 39.7736\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9155\n",
      "Epoch 432: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.9155 - val_loss: 25.6402\n",
      "Epoch 433/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8061\n",
      "Epoch 433: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8233 - val_loss: 30.7135\n",
      "Epoch 434/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8594\n",
      "Epoch 434: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8462 - val_loss: 22.5709\n",
      "Epoch 435/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9483\n",
      "Epoch 435: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9317 - val_loss: 25.1856\n",
      "Epoch 436/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7711\n",
      "Epoch 436: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7457 - val_loss: 23.2361\n",
      "Epoch 437/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8277\n",
      "Epoch 437: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7682 - val_loss: 27.2195\n",
      "Epoch 438/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9328\n",
      "Epoch 438: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9310 - val_loss: 24.0945\n",
      "Epoch 439/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0321\n",
      "Epoch 439: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0375 - val_loss: 21.4644\n",
      "Epoch 440/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9242\n",
      "Epoch 440: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8963 - val_loss: 22.0193\n",
      "Epoch 441/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8770\n",
      "Epoch 441: val_loss did not improve from 20.99080\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8182 - val_loss: 25.9926\n",
      "Epoch 442/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7649\n",
      "Epoch 442: val_loss improved from 20.99080 to 20.72227, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7447 - val_loss: 20.7223\n",
      "Epoch 443/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8310\n",
      "Epoch 443: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7937 - val_loss: 27.1167\n",
      "Epoch 444/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8513\n",
      "Epoch 444: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8170 - val_loss: 31.3815\n",
      "Epoch 445/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7769\n",
      "Epoch 445: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8406 - val_loss: 24.0566\n",
      "Epoch 446/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9677\n",
      "Epoch 446: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9021 - val_loss: 24.2369\n",
      "Epoch 447/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9653\n",
      "Epoch 447: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8372 - val_loss: 24.6366\n",
      "Epoch 448/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9720\n",
      "Epoch 448: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9371 - val_loss: 23.5156\n",
      "Epoch 449/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7464\n",
      "Epoch 449: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7464 - val_loss: 22.5784\n",
      "Epoch 450/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8349\n",
      "Epoch 450: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8144 - val_loss: 25.8721\n",
      "Epoch 451/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9653\n",
      "Epoch 451: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8304 - val_loss: 25.7070\n",
      "Epoch 452/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0017\n",
      "Epoch 452: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8947 - val_loss: 22.3974\n",
      "Epoch 453/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8260\n",
      "Epoch 453: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8123 - val_loss: 26.3636\n",
      "Epoch 454/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8759\n",
      "Epoch 454: val_loss did not improve from 20.72227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7771 - val_loss: 24.4494\n",
      "Epoch 455/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0574\n",
      "Epoch 455: val_loss improved from 20.72227 to 20.70502, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9626 - val_loss: 20.7050\n",
      "Epoch 456/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8241\n",
      "Epoch 456: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8341 - val_loss: 26.4561\n",
      "Epoch 457/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8417\n",
      "Epoch 457: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8076 - val_loss: 22.0338\n",
      "Epoch 458/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8913\n",
      "Epoch 458: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8913 - val_loss: 24.5282\n",
      "Epoch 459/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7117\n",
      "Epoch 459: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7187 - val_loss: 21.6003\n",
      "Epoch 460/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9964\n",
      "Epoch 460: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0066 - val_loss: 33.8058\n",
      "Epoch 461/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9817\n",
      "Epoch 461: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0361 - val_loss: 24.0855\n",
      "Epoch 462/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7862\n",
      "Epoch 462: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7905 - val_loss: 20.7792\n",
      "Epoch 463/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7192\n",
      "Epoch 463: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7969 - val_loss: 23.8103\n",
      "Epoch 464/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8408\n",
      "Epoch 464: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7670 - val_loss: 22.9681\n",
      "Epoch 465/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9746\n",
      "Epoch 465: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9456 - val_loss: 21.4227\n",
      "Epoch 466/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6862\n",
      "Epoch 466: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7106 - val_loss: 34.2524\n",
      "Epoch 467/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7787\n",
      "Epoch 467: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8565 - val_loss: 21.2835\n",
      "Epoch 468/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9864\n",
      "Epoch 468: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9624 - val_loss: 26.2433\n",
      "Epoch 469/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8334\n",
      "Epoch 469: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8692 - val_loss: 26.4629\n",
      "Epoch 470/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7641\n",
      "Epoch 470: val_loss did not improve from 20.70502\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7641 - val_loss: 21.6743\n",
      "Epoch 471/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7105\n",
      "Epoch 471: val_loss improved from 20.70502 to 20.63788, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7996 - val_loss: 20.6379\n",
      "Epoch 472/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8835\n",
      "Epoch 472: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8849 - val_loss: 22.2378\n",
      "Epoch 473/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1278\n",
      "Epoch 473: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0401 - val_loss: 24.4133\n",
      "Epoch 474/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7348\n",
      "Epoch 474: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8545 - val_loss: 22.3886\n",
      "Epoch 475/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9375\n",
      "Epoch 475: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9131 - val_loss: 21.6766\n",
      "Epoch 476/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7944\n",
      "Epoch 476: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8339 - val_loss: 26.6313\n",
      "Epoch 477/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8413\n",
      "Epoch 477: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8332 - val_loss: 22.3228\n",
      "Epoch 478/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7484\n",
      "Epoch 478: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7484 - val_loss: 26.9243\n",
      "Epoch 479/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9546\n",
      "Epoch 479: val_loss did not improve from 20.63788\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9068 - val_loss: 22.0703\n",
      "Epoch 480/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6308\n",
      "Epoch 480: val_loss improved from 20.63788 to 19.99314, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7122 - val_loss: 19.9931\n",
      "Epoch 481/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8521\n",
      "Epoch 481: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8426 - val_loss: 27.8776\n",
      "Epoch 482/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8609\n",
      "Epoch 482: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8238 - val_loss: 28.9105\n",
      "Epoch 483/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6947\n",
      "Epoch 483: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7052 - val_loss: 23.5439\n",
      "Epoch 484/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8584\n",
      "Epoch 484: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0626 - val_loss: 22.8468\n",
      "Epoch 485/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6978\n",
      "Epoch 485: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6661 - val_loss: 24.8438\n",
      "Epoch 486/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7787\n",
      "Epoch 486: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7937 - val_loss: 26.2715\n",
      "Epoch 487/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8266\n",
      "Epoch 487: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.8092 - val_loss: 22.5601\n",
      "Epoch 488/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8857\n",
      "Epoch 488: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8858 - val_loss: 29.9091\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8370\n",
      "Epoch 489: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8370 - val_loss: 21.0738\n",
      "Epoch 490/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8269\n",
      "Epoch 490: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7717 - val_loss: 21.6113\n",
      "Epoch 491/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6341\n",
      "Epoch 491: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7392 - val_loss: 22.0532\n",
      "Epoch 492/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8122\n",
      "Epoch 492: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8412 - val_loss: 30.4565\n",
      "Epoch 493/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7903\n",
      "Epoch 493: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7725 - val_loss: 26.8550\n",
      "Epoch 494/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7986\n",
      "Epoch 494: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7882 - val_loss: 20.2304\n",
      "Epoch 495/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7146\n",
      "Epoch 495: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7192 - val_loss: 23.3817\n",
      "Epoch 496/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7548\n",
      "Epoch 496: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8250 - val_loss: 22.0270\n",
      "Epoch 497/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7633\n",
      "Epoch 497: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7187 - val_loss: 23.8774\n",
      "Epoch 498/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8619\n",
      "Epoch 498: val_loss did not improve from 19.99314\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9207 - val_loss: 34.5185\n",
      "Epoch 499/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8344\n",
      "Epoch 499: val_loss improved from 19.99314 to 19.53149, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9250 - val_loss: 19.5315\n",
      "Epoch 500/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8439\n",
      "Epoch 500: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8439 - val_loss: 23.5936\n",
      "Epoch 501/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8001\n",
      "Epoch 501: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8708 - val_loss: 24.5530\n",
      "Epoch 502/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8390\n",
      "Epoch 502: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8406 - val_loss: 35.9443\n",
      "Epoch 503/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8259\n",
      "Epoch 503: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7780 - val_loss: 23.4197\n",
      "Epoch 504/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7123\n",
      "Epoch 504: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7839 - val_loss: 31.0685\n",
      "Epoch 505/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0122\n",
      "Epoch 505: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0122 - val_loss: 28.8595\n",
      "Epoch 506/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8332\n",
      "Epoch 506: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7789 - val_loss: 30.0273\n",
      "Epoch 507/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8088\n",
      "Epoch 507: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7829 - val_loss: 24.8891\n",
      "Epoch 508/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9100\n",
      "Epoch 508: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8985 - val_loss: 28.2782\n",
      "Epoch 509/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7065\n",
      "Epoch 509: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7441 - val_loss: 24.0991\n",
      "Epoch 510/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8920\n",
      "Epoch 510: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8364 - val_loss: 23.7731\n",
      "Epoch 511/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8718\n",
      "Epoch 511: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8091 - val_loss: 21.5800\n",
      "Epoch 512/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7647\n",
      "Epoch 512: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7647 - val_loss: 21.5290\n",
      "Epoch 513/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6264\n",
      "Epoch 513: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7152 - val_loss: 19.9804\n",
      "Epoch 514/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8103\n",
      "Epoch 514: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8422 - val_loss: 32.5428\n",
      "Epoch 515/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8433\n",
      "Epoch 515: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7850 - val_loss: 25.4078\n",
      "Epoch 516/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6525\n",
      "Epoch 516: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7271 - val_loss: 22.2492\n",
      "Epoch 517/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7716\n",
      "Epoch 517: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7716 - val_loss: 21.4936\n",
      "Epoch 518/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7329\n",
      "Epoch 518: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7558 - val_loss: 22.8167\n",
      "Epoch 519/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7011\n",
      "Epoch 519: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7562 - val_loss: 22.1419\n",
      "Epoch 520/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7768\n",
      "Epoch 520: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7768 - val_loss: 21.7400\n",
      "Epoch 521/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8505\n",
      "Epoch 521: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8476 - val_loss: 21.5203\n",
      "Epoch 522/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9621\n",
      "Epoch 522: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9147 - val_loss: 31.9972\n",
      "Epoch 523/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8996\n",
      "Epoch 523: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8827 - val_loss: 27.2020\n",
      "Epoch 524/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8031\n",
      "Epoch 524: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8056 - val_loss: 29.7132\n",
      "Epoch 525/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6909\n",
      "Epoch 525: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7307 - val_loss: 21.6381\n",
      "Epoch 526/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7258\n",
      "Epoch 526: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7157 - val_loss: 24.6394\n",
      "Epoch 527/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8724\n",
      "Epoch 527: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8843 - val_loss: 22.8215\n",
      "Epoch 528/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7852\n",
      "Epoch 528: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7870 - val_loss: 22.2355\n",
      "Epoch 529/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7993\n",
      "Epoch 529: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8654 - val_loss: 20.3301\n",
      "Epoch 530/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8613\n",
      "Epoch 530: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8932 - val_loss: 23.6118\n",
      "Epoch 531/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7758\n",
      "Epoch 531: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7758 - val_loss: 31.8809\n",
      "Epoch 532/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8218\n",
      "Epoch 532: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8289 - val_loss: 22.3750\n",
      "Epoch 533/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7688\n",
      "Epoch 533: val_loss did not improve from 19.53149\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7688 - val_loss: 31.4352\n",
      "Epoch 534/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6908\n",
      "Epoch 534: val_loss improved from 19.53149 to 19.52642, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6960 - val_loss: 19.5264\n",
      "Epoch 535/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8728\n",
      "Epoch 535: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7589 - val_loss: 22.8555\n",
      "Epoch 536/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8708\n",
      "Epoch 536: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8313 - val_loss: 23.7054\n",
      "Epoch 537/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7987\n",
      "Epoch 537: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7414 - val_loss: 23.2284\n",
      "Epoch 538/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9169\n",
      "Epoch 538: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9169 - val_loss: 22.4523\n",
      "Epoch 539/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7015\n",
      "Epoch 539: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7311 - val_loss: 22.6199\n",
      "Epoch 540/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7927\n",
      "Epoch 540: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7283 - val_loss: 22.0460\n",
      "Epoch 541/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7421\n",
      "Epoch 541: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7889 - val_loss: 24.3089\n",
      "Epoch 542/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8778\n",
      "Epoch 542: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8667 - val_loss: 32.1574\n",
      "Epoch 543/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8094\n",
      "Epoch 543: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8099 - val_loss: 22.7323\n",
      "Epoch 544/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9221\n",
      "Epoch 544: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9637 - val_loss: 25.1195\n",
      "Epoch 545/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8384\n",
      "Epoch 545: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8233 - val_loss: 20.6170\n",
      "Epoch 546/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0033\n",
      "Epoch 546: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9622 - val_loss: 20.7308\n",
      "Epoch 547/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7545\n",
      "Epoch 547: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8641 - val_loss: 21.8220\n",
      "Epoch 548/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8419\n",
      "Epoch 548: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8142 - val_loss: 23.9925\n",
      "Epoch 549/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8915\n",
      "Epoch 549: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8625 - val_loss: 25.8741\n",
      "Epoch 550/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8988\n",
      "Epoch 550: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8634 - val_loss: 27.5670\n",
      "Epoch 551/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6854\n",
      "Epoch 551: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7487 - val_loss: 31.2437\n",
      "Epoch 552/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9407\n",
      "Epoch 552: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8975 - val_loss: 24.4018\n",
      "Epoch 553/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7549\n",
      "Epoch 553: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7434 - val_loss: 22.5191\n",
      "Epoch 554/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8041\n",
      "Epoch 554: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7936 - val_loss: 21.7600\n",
      "Epoch 555/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7264\n",
      "Epoch 555: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6918 - val_loss: 24.5245\n",
      "Epoch 556/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7211\n",
      "Epoch 556: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7383 - val_loss: 31.0914\n",
      "Epoch 557/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8047\n",
      "Epoch 557: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8449 - val_loss: 22.8911\n",
      "Epoch 558/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7720\n",
      "Epoch 558: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7232 - val_loss: 21.0090\n",
      "Epoch 559/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6825\n",
      "Epoch 559: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7343 - val_loss: 21.0078\n",
      "Epoch 560/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8097\n",
      "Epoch 560: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8064 - val_loss: 21.7756\n",
      "Epoch 561/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9619\n",
      "Epoch 561: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9719 - val_loss: 23.0845\n",
      "Epoch 562/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8337\n",
      "Epoch 562: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8337 - val_loss: 24.1269\n",
      "Epoch 563/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7306\n",
      "Epoch 563: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7306 - val_loss: 23.6253\n",
      "Epoch 564/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7667\n",
      "Epoch 564: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8260 - val_loss: 23.9321\n",
      "Epoch 565/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7375\n",
      "Epoch 565: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7544 - val_loss: 24.8681\n",
      "Epoch 566/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5874\n",
      "Epoch 566: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6711 - val_loss: 20.7944\n",
      "Epoch 567/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9537\n",
      "Epoch 567: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9774 - val_loss: 22.9979\n",
      "Epoch 568/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8123\n",
      "Epoch 568: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8123 - val_loss: 25.7258\n",
      "Epoch 569/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8948\n",
      "Epoch 569: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8042 - val_loss: 25.1328\n",
      "Epoch 570/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7237\n",
      "Epoch 570: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7237 - val_loss: 23.0591\n",
      "Epoch 571/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6199\n",
      "Epoch 571: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6199 - val_loss: 25.3922\n",
      "Epoch 572/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6465\n",
      "Epoch 572: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6465 - val_loss: 28.3885\n",
      "Epoch 573/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7298\n",
      "Epoch 573: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7298 - val_loss: 22.5572\n",
      "Epoch 574/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7567\n",
      "Epoch 574: val_loss did not improve from 19.52642\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7567 - val_loss: 20.4540\n",
      "Epoch 575/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8142\n",
      "Epoch 575: val_loss improved from 19.52642 to 19.49554, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7284 - val_loss: 19.4955\n",
      "Epoch 576/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8654\n",
      "Epoch 576: val_loss did not improve from 19.49554\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7744 - val_loss: 22.9891\n",
      "Epoch 577/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7175\n",
      "Epoch 577: val_loss did not improve from 19.49554\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6401 - val_loss: 24.4203\n",
      "Epoch 578/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7375\n",
      "Epoch 578: val_loss improved from 19.49554 to 19.34874, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6770 - val_loss: 19.3487\n",
      "Epoch 579/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7464\n",
      "Epoch 579: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7792 - val_loss: 25.0752\n",
      "Epoch 580/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8690\n",
      "Epoch 580: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8397 - val_loss: 21.0644\n",
      "Epoch 581/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8670\n",
      "Epoch 581: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8011 - val_loss: 25.7480\n",
      "Epoch 582/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6335\n",
      "Epoch 582: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7448 - val_loss: 31.9073\n",
      "Epoch 583/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6374\n",
      "Epoch 583: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7463 - val_loss: 20.3327\n",
      "Epoch 584/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7547\n",
      "Epoch 584: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7127 - val_loss: 21.2634\n",
      "Epoch 585/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9564\n",
      "Epoch 585: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9092 - val_loss: 20.7809\n",
      "Epoch 586/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7841\n",
      "Epoch 586: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7708 - val_loss: 22.5019\n",
      "Epoch 587/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8341\n",
      "Epoch 587: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8341 - val_loss: 25.6939\n",
      "Epoch 588/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7789\n",
      "Epoch 588: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7744 - val_loss: 20.5683\n",
      "Epoch 589/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9567\n",
      "Epoch 589: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9223 - val_loss: 20.1903\n",
      "Epoch 590/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6401\n",
      "Epoch 590: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.6450 - val_loss: 21.7140\n",
      "Epoch 591/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7736\n",
      "Epoch 591: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7736 - val_loss: 19.6607\n",
      "Epoch 592/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7724\n",
      "Epoch 592: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7724 - val_loss: 33.3415\n",
      "Epoch 593/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7898\n",
      "Epoch 593: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7898 - val_loss: 19.6929\n",
      "Epoch 594/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7012\n",
      "Epoch 594: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7542 - val_loss: 20.0859\n",
      "Epoch 595/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7209\n",
      "Epoch 595: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7424 - val_loss: 24.5669\n",
      "Epoch 596/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5594\n",
      "Epoch 596: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6596 - val_loss: 22.3506\n",
      "Epoch 597/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7695\n",
      "Epoch 597: val_loss did not improve from 19.34874\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9666 - val_loss: 27.3423\n",
      "Epoch 598/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7941\n",
      "Epoch 598: val_loss improved from 19.34874 to 19.30563, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7424 - val_loss: 19.3056\n",
      "Epoch 599/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0140\n",
      "Epoch 599: val_loss did not improve from 19.30563\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0060 - val_loss: 19.3106\n",
      "Epoch 600/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8276\n",
      "Epoch 600: val_loss did not improve from 19.30563\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7628 - val_loss: 19.7474\n",
      "Epoch 601/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7595\n",
      "Epoch 601: val_loss did not improve from 19.30563\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7595 - val_loss: 21.1735\n",
      "Epoch 602/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9427\n",
      "Epoch 602: val_loss improved from 19.30563 to 19.11307, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7963 - val_loss: 19.1131\n",
      "Epoch 603/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8001\n",
      "Epoch 603: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7453 - val_loss: 20.9647\n",
      "Epoch 604/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5856\n",
      "Epoch 604: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5989 - val_loss: 23.2060\n",
      "Epoch 605/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7301\n",
      "Epoch 605: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7301 - val_loss: 19.4905\n",
      "Epoch 606/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6624\n",
      "Epoch 606: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7543 - val_loss: 26.5287\n",
      "Epoch 607/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7068\n",
      "Epoch 607: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7306 - val_loss: 19.5219\n",
      "Epoch 608/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9186\n",
      "Epoch 608: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.8980 - val_loss: 23.8591\n",
      "Epoch 609/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7748\n",
      "Epoch 609: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.8334 - val_loss: 31.2861\n",
      "Epoch 610/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6169\n",
      "Epoch 610: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7929 - val_loss: 20.7795\n",
      "Epoch 611/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7079\n",
      "Epoch 611: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7521 - val_loss: 36.0592\n",
      "Epoch 612/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7798\n",
      "Epoch 612: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8279 - val_loss: 20.0794\n",
      "Epoch 613/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7800\n",
      "Epoch 613: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7804 - val_loss: 19.3396\n",
      "Epoch 614/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7519\n",
      "Epoch 614: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7156 - val_loss: 25.9710\n",
      "Epoch 615/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6819\n",
      "Epoch 615: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6923 - val_loss: 21.1270\n",
      "Epoch 616/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8176\n",
      "Epoch 616: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8176 - val_loss: 24.2506\n",
      "Epoch 617/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8016\n",
      "Epoch 617: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7885 - val_loss: 27.1242\n",
      "Epoch 618/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7111\n",
      "Epoch 618: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7189 - val_loss: 19.8167\n",
      "Epoch 619/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6493\n",
      "Epoch 619: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6166 - val_loss: 23.5523\n",
      "Epoch 620/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7084\n",
      "Epoch 620: val_loss did not improve from 19.11307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7258 - val_loss: 19.5379\n",
      "Epoch 621/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9400\n",
      "Epoch 621: val_loss improved from 19.11307 to 18.71631, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8441 - val_loss: 18.7163\n",
      "Epoch 622/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7256\n",
      "Epoch 622: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7336 - val_loss: 20.6901\n",
      "Epoch 623/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7575\n",
      "Epoch 623: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7097 - val_loss: 22.8268\n",
      "Epoch 624/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6569\n",
      "Epoch 624: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6137 - val_loss: 24.4137\n",
      "Epoch 625/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6760\n",
      "Epoch 625: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6539 - val_loss: 19.0682\n",
      "Epoch 626/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6628\n",
      "Epoch 626: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7472 - val_loss: 20.1013\n",
      "Epoch 627/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7335\n",
      "Epoch 627: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7544 - val_loss: 23.1255\n",
      "Epoch 628/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6709\n",
      "Epoch 628: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7425 - val_loss: 20.0845\n",
      "Epoch 629/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6672\n",
      "Epoch 629: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7237 - val_loss: 24.8862\n",
      "Epoch 630/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7664\n",
      "Epoch 630: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8127 - val_loss: 20.6441\n",
      "Epoch 631/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8786\n",
      "Epoch 631: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8710 - val_loss: 21.9968\n",
      "Epoch 632/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8764\n",
      "Epoch 632: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8560 - val_loss: 20.9126\n",
      "Epoch 633/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7348\n",
      "Epoch 633: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7348 - val_loss: 22.6723\n",
      "Epoch 634/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7513\n",
      "Epoch 634: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6961 - val_loss: 21.3756\n",
      "Epoch 635/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5538\n",
      "Epoch 635: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6881 - val_loss: 26.7808\n",
      "Epoch 636/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7509\n",
      "Epoch 636: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6904 - val_loss: 26.5755\n",
      "Epoch 637/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8015\n",
      "Epoch 637: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7789 - val_loss: 20.9399\n",
      "Epoch 638/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7792\n",
      "Epoch 638: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7470 - val_loss: 21.8549\n",
      "Epoch 639/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7011\n",
      "Epoch 639: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7632 - val_loss: 19.8587\n",
      "Epoch 640/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8005\n",
      "Epoch 640: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7755 - val_loss: 23.6058\n",
      "Epoch 641/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8181\n",
      "Epoch 641: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7317 - val_loss: 25.7424\n",
      "Epoch 642/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7414\n",
      "Epoch 642: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7259 - val_loss: 24.3079\n",
      "Epoch 643/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7407\n",
      "Epoch 643: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7261 - val_loss: 19.5925\n",
      "Epoch 644/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8502\n",
      "Epoch 644: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8016 - val_loss: 24.0981\n",
      "Epoch 645/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6974\n",
      "Epoch 645: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6949 - val_loss: 18.8065\n",
      "Epoch 646/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8945\n",
      "Epoch 646: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8053 - val_loss: 20.5401\n",
      "Epoch 647/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7960\n",
      "Epoch 647: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7960 - val_loss: 25.0171\n",
      "Epoch 648/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7176\n",
      "Epoch 648: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7176 - val_loss: 21.9038\n",
      "Epoch 649/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7919\n",
      "Epoch 649: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7919 - val_loss: 19.1400\n",
      "Epoch 650/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7084\n",
      "Epoch 650: val_loss did not improve from 18.71631\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.8522 - val_loss: 24.1282\n",
      "Epoch 651/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7413\n",
      "Epoch 651: val_loss improved from 18.71631 to 18.32633, saving model to Best_LSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7364 - val_loss: 18.3263\n",
      "Epoch 652/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7488\n",
      "Epoch 652: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7488 - val_loss: 27.1147\n",
      "Epoch 653/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8078\n",
      "Epoch 653: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8584 - val_loss: 19.2464\n",
      "Epoch 654/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5178\n",
      "Epoch 654: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2.6396 - val_loss: 24.7389\n",
      "Epoch 655/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6776\n",
      "Epoch 655: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6302 - val_loss: 19.2494\n",
      "Epoch 656/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5574\n",
      "Epoch 656: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.6114 - val_loss: 20.4728\n",
      "Epoch 657/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8113\n",
      "Epoch 657: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7871 - val_loss: 24.5530\n",
      "Epoch 658/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7479\n",
      "Epoch 658: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7337 - val_loss: 24.6639\n",
      "Epoch 659/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8164\n",
      "Epoch 659: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7695 - val_loss: 23.7901\n",
      "Epoch 660/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7620\n",
      "Epoch 660: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7163 - val_loss: 26.0869\n",
      "Epoch 661/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6976\n",
      "Epoch 661: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6892 - val_loss: 23.2515\n",
      "Epoch 662/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7104\n",
      "Epoch 662: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7079 - val_loss: 19.2712\n",
      "Epoch 663/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8640\n",
      "Epoch 663: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8357 - val_loss: 23.8326\n",
      "Epoch 664/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9407\n",
      "Epoch 664: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8775 - val_loss: 22.6508\n",
      "Epoch 665/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6579\n",
      "Epoch 665: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6557 - val_loss: 24.0664\n",
      "Epoch 666/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6794\n",
      "Epoch 666: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6794 - val_loss: 18.4823\n",
      "Epoch 667/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8136\n",
      "Epoch 667: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8136 - val_loss: 19.1967\n",
      "Epoch 668/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7504\n",
      "Epoch 668: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7323 - val_loss: 21.8653\n",
      "Epoch 669/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7848\n",
      "Epoch 669: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7982 - val_loss: 20.5278\n",
      "Epoch 670/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7739\n",
      "Epoch 670: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8205 - val_loss: 22.4261\n",
      "Epoch 671/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9452\n",
      "Epoch 671: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8517 - val_loss: 24.1752\n",
      "Epoch 672/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7423\n",
      "Epoch 672: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7194 - val_loss: 23.6829\n",
      "Epoch 673/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8840\n",
      "Epoch 673: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8601 - val_loss: 31.6763\n",
      "Epoch 674/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7092\n",
      "Epoch 674: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7003 - val_loss: 23.4160\n",
      "Epoch 675/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6160\n",
      "Epoch 675: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6280 - val_loss: 20.0805\n",
      "Epoch 676/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8636\n",
      "Epoch 676: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8637 - val_loss: 22.9011\n",
      "Epoch 677/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7136\n",
      "Epoch 677: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7032 - val_loss: 19.9337\n",
      "Epoch 678/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8525\n",
      "Epoch 678: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8525 - val_loss: 21.1482\n",
      "Epoch 679/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6214\n",
      "Epoch 679: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6238 - val_loss: 22.6172\n",
      "Epoch 680/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7303\n",
      "Epoch 680: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7961 - val_loss: 28.9132\n",
      "Epoch 681/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8245\n",
      "Epoch 681: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8245 - val_loss: 20.8549\n",
      "Epoch 682/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6316\n",
      "Epoch 682: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6713 - val_loss: 22.7790\n",
      "Epoch 683/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5595\n",
      "Epoch 683: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6247 - val_loss: 22.4020\n",
      "Epoch 684/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4767\n",
      "Epoch 684: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5671 - val_loss: 29.5671\n",
      "Epoch 685/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7107\n",
      "Epoch 685: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7107 - val_loss: 20.5829\n",
      "Epoch 686/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6906\n",
      "Epoch 686: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6759 - val_loss: 21.6196\n",
      "Epoch 687/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7839\n",
      "Epoch 687: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8408 - val_loss: 18.4432\n",
      "Epoch 688/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8020\n",
      "Epoch 688: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8528 - val_loss: 27.8449\n",
      "Epoch 689/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6879\n",
      "Epoch 689: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6859 - val_loss: 19.8035\n",
      "Epoch 690/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7422\n",
      "Epoch 690: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8294 - val_loss: 20.0000\n",
      "Epoch 691/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7877\n",
      "Epoch 691: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7877 - val_loss: 22.4581\n",
      "Epoch 692/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8016\n",
      "Epoch 692: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7135 - val_loss: 19.0146\n",
      "Epoch 693/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7114\n",
      "Epoch 693: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7114 - val_loss: 18.5994\n",
      "Epoch 694/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6454\n",
      "Epoch 694: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6395 - val_loss: 28.7393\n",
      "Epoch 695/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7319\n",
      "Epoch 695: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7319 - val_loss: 22.1542\n",
      "Epoch 696/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8065\n",
      "Epoch 696: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7818 - val_loss: 22.5207\n",
      "Epoch 697/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7060\n",
      "Epoch 697: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.7029 - val_loss: 18.3313\n",
      "Epoch 698/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5725\n",
      "Epoch 698: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6629 - val_loss: 26.4633\n",
      "Epoch 699/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7268\n",
      "Epoch 699: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6799 - val_loss: 19.3252\n",
      "Epoch 700/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6809\n",
      "Epoch 700: val_loss did not improve from 18.32633\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6809 - val_loss: 21.6910\n",
      "Epoch 701/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7436\n",
      "Epoch 701: val_loss did not improve from 18.32633\n",
      "Restoring model weights from the end of the best epoch: 651.\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7380 - val_loss: 20.4428\n",
      "Epoch 701: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "lstm_sgd_model = TimeSeriesModel(model_type='lstm', optimizer = 'sgd')\n",
    "# Train the model\n",
    "lstm_sgd_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_LSTM_Model_SGD_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a73419a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = lstm_sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f30088ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.438036629701268\n",
      "R2 Score: 0.8934398002906807\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13807e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'LSTM - SGD Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1670c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d3dd5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5700.8467\n",
      "Epoch 1: val_loss improved from inf to 21339.31445, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 4s 33ms/step - loss: 5660.6763 - val_loss: 21339.3145\n",
      "Epoch 2/1000\n",
      "11/37 [=======>......................] - ETA: 0s - loss: 4816.9019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 4973.0449\n",
      "Epoch 2: val_loss improved from 21339.31445 to 20448.07031, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4973.0449 - val_loss: 20448.0703\n",
      "Epoch 3/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4703.2314\n",
      "Epoch 3: val_loss improved from 20448.07031 to 19724.43359, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4648.1353 - val_loss: 19724.4336\n",
      "Epoch 4/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4376.9614\n",
      "Epoch 4: val_loss improved from 19724.43359 to 19053.44336, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4369.2183 - val_loss: 19053.4434\n",
      "Epoch 5/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4109.3711\n",
      "Epoch 5: val_loss improved from 19053.44336 to 18407.07422, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4114.9419 - val_loss: 18407.0742\n",
      "Epoch 6/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3930.7556\n",
      "Epoch 6: val_loss improved from 18407.07422 to 17778.75586, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3873.2297 - val_loss: 17778.7559\n",
      "Epoch 7/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3658.5513\n",
      "Epoch 7: val_loss improved from 17778.75586 to 17156.31250, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3643.2161 - val_loss: 17156.3125\n",
      "Epoch 8/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3457.3450\n",
      "Epoch 8: val_loss improved from 17156.31250 to 16553.65820, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3424.9810 - val_loss: 16553.6582\n",
      "Epoch 9/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3247.5115\n",
      "Epoch 9: val_loss improved from 16553.65820 to 15951.02344, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3216.2336 - val_loss: 15951.0234\n",
      "Epoch 10/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3056.6475\n",
      "Epoch 10: val_loss improved from 15951.02344 to 15370.07910, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3020.3652 - val_loss: 15370.0791\n",
      "Epoch 11/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2801.1489\n",
      "Epoch 11: val_loss improved from 15370.07910 to 14794.11133, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2834.1633 - val_loss: 14794.1113\n",
      "Epoch 12/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2644.5813\n",
      "Epoch 12: val_loss improved from 14794.11133 to 14237.16406, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2662.7441 - val_loss: 14237.1641\n",
      "Epoch 13/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2493.8066\n",
      "Epoch 13: val_loss improved from 14237.16406 to 13697.18555, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2502.9783 - val_loss: 13697.1855\n",
      "Epoch 14/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2339.8184\n",
      "Epoch 14: val_loss improved from 13697.18555 to 13155.69629, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2350.3853 - val_loss: 13155.6963\n",
      "Epoch 15/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2221.6855\n",
      "Epoch 15: val_loss improved from 13155.69629 to 12639.93164, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2211.0554 - val_loss: 12639.9316\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2083.8667\n",
      "Epoch 16: val_loss improved from 12639.93164 to 12131.15820, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 2083.8667 - val_loss: 12131.1582\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1969.4376\n",
      "Epoch 17: val_loss improved from 12131.15820 to 11647.99707, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1969.4376 - val_loss: 11647.9971\n",
      "Epoch 18/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1848.3879\n",
      "Epoch 18: val_loss improved from 11647.99707 to 11161.91406, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1863.0695 - val_loss: 11161.9141\n",
      "Epoch 19/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1772.7772\n",
      "Epoch 19: val_loss improved from 11161.91406 to 10696.99609, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1786.4590 - val_loss: 10696.9961\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1627.7358\n",
      "Epoch 20: val_loss improved from 10696.99609 to 10225.08789, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1627.7358 - val_loss: 10225.0879\n",
      "Epoch 21/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1530.5198\n",
      "Epoch 21: val_loss improved from 10225.08789 to 9765.96484, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1521.6581 - val_loss: 9765.9648\n",
      "Epoch 22/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1411.0072\n",
      "Epoch 22: val_loss improved from 9765.96484 to 9314.76465, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1417.3846 - val_loss: 9314.7646\n",
      "Epoch 23/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1316.6383\n",
      "Epoch 23: val_loss improved from 9314.76465 to 8878.41113, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1317.1838 - val_loss: 8878.4111\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1228.3197\n",
      "Epoch 24: val_loss improved from 8878.41113 to 8456.83984, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1228.3197 - val_loss: 8456.8398\n",
      "Epoch 25/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1148.5919\n",
      "Epoch 25: val_loss improved from 8456.83984 to 8047.71533, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 1142.4084 - val_loss: 8047.7153\n",
      "Epoch 26/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1050.7617\n",
      "Epoch 26: val_loss improved from 8047.71533 to 7643.28662, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1060.9932 - val_loss: 7643.2866\n",
      "Epoch 27/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1002.7797\n",
      "Epoch 27: val_loss improved from 7643.28662 to 7267.01807, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 984.1672 - val_loss: 7267.0181\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 911.1558\n",
      "Epoch 28: val_loss improved from 7267.01807 to 6888.20361, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 911.1558 - val_loss: 6888.2036\n",
      "Epoch 29/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 842.3536\n",
      "Epoch 29: val_loss improved from 6888.20361 to 6523.31055, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 844.1685 - val_loss: 6523.3105\n",
      "Epoch 30/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 777.9871\n",
      "Epoch 30: val_loss improved from 6523.31055 to 6158.59326, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 776.1818 - val_loss: 6158.5933\n",
      "Epoch 31/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 803.1936\n",
      "Epoch 31: val_loss improved from 6158.59326 to 5809.09229, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 814.1171 - val_loss: 5809.0923\n",
      "Epoch 32/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 655.1539\n",
      "Epoch 32: val_loss improved from 5809.09229 to 5481.51172, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 649.5041 - val_loss: 5481.5117\n",
      "Epoch 33/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 603.0705\n",
      "Epoch 33: val_loss improved from 5481.51172 to 5165.19385, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 603.1916 - val_loss: 5165.1938\n",
      "Epoch 34/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 591.4268\n",
      "Epoch 34: val_loss improved from 5165.19385 to 4846.59326, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 582.1196 - val_loss: 4846.5933\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 492.7131\n",
      "Epoch 35: val_loss improved from 4846.59326 to 4545.10840, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 492.7131 - val_loss: 4545.1084\n",
      "Epoch 36/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 475.5379\n",
      "Epoch 36: val_loss improved from 4545.10840 to 4245.87598, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 467.5252 - val_loss: 4245.8760\n",
      "Epoch 37/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 430.0422\n",
      "Epoch 37: val_loss improved from 4245.87598 to 3959.23926, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 429.6494 - val_loss: 3959.2393\n",
      "Epoch 38/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 368.3969\n",
      "Epoch 38: val_loss improved from 3959.23926 to 3697.76611, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 360.3646 - val_loss: 3697.7661\n",
      "Epoch 39/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 332.3022\n",
      "Epoch 39: val_loss improved from 3697.76611 to 3442.39233, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 344.6541 - val_loss: 3442.3923\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 282.5000\n",
      "Epoch 40: val_loss improved from 3442.39233 to 3192.82129, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 282.5000 - val_loss: 3192.8213\n",
      "Epoch 41/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 256.6690\n",
      "Epoch 41: val_loss improved from 3192.82129 to 2961.61890, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 259.4554 - val_loss: 2961.6189\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 214.7599\n",
      "Epoch 42: val_loss improved from 2961.61890 to 2729.15918, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 222.8687 - val_loss: 2729.1592\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 199.0709\n",
      "Epoch 43: val_loss improved from 2729.15918 to 2528.28320, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 199.0709 - val_loss: 2528.2832\n",
      "Epoch 44/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 178.1014\n",
      "Epoch 44: val_loss improved from 2528.28320 to 2337.08936, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 173.3784 - val_loss: 2337.0894\n",
      "Epoch 45/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 151.1950\n",
      "Epoch 45: val_loss improved from 2337.08936 to 2139.21582, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 148.1675 - val_loss: 2139.2158\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 126.1652\n",
      "Epoch 46: val_loss improved from 2139.21582 to 1955.97620, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 126.1652 - val_loss: 1955.9762\n",
      "Epoch 47/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 146.6572\n",
      "Epoch 47: val_loss improved from 1955.97620 to 1788.93665, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 141.4460 - val_loss: 1788.9366\n",
      "Epoch 48/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 99.6917\n",
      "Epoch 48: val_loss improved from 1788.93665 to 1630.90662, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 96.7227 - val_loss: 1630.9066\n",
      "Epoch 49/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 93.3238\n",
      "Epoch 49: val_loss improved from 1630.90662 to 1489.13525, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 92.5013 - val_loss: 1489.1353\n",
      "Epoch 50/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 75.7727\n",
      "Epoch 50: val_loss improved from 1489.13525 to 1361.66150, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 74.3420 - val_loss: 1361.6615\n",
      "Epoch 51/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 64.8452\n",
      "Epoch 51: val_loss improved from 1361.66150 to 1234.98340, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 65.7655 - val_loss: 1234.9834\n",
      "Epoch 52/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 60.0622\n",
      "Epoch 52: val_loss improved from 1234.98340 to 1132.79675, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 57.8665 - val_loss: 1132.7968\n",
      "Epoch 53/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 79.5721\n",
      "Epoch 53: val_loss improved from 1132.79675 to 1033.84888, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 79.6426 - val_loss: 1033.8489\n",
      "Epoch 54/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 41.4125\n",
      "Epoch 54: val_loss improved from 1033.84888 to 942.92816, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 43.9205 - val_loss: 942.9282\n",
      "Epoch 55/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 47.1440\n",
      "Epoch 55: val_loss improved from 942.92816 to 874.30383, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 44.6858 - val_loss: 874.3038\n",
      "Epoch 56/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 37.7281\n",
      "Epoch 56: val_loss improved from 874.30383 to 814.12708, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 38.4570 - val_loss: 814.1271\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 37.8038\n",
      "Epoch 57: val_loss improved from 814.12708 to 760.60730, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 37.8038 - val_loss: 760.6073\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 33.6760\n",
      "Epoch 58: val_loss improved from 760.60730 to 732.71997, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 33.6760 - val_loss: 732.7200\n",
      "Epoch 59/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 31.5511\n",
      "Epoch 59: val_loss improved from 732.71997 to 678.35767, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 31.1240 - val_loss: 678.3577\n",
      "Epoch 60/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 32.9895\n",
      "Epoch 60: val_loss improved from 678.35767 to 647.67365, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 32.0730 - val_loss: 647.6736\n",
      "Epoch 61/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 31.7723\n",
      "Epoch 61: val_loss improved from 647.67365 to 601.17548, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 30.6831 - val_loss: 601.1755\n",
      "Epoch 62/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 27.0410\n",
      "Epoch 62: val_loss improved from 601.17548 to 578.81195, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 27.1342 - val_loss: 578.8120\n",
      "Epoch 63/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 26.7408\n",
      "Epoch 63: val_loss improved from 578.81195 to 544.92377, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 26.8560 - val_loss: 544.9238\n",
      "Epoch 64/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 25.1384\n",
      "Epoch 64: val_loss improved from 544.92377 to 519.32123, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 26.2921 - val_loss: 519.3212\n",
      "Epoch 65/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 28.0722\n",
      "Epoch 65: val_loss improved from 519.32123 to 506.23111, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 28.0173 - val_loss: 506.2311\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 25.5374\n",
      "Epoch 66: val_loss improved from 506.23111 to 486.02887, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 24.9275 - val_loss: 486.0289\n",
      "Epoch 67/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 25.2802\n",
      "Epoch 67: val_loss improved from 486.02887 to 463.61490, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 25.3064 - val_loss: 463.6149\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 21.8091\n",
      "Epoch 68: val_loss improved from 463.61490 to 445.28305, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 21.8091 - val_loss: 445.2831\n",
      "Epoch 69/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 25.2326\n",
      "Epoch 69: val_loss improved from 445.28305 to 435.78198, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 23.7632 - val_loss: 435.7820\n",
      "Epoch 70/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 77.8684\n",
      "Epoch 70: val_loss improved from 435.78198 to 407.71759, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 73.2054 - val_loss: 407.7176\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 16.8057\n",
      "Epoch 71: val_loss improved from 407.71759 to 391.03647, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 16.8057 - val_loss: 391.0365\n",
      "Epoch 72/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 17.5350\n",
      "Epoch 72: val_loss improved from 391.03647 to 381.61102, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 17.5488 - val_loss: 381.6110\n",
      "Epoch 73/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 21.2382\n",
      "Epoch 73: val_loss improved from 381.61102 to 367.74091, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 20.1005 - val_loss: 367.7409\n",
      "Epoch 74/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 40.4528\n",
      "Epoch 74: val_loss improved from 367.74091 to 354.75430, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 37.8669 - val_loss: 354.7543\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 18.4580\n",
      "Epoch 75: val_loss improved from 354.75430 to 349.08139, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 18.4580 - val_loss: 349.0814\n",
      "Epoch 76/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 18.2066\n",
      "Epoch 76: val_loss improved from 349.08139 to 336.24738, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 17.9450 - val_loss: 336.2474\n",
      "Epoch 77/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 24.8089\n",
      "Epoch 77: val_loss improved from 336.24738 to 330.84863, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 24.3626 - val_loss: 330.8486\n",
      "Epoch 78/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.8046\n",
      "Epoch 78: val_loss did not improve from 330.84863\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 16.7128 - val_loss: 346.6445\n",
      "Epoch 79/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 19.9970\n",
      "Epoch 79: val_loss did not improve from 330.84863\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 19.6555 - val_loss: 345.5848\n",
      "Epoch 80/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 18.7265\n",
      "Epoch 80: val_loss improved from 330.84863 to 305.22849, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 18.8699 - val_loss: 305.2285\n",
      "Epoch 81/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.1662\n",
      "Epoch 81: val_loss improved from 305.22849 to 301.06003, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 16.9808 - val_loss: 301.0600\n",
      "Epoch 82/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 28.8394\n",
      "Epoch 82: val_loss did not improve from 301.06003\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 28.0809 - val_loss: 306.7787\n",
      "Epoch 83/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 16.2906\n",
      "Epoch 83: val_loss improved from 301.06003 to 284.54471, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 18.0806 - val_loss: 284.5447\n",
      "Epoch 84/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 15.2713\n",
      "Epoch 84: val_loss improved from 284.54471 to 280.51318, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 15.4865 - val_loss: 280.5132\n",
      "Epoch 85/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.2319\n",
      "Epoch 85: val_loss did not improve from 280.51318\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 19.2823 - val_loss: 281.8370\n",
      "Epoch 86/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 15.4883\n",
      "Epoch 86: val_loss did not improve from 280.51318\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 15.5591 - val_loss: 287.9298\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.1389\n",
      "Epoch 87: val_loss improved from 280.51318 to 274.14804, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 14.1389 - val_loss: 274.1480\n",
      "Epoch 88/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 31.1818\n",
      "Epoch 88: val_loss improved from 274.14804 to 263.94489, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 30.1227 - val_loss: 263.9449\n",
      "Epoch 89/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.4212\n",
      "Epoch 89: val_loss did not improve from 263.94489\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 13.7427 - val_loss: 264.0239\n",
      "Epoch 90/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.0417\n",
      "Epoch 90: val_loss improved from 263.94489 to 260.95758, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 15.7388 - val_loss: 260.9576\n",
      "Epoch 91/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.8900\n",
      "Epoch 91: val_loss did not improve from 260.95758\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 15.5358 - val_loss: 328.6946\n",
      "Epoch 92/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 17.6113\n",
      "Epoch 92: val_loss improved from 260.95758 to 255.81485, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 16.8966 - val_loss: 255.8148\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 15.9197\n",
      "Epoch 93: val_loss did not improve from 255.81485\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 15.9197 - val_loss: 258.8004\n",
      "Epoch 94/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.3788\n",
      "Epoch 94: val_loss did not improve from 255.81485\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 14.9545 - val_loss: 256.9550\n",
      "Epoch 95/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.8170\n",
      "Epoch 95: val_loss improved from 255.81485 to 254.85086, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 17.6475 - val_loss: 254.8509\n",
      "Epoch 96/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 14.1036\n",
      "Epoch 96: val_loss improved from 254.85086 to 244.83598, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 14.1301 - val_loss: 244.8360\n",
      "Epoch 97/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 13.9109\n",
      "Epoch 97: val_loss did not improve from 244.83598\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 14.0916 - val_loss: 263.6124\n",
      "Epoch 98/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.2290\n",
      "Epoch 98: val_loss did not improve from 244.83598\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 17.2177 - val_loss: 270.2338\n",
      "Epoch 99/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 14.0801\n",
      "Epoch 99: val_loss did not improve from 244.83598\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 13.6730 - val_loss: 265.2314\n",
      "Epoch 100/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 23.8795\n",
      "Epoch 100: val_loss did not improve from 244.83598\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 23.4359 - val_loss: 266.2213\n",
      "Epoch 101/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.2074\n",
      "Epoch 101: val_loss did not improve from 244.83598\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 11.9312 - val_loss: 246.5225\n",
      "Epoch 102/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 15.6355\n",
      "Epoch 102: val_loss improved from 244.83598 to 233.42284, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 15.2576 - val_loss: 233.4228\n",
      "Epoch 103/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.8343\n",
      "Epoch 103: val_loss did not improve from 233.42284\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 13.0035 - val_loss: 234.7651\n",
      "Epoch 104/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 13.8109\n",
      "Epoch 104: val_loss improved from 233.42284 to 232.40219, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 15.3074 - val_loss: 232.4022\n",
      "Epoch 105/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 12.4235\n",
      "Epoch 105: val_loss did not improve from 232.40219\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.4615 - val_loss: 243.2542\n",
      "Epoch 106/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.6119\n",
      "Epoch 106: val_loss did not improve from 232.40219\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 13.5159 - val_loss: 234.6291\n",
      "Epoch 107/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11.9909\n",
      "Epoch 107: val_loss did not improve from 232.40219\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 13.2295 - val_loss: 238.0287\n",
      "Epoch 108/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.7114\n",
      "Epoch 108: val_loss improved from 232.40219 to 231.72987, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 12.5838 - val_loss: 231.7299\n",
      "Epoch 109/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 14.1517\n",
      "Epoch 109: val_loss improved from 231.72987 to 220.45428, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 14.0636 - val_loss: 220.4543\n",
      "Epoch 110/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.3615\n",
      "Epoch 110: val_loss did not improve from 220.45428\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.0210 - val_loss: 228.7945\n",
      "Epoch 111/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.5429\n",
      "Epoch 111: val_loss did not improve from 220.45428\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 12.3160 - val_loss: 238.9397\n",
      "Epoch 112/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.2485\n",
      "Epoch 112: val_loss did not improve from 220.45428\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.2109 - val_loss: 223.5188\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 13.0061\n",
      "Epoch 113: val_loss improved from 220.45428 to 220.07605, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 13.0061 - val_loss: 220.0760\n",
      "Epoch 114/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.5791\n",
      "Epoch 114: val_loss did not improve from 220.07605\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.3235 - val_loss: 233.5577\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.3510\n",
      "Epoch 115: val_loss did not improve from 220.07605\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.3510 - val_loss: 237.6291\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.5181\n",
      "Epoch 116: val_loss improved from 220.07605 to 216.96219, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 11.5462 - val_loss: 216.9622\n",
      "Epoch 117/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.2903\n",
      "Epoch 117: val_loss did not improve from 216.96219\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 12.0159 - val_loss: 219.7599\n",
      "Epoch 118/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.1447\n",
      "Epoch 118: val_loss did not improve from 216.96219\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 11.0822 - val_loss: 227.8681\n",
      "Epoch 119/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.9495\n",
      "Epoch 119: val_loss improved from 216.96219 to 216.32614, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 11.8869 - val_loss: 216.3261\n",
      "Epoch 120/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.7317\n",
      "Epoch 120: val_loss did not improve from 216.32614\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 11.6631 - val_loss: 218.1142\n",
      "Epoch 121/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.0256\n",
      "Epoch 121: val_loss improved from 216.32614 to 214.92987, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 11.0491 - val_loss: 214.9299\n",
      "Epoch 122/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.6346\n",
      "Epoch 122: val_loss did not improve from 214.92987\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 10.7310 - val_loss: 229.0914\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.7647\n",
      "Epoch 123: val_loss did not improve from 214.92987\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 11.7647 - val_loss: 233.0638\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0420\n",
      "Epoch 124: val_loss did not improve from 214.92987\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 10.0420 - val_loss: 218.7211\n",
      "Epoch 125/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.8105\n",
      "Epoch 125: val_loss improved from 214.92987 to 203.14882, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.6952 - val_loss: 203.1488\n",
      "Epoch 126/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 10.5421\n",
      "Epoch 126: val_loss did not improve from 203.14882\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 10.2119 - val_loss: 213.4947\n",
      "Epoch 127/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.1753\n",
      "Epoch 127: val_loss did not improve from 203.14882\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.3085 - val_loss: 218.2757\n",
      "Epoch 128/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 13.2930\n",
      "Epoch 128: val_loss improved from 203.14882 to 199.36421, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 12.9377 - val_loss: 199.3642\n",
      "Epoch 129/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.3183\n",
      "Epoch 129: val_loss did not improve from 199.36421\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.2024 - val_loss: 212.8760\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7679\n",
      "Epoch 130: val_loss did not improve from 199.36421\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.7679 - val_loss: 211.2365\n",
      "Epoch 131/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 10.9491\n",
      "Epoch 131: val_loss did not improve from 199.36421\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 10.5166 - val_loss: 208.6892\n",
      "Epoch 132/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 9.4824\n",
      "Epoch 132: val_loss did not improve from 199.36421\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 9.3138 - val_loss: 200.5797\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3848\n",
      "Epoch 133: val_loss did not improve from 199.36421\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 10.3848 - val_loss: 201.1249\n",
      "Epoch 134/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.5437\n",
      "Epoch 134: val_loss improved from 199.36421 to 197.80782, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.8133 - val_loss: 197.8078\n",
      "Epoch 135/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.2959\n",
      "Epoch 135: val_loss improved from 197.80782 to 197.06616, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.1900 - val_loss: 197.0662\n",
      "Epoch 136/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.3885\n",
      "Epoch 136: val_loss did not improve from 197.06616\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.2582 - val_loss: 204.5081\n",
      "Epoch 137/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 27.9868\n",
      "Epoch 137: val_loss improved from 197.06616 to 192.71582, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 26.5866 - val_loss: 192.7158\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.3976\n",
      "Epoch 138: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 8.3976 - val_loss: 200.3717\n",
      "Epoch 139/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.8748\n",
      "Epoch 139: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.4012 - val_loss: 194.4110\n",
      "Epoch 140/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.6895\n",
      "Epoch 140: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 8.6250 - val_loss: 195.4590\n",
      "Epoch 141/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 16.0792\n",
      "Epoch 141: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 15.2759 - val_loss: 192.9266\n",
      "Epoch 142/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 8.3100\n",
      "Epoch 142: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 9.1850 - val_loss: 201.4174\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.2290\n",
      "Epoch 143: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 8.2290 - val_loss: 205.5191\n",
      "Epoch 144/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 10.1569\n",
      "Epoch 144: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 10.0155 - val_loss: 196.8717\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.6113 \n",
      "Epoch 145: val_loss did not improve from 192.71582\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 9.6113 - val_loss: 198.8715\n",
      "Epoch 146/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 34.0834\n",
      "Epoch 146: val_loss improved from 192.71582 to 187.41533, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 30.5872 - val_loss: 187.4153\n",
      "Epoch 147/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 7.5133\n",
      "Epoch 147: val_loss did not improve from 187.41533\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 7.9522 - val_loss: 191.2217\n",
      "Epoch 148/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.0026\n",
      "Epoch 148: val_loss did not improve from 187.41533\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 8.9138 - val_loss: 286.1470\n",
      "Epoch 149/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 8.2094\n",
      "Epoch 149: val_loss did not improve from 187.41533\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 8.3925 - val_loss: 273.4819\n",
      "Epoch 150/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 8.5301\n",
      "Epoch 150: val_loss did not improve from 187.41533\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 9.4340 - val_loss: 277.5748\n",
      "Epoch 151/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 9.3507\n",
      "Epoch 151: val_loss improved from 187.41533 to 185.92125, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.0274 - val_loss: 185.9212\n",
      "Epoch 152/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 8.7848\n",
      "Epoch 152: val_loss did not improve from 185.92125\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 9.1630 - val_loss: 187.2059\n",
      "Epoch 153/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 12.1376\n",
      "Epoch 153: val_loss improved from 185.92125 to 181.46056, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 11.3501 - val_loss: 181.4606\n",
      "Epoch 154/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 8.0100\n",
      "Epoch 154: val_loss did not improve from 181.46056\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 7.9992 - val_loss: 193.4170\n",
      "Epoch 155/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.2927\n",
      "Epoch 155: val_loss did not improve from 181.46056\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.8762 - val_loss: 191.5213\n",
      "Epoch 156/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.6803\n",
      "Epoch 156: val_loss did not improve from 181.46056\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 8.4450 - val_loss: 198.5733\n",
      "Epoch 157/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.3197\n",
      "Epoch 157: val_loss did not improve from 181.46056\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 8.2007 - val_loss: 205.0705\n",
      "Epoch 158/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.1112\n",
      "Epoch 158: val_loss did not improve from 181.46056\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.9814 - val_loss: 186.1363\n",
      "Epoch 159/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.7323\n",
      "Epoch 159: val_loss improved from 181.46056 to 173.09406, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.4761 - val_loss: 173.0941\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.6211\n",
      "Epoch 160: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.6211 - val_loss: 177.2846\n",
      "Epoch 161/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.4940\n",
      "Epoch 161: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.1050 - val_loss: 195.6653\n",
      "Epoch 162/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 7.9488\n",
      "Epoch 162: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.4931 - val_loss: 175.5620\n",
      "Epoch 163/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.2885\n",
      "Epoch 163: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 8.0694 - val_loss: 185.0792\n",
      "Epoch 164/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.1290\n",
      "Epoch 164: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 8.1171 - val_loss: 180.9641\n",
      "Epoch 165/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.7577\n",
      "Epoch 165: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.9056 - val_loss: 184.2994\n",
      "Epoch 166/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.8110\n",
      "Epoch 166: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 8.7543 - val_loss: 180.7060\n",
      "Epoch 167/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.1040\n",
      "Epoch 167: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 8.0123 - val_loss: 185.2058\n",
      "Epoch 168/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.4259\n",
      "Epoch 168: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.3882 - val_loss: 177.2029\n",
      "Epoch 169/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.8182\n",
      "Epoch 169: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.7341 - val_loss: 176.2190\n",
      "Epoch 170/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.1342\n",
      "Epoch 170: val_loss did not improve from 173.09406\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.8870 - val_loss: 190.0562\n",
      "Epoch 171/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 26.3354\n",
      "Epoch 171: val_loss improved from 173.09406 to 173.07405, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 25.3468 - val_loss: 173.0741\n",
      "Epoch 172/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.5894\n",
      "Epoch 172: val_loss did not improve from 173.07405\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 6.5920 - val_loss: 175.7249\n",
      "Epoch 173/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.9319\n",
      "Epoch 173: val_loss did not improve from 173.07405\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.0432 - val_loss: 194.7889\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.2175\n",
      "Epoch 174: val_loss did not improve from 173.07405\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.2175 - val_loss: 181.6968\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.2989\n",
      "Epoch 175: val_loss did not improve from 173.07405\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.2989 - val_loss: 185.2056\n",
      "Epoch 176/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.3486\n",
      "Epoch 176: val_loss improved from 173.07405 to 172.43878, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.3907 - val_loss: 172.4388\n",
      "Epoch 177/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.9716\n",
      "Epoch 177: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.9173 - val_loss: 173.7794\n",
      "Epoch 178/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.7280\n",
      "Epoch 178: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.7556 - val_loss: 179.6256\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.3309\n",
      "Epoch 179: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.3309 - val_loss: 181.5614\n",
      "Epoch 180/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.3650\n",
      "Epoch 180: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.2165 - val_loss: 174.8172\n",
      "Epoch 181/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.2855\n",
      "Epoch 181: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 8.3677 - val_loss: 200.3112\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.7353\n",
      "Epoch 182: val_loss did not improve from 172.43878\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.7353 - val_loss: 198.5504\n",
      "Epoch 183/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11.1412\n",
      "Epoch 183: val_loss improved from 172.43878 to 169.76860, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 10.7493 - val_loss: 169.7686\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.1826\n",
      "Epoch 184: val_loss did not improve from 169.76860\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.1826 - val_loss: 179.3282\n",
      "Epoch 185/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.8378\n",
      "Epoch 185: val_loss did not improve from 169.76860\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 7.1434 - val_loss: 184.7609\n",
      "Epoch 186/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.8581\n",
      "Epoch 186: val_loss did not improve from 169.76860\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.6518 - val_loss: 173.9797\n",
      "Epoch 187/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.9751\n",
      "Epoch 187: val_loss improved from 169.76860 to 169.23271, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 12.9024 - val_loss: 169.2327\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.5181\n",
      "Epoch 188: val_loss did not improve from 169.23271\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.5181 - val_loss: 179.6396\n",
      "Epoch 189/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.3235\n",
      "Epoch 189: val_loss did not improve from 169.23271\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.4002 - val_loss: 180.8135\n",
      "Epoch 190/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6803\n",
      "Epoch 190: val_loss improved from 169.23271 to 166.17676, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.5740 - val_loss: 166.1768\n",
      "Epoch 191/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.9510\n",
      "Epoch 191: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.3917 - val_loss: 434.9947\n",
      "Epoch 192/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.0641\n",
      "Epoch 192: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.0350 - val_loss: 166.8606\n",
      "Epoch 193/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.9046\n",
      "Epoch 193: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 8.5810 - val_loss: 169.2062\n",
      "Epoch 194/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.6217\n",
      "Epoch 194: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 10.2855 - val_loss: 170.2665\n",
      "Epoch 195/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 6.2160\n",
      "Epoch 195: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.8498 - val_loss: 181.1839\n",
      "Epoch 196/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.7309\n",
      "Epoch 196: val_loss did not improve from 166.17676\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.6641 - val_loss: 172.0393\n",
      "Epoch 197/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.8242\n",
      "Epoch 197: val_loss improved from 166.17676 to 165.71916, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.4672 - val_loss: 165.7192\n",
      "Epoch 198/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.6280\n",
      "Epoch 198: val_loss did not improve from 165.71916\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.5257 - val_loss: 175.2074\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6848\n",
      "Epoch 199: val_loss did not improve from 165.71916\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.6848 - val_loss: 234.1237\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.0206\n",
      "Epoch 200: val_loss did not improve from 165.71916\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.0206 - val_loss: 189.4062\n",
      "Epoch 201/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.0793\n",
      "Epoch 201: val_loss improved from 165.71916 to 154.81375, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.7972 - val_loss: 154.8138\n",
      "Epoch 202/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.6110\n",
      "Epoch 202: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.3490 - val_loss: 180.1295\n",
      "Epoch 203/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 31.9127\n",
      "Epoch 203: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 30.4030 - val_loss: 176.5439\n",
      "Epoch 204/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.2270\n",
      "Epoch 204: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.1755 - val_loss: 172.0012\n",
      "Epoch 205/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.5740\n",
      "Epoch 205: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.7031 - val_loss: 187.3474\n",
      "Epoch 206/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.7134\n",
      "Epoch 206: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.8533 - val_loss: 211.6924\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6147\n",
      "Epoch 207: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 6.6147 - val_loss: 177.8695\n",
      "Epoch 208/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.2080\n",
      "Epoch 208: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.1774 - val_loss: 162.4996\n",
      "Epoch 209/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.5860\n",
      "Epoch 209: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.6687 - val_loss: 164.7713\n",
      "Epoch 210/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.5019\n",
      "Epoch 210: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.5387 - val_loss: 165.0106\n",
      "Epoch 211/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.8035\n",
      "Epoch 211: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.9825 - val_loss: 185.0066\n",
      "Epoch 212/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.6836\n",
      "Epoch 212: val_loss did not improve from 154.81375\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.7126 - val_loss: 184.0158\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.3374\n",
      "Epoch 213: val_loss improved from 154.81375 to 154.29594, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.3374 - val_loss: 154.2959\n",
      "Epoch 214/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 42.9632\n",
      "Epoch 214: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 40.9787 - val_loss: 171.7117\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0177\n",
      "Epoch 215: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.0177 - val_loss: 190.2144\n",
      "Epoch 216/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.9559\n",
      "Epoch 216: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.8440 - val_loss: 207.2019\n",
      "Epoch 217/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.2594\n",
      "Epoch 217: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.0804 - val_loss: 195.4264\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.5289\n",
      "Epoch 218: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.5289 - val_loss: 159.3378\n",
      "Epoch 219/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4289\n",
      "Epoch 219: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.6896 - val_loss: 168.7427\n",
      "Epoch 220/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.4794 \n",
      "Epoch 220: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.2670 - val_loss: 164.0898\n",
      "Epoch 221/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.6312\n",
      "Epoch 221: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.7642 - val_loss: 183.9306\n",
      "Epoch 222/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6742\n",
      "Epoch 222: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.7767 - val_loss: 193.9486\n",
      "Epoch 223/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.6918\n",
      "Epoch 223: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.8042 - val_loss: 213.7535\n",
      "Epoch 224/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.6185\n",
      "Epoch 224: val_loss did not improve from 154.29594\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.5885 - val_loss: 170.0837\n",
      "Epoch 225/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.5072\n",
      "Epoch 225: val_loss improved from 154.29594 to 152.30807, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.5747 - val_loss: 152.3081\n",
      "Epoch 226/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.7739\n",
      "Epoch 226: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.6370 - val_loss: 159.9978\n",
      "Epoch 227/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.2719\n",
      "Epoch 227: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.2318 - val_loss: 201.5399\n",
      "Epoch 228/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.9320\n",
      "Epoch 228: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.9570 - val_loss: 155.6104\n",
      "Epoch 229/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.8366\n",
      "Epoch 229: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.8630 - val_loss: 160.6418\n",
      "Epoch 230/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.0604\n",
      "Epoch 230: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.7580 - val_loss: 161.1630\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.6552\n",
      "Epoch 231: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.6552 - val_loss: 154.6513\n",
      "Epoch 232/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.1836\n",
      "Epoch 232: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.2200 - val_loss: 174.9178\n",
      "Epoch 233/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.0256\n",
      "Epoch 233: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.4702 - val_loss: 235.4375\n",
      "Epoch 234/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.9581\n",
      "Epoch 234: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8937 - val_loss: 348.6595\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6524\n",
      "Epoch 235: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.6524 - val_loss: 177.8573\n",
      "Epoch 236/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8047\n",
      "Epoch 236: val_loss did not improve from 152.30807\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8316 - val_loss: 154.2090\n",
      "Epoch 237/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.5977\n",
      "Epoch 237: val_loss improved from 152.30807 to 149.61307, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8715 - val_loss: 149.6131\n",
      "Epoch 238/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.0208\n",
      "Epoch 238: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8358 - val_loss: 158.4731\n",
      "Epoch 239/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.3624\n",
      "Epoch 239: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.1403 - val_loss: 157.3001\n",
      "Epoch 240/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.9378\n",
      "Epoch 240: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.4575 - val_loss: 165.2632\n",
      "Epoch 241/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4370\n",
      "Epoch 241: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.0750 - val_loss: 150.8363\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.2339\n",
      "Epoch 242: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.2339 - val_loss: 155.3804\n",
      "Epoch 243/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4502\n",
      "Epoch 243: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.4655 - val_loss: 176.9430\n",
      "Epoch 244/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.2251\n",
      "Epoch 244: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 7.2106 - val_loss: 170.9451\n",
      "Epoch 245/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.3121\n",
      "Epoch 245: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.2020 - val_loss: 178.0545\n",
      "Epoch 246/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.7006\n",
      "Epoch 246: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.6314 - val_loss: 179.4237\n",
      "Epoch 247/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.2874\n",
      "Epoch 247: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 13.7525 - val_loss: 149.9213\n",
      "Epoch 248/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.9708\n",
      "Epoch 248: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.9354 - val_loss: 157.0571\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.5122\n",
      "Epoch 249: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.5122 - val_loss: 169.5540\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.5677\n",
      "Epoch 250: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.5677 - val_loss: 340.3588\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.3813\n",
      "Epoch 251: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.3813 - val_loss: 180.5221\n",
      "Epoch 252/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.1615\n",
      "Epoch 252: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.1359 - val_loss: 342.1698\n",
      "Epoch 253/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.8206\n",
      "Epoch 253: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.0142 - val_loss: 161.9402\n",
      "Epoch 254/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.7944\n",
      "Epoch 254: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.7380 - val_loss: 168.9860\n",
      "Epoch 255/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.9196\n",
      "Epoch 255: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.2407 - val_loss: 171.5584\n",
      "Epoch 256/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.0716\n",
      "Epoch 256: val_loss did not improve from 149.61307\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.1143 - val_loss: 157.6261\n",
      "Epoch 257/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.4643\n",
      "Epoch 257: val_loss improved from 149.61307 to 147.89481, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.3054 - val_loss: 147.8948\n",
      "Epoch 258/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 6.0344\n",
      "Epoch 258: val_loss did not improve from 147.89481\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.8699 - val_loss: 165.8149\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.7048\n",
      "Epoch 259: val_loss did not improve from 147.89481\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.7048 - val_loss: 291.3379\n",
      "Epoch 260/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1963\n",
      "Epoch 260: val_loss improved from 147.89481 to 146.65179, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.0202 - val_loss: 146.6518\n",
      "Epoch 261/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1897\n",
      "Epoch 261: val_loss did not improve from 146.65179\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.2191 - val_loss: 148.8649\n",
      "Epoch 262/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 7.1463\n",
      "Epoch 262: val_loss did not improve from 146.65179\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.6493 - val_loss: 152.0566\n",
      "Epoch 263/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9355\n",
      "Epoch 263: val_loss did not improve from 146.65179\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8940 - val_loss: 169.0989\n",
      "Epoch 264/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.6683\n",
      "Epoch 264: val_loss did not improve from 146.65179\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.6180 - val_loss: 190.2581\n",
      "Epoch 265/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3323\n",
      "Epoch 265: val_loss improved from 146.65179 to 146.20763, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.2962 - val_loss: 146.2076\n",
      "Epoch 266/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.0370\n",
      "Epoch 266: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.0950 - val_loss: 166.1299\n",
      "Epoch 267/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8645\n",
      "Epoch 267: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8394 - val_loss: 220.9447\n",
      "Epoch 268/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1382\n",
      "Epoch 268: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.0969 - val_loss: 160.0490\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.4234\n",
      "Epoch 269: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.4234 - val_loss: 147.1419\n",
      "Epoch 270/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9193\n",
      "Epoch 270: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.8169 - val_loss: 175.0983\n",
      "Epoch 271/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4943\n",
      "Epoch 271: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.4479 - val_loss: 152.5363\n",
      "Epoch 272/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.5001\n",
      "Epoch 272: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.4643 - val_loss: 155.4654\n",
      "Epoch 273/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2994\n",
      "Epoch 273: val_loss did not improve from 146.20763\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.2314 - val_loss: 163.0263\n",
      "Epoch 274/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.3612\n",
      "Epoch 274: val_loss improved from 146.20763 to 144.89272, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 5.2836 - val_loss: 144.8927\n",
      "Epoch 275/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2184\n",
      "Epoch 275: val_loss improved from 144.89272 to 140.57239, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.3942 - val_loss: 140.5724\n",
      "Epoch 276/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.9033\n",
      "Epoch 276: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8319 - val_loss: 165.5868\n",
      "Epoch 277/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 14.6389\n",
      "Epoch 277: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 13.8210 - val_loss: 156.9662\n",
      "Epoch 278/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.4367\n",
      "Epoch 278: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4780 - val_loss: 289.2148\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.9430\n",
      "Epoch 279: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.9430 - val_loss: 179.9315\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5986\n",
      "Epoch 280: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5986 - val_loss: 152.6400\n",
      "Epoch 281/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.1546\n",
      "Epoch 281: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.2661 - val_loss: 147.8642\n",
      "Epoch 282/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.0484\n",
      "Epoch 282: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.9831 - val_loss: 186.8448\n",
      "Epoch 283/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.7334\n",
      "Epoch 283: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8703 - val_loss: 186.8783\n",
      "Epoch 284/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1176\n",
      "Epoch 284: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.1311 - val_loss: 374.3938\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1690\n",
      "Epoch 285: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.1690 - val_loss: 224.7551\n",
      "Epoch 286/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.3535\n",
      "Epoch 286: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.0766 - val_loss: 146.4979\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.7389\n",
      "Epoch 287: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.7389 - val_loss: 173.5603\n",
      "Epoch 288/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.8489\n",
      "Epoch 288: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 12.2295 - val_loss: 141.7525\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0857\n",
      "Epoch 289: val_loss did not improve from 140.57239\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0857 - val_loss: 148.0230\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.6381\n",
      "Epoch 290: val_loss improved from 140.57239 to 140.11269, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.6381 - val_loss: 140.1127\n",
      "Epoch 291/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.3428 \n",
      "Epoch 291: val_loss did not improve from 140.11269\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.0129 - val_loss: 154.4060\n",
      "Epoch 292/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1285\n",
      "Epoch 292: val_loss did not improve from 140.11269\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0985 - val_loss: 214.2360\n",
      "Epoch 293/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3023\n",
      "Epoch 293: val_loss improved from 140.11269 to 132.12343, saving model to Best_LSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.0698 - val_loss: 132.1234\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.6724\n",
      "Epoch 294: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.6724 - val_loss: 141.8913\n",
      "Epoch 295/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3607\n",
      "Epoch 295: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.4466 - val_loss: 165.4572\n",
      "Epoch 296/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.0537\n",
      "Epoch 296: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.0640 - val_loss: 642.0240\n",
      "Epoch 297/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8257\n",
      "Epoch 297: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7660 - val_loss: 169.7816\n",
      "Epoch 298/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8534\n",
      "Epoch 298: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.8146 - val_loss: 247.6258\n",
      "Epoch 299/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8378\n",
      "Epoch 299: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 4.8270 - val_loss: 418.8184\n",
      "Epoch 300/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7609\n",
      "Epoch 300: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7550 - val_loss: 182.5973\n",
      "Epoch 301/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8599\n",
      "Epoch 301: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.7739 - val_loss: 148.3001\n",
      "Epoch 302/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6718\n",
      "Epoch 302: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.6672 - val_loss: 184.1949\n",
      "Epoch 303/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0488\n",
      "Epoch 303: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.0381 - val_loss: 280.2289\n",
      "Epoch 304/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8205\n",
      "Epoch 304: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.0214 - val_loss: 518.1758\n",
      "Epoch 305/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5653\n",
      "Epoch 305: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.6130 - val_loss: 434.9171\n",
      "Epoch 306/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8545\n",
      "Epoch 306: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.1161 - val_loss: 139.0694\n",
      "Epoch 307/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8876\n",
      "Epoch 307: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.0003 - val_loss: 189.9683\n",
      "Epoch 308/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.7410\n",
      "Epoch 308: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.6564 - val_loss: 155.7781\n",
      "Epoch 309/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.2298\n",
      "Epoch 309: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.1588 - val_loss: 180.6004\n",
      "Epoch 310/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.5689\n",
      "Epoch 310: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.6821 - val_loss: 258.5972\n",
      "Epoch 311/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.0978\n",
      "Epoch 311: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.8378 - val_loss: 140.4631\n",
      "Epoch 312/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2789\n",
      "Epoch 312: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3808 - val_loss: 253.0133\n",
      "Epoch 313/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.8188\n",
      "Epoch 313: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.7780 - val_loss: 152.2974\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.0814\n",
      "Epoch 314: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.0814 - val_loss: 251.2866\n",
      "Epoch 315/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1236\n",
      "Epoch 315: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1561 - val_loss: 367.7935\n",
      "Epoch 316/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.9112\n",
      "Epoch 316: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.7810 - val_loss: 135.2333\n",
      "Epoch 317/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.8991\n",
      "Epoch 317: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.8311 - val_loss: 240.7970\n",
      "Epoch 318/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2460\n",
      "Epoch 318: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3485 - val_loss: 198.4909\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4741\n",
      "Epoch 319: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.4741 - val_loss: 182.7746\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0751\n",
      "Epoch 320: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.0751 - val_loss: 228.9196\n",
      "Epoch 321/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3241\n",
      "Epoch 321: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3057 - val_loss: 1352.2795\n",
      "Epoch 322/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.1385\n",
      "Epoch 322: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.8434 - val_loss: 672.2341\n",
      "Epoch 323/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2851\n",
      "Epoch 323: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2382 - val_loss: 143.9646\n",
      "Epoch 324/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.8942\n",
      "Epoch 324: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 4.7180 - val_loss: 333.1893\n",
      "Epoch 325/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.0421\n",
      "Epoch 325: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.9604 - val_loss: 157.5818\n",
      "Epoch 326/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5156\n",
      "Epoch 326: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.4533 - val_loss: 166.0933\n",
      "Epoch 327/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5966\n",
      "Epoch 327: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.5105 - val_loss: 157.0156\n",
      "Epoch 328/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.0417\n",
      "Epoch 328: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 14.4350 - val_loss: 247.9058\n",
      "Epoch 329/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8348\n",
      "Epoch 329: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8353 - val_loss: 682.7271\n",
      "Epoch 330/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5473\n",
      "Epoch 330: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.5766 - val_loss: 531.9832\n",
      "Epoch 331/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.8517\n",
      "Epoch 331: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.7765 - val_loss: 972.8530\n",
      "Epoch 332/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0453\n",
      "Epoch 332: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.0097 - val_loss: 368.7042\n",
      "Epoch 333/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.7546\n",
      "Epoch 333: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.6693 - val_loss: 145.4871\n",
      "Epoch 334/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5211\n",
      "Epoch 334: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.3997 - val_loss: 260.3690\n",
      "Epoch 335/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4625\n",
      "Epoch 335: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.4449 - val_loss: 866.3419\n",
      "Epoch 336/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7435\n",
      "Epoch 336: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7136 - val_loss: 142.0280\n",
      "Epoch 337/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1862\n",
      "Epoch 337: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0936 - val_loss: 169.3490\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.1500\n",
      "Epoch 338: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 12.1500 - val_loss: 472.4659\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0112\n",
      "Epoch 339: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0112 - val_loss: 576.0591\n",
      "Epoch 340/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3629\n",
      "Epoch 340: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.2639 - val_loss: 1242.8502\n",
      "Epoch 341/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3456\n",
      "Epoch 341: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.2822 - val_loss: 137.8500\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.7577\n",
      "Epoch 342: val_loss did not improve from 132.12343\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 8.7577 - val_loss: 214.8173\n",
      "Epoch 343/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.0159\n",
      "Epoch 343: val_loss did not improve from 132.12343\n",
      "Restoring model weights from the end of the best epoch: 293.\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0458 - val_loss: 145.8564\n",
      "Epoch 343: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "lstm_rmsprop_model = TimeSeriesModel(model_type='lstm', optimizer = RMSprop(learning_rate=0.001))\n",
    "# Train the model\n",
    "lstm_rmsprop_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_LSTM_Model_RMSprop_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9c57916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = lstm_rmsprop_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55313dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.990821285586014\n",
      "R2 Score: 0.22212265837737477\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1daec148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'LSTM - RMSprop Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a39fd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb46bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b64a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5939.6616\n",
      "Epoch 1: val_loss improved from inf to 20934.76758, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 6s 58ms/step - loss: 5901.3994 - val_loss: 20934.7676\n",
      "Epoch 2/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4515.1880\n",
      "Epoch 2: val_loss improved from 20934.76758 to 18626.75391, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4484.7456 - val_loss: 18626.7539\n",
      "Epoch 3/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3796.8950\n",
      "Epoch 3: val_loss improved from 18626.75391 to 17187.13672, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3802.9897 - val_loss: 17187.1367\n",
      "Epoch 4/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3297.6262\n",
      "Epoch 4: val_loss improved from 17187.13672 to 15962.90918, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3324.5562 - val_loss: 15962.9092\n",
      "Epoch 5/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2983.0642\n",
      "Epoch 5: val_loss improved from 15962.90918 to 14908.90039, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2948.1335 - val_loss: 14908.9004\n",
      "Epoch 6/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2647.7310\n",
      "Epoch 6: val_loss improved from 14908.90039 to 13970.81152, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2641.4333 - val_loss: 13970.8115\n",
      "Epoch 7/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2385.5671\n",
      "Epoch 7: val_loss improved from 13970.81152 to 13145.73535, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 2387.6362 - val_loss: 13145.7354\n",
      "Epoch 8/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2204.1875\n",
      "Epoch 8: val_loss improved from 13145.73535 to 12389.79590, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 2180.7332 - val_loss: 12389.7959\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2008.1376\n",
      "Epoch 9: val_loss improved from 12389.79590 to 11732.37793, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 2008.1376 - val_loss: 11732.3779\n",
      "Epoch 10/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1893.2274\n",
      "Epoch 10: val_loss improved from 11732.37793 to 11130.79785, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1869.4359 - val_loss: 11130.7979\n",
      "Epoch 11/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1750.6050\n",
      "Epoch 11: val_loss improved from 11130.79785 to 10606.13867, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1756.2415 - val_loss: 10606.1387\n",
      "Epoch 12/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1670.6449\n",
      "Epoch 12: val_loss improved from 10606.13867 to 10129.24219, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1664.4821 - val_loss: 10129.2422\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1585.1538\n",
      "Epoch 13: val_loss improved from 10129.24219 to 9679.72559, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1585.1538 - val_loss: 9679.7256\n",
      "Epoch 14/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1500.3767\n",
      "Epoch 14: val_loss improved from 9679.72559 to 9292.93555, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1521.2775 - val_loss: 9292.9355\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1473.3973\n",
      "Epoch 15: val_loss improved from 9292.93555 to 8950.64941, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1473.3973 - val_loss: 8950.6494\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1409.3179\n",
      "Epoch 16: val_loss improved from 8950.64941 to 8639.37988, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1409.3179 - val_loss: 8639.3799\n",
      "Epoch 17/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1220.4146\n",
      "Epoch 17: val_loss improved from 8639.37988 to 8169.56396, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 1218.1718 - val_loss: 8169.5640\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1079.5061\n",
      "Epoch 18: val_loss improved from 8169.56396 to 7666.99170, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1079.5061 - val_loss: 7666.9917\n",
      "Epoch 19/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 980.2360\n",
      "Epoch 19: val_loss improved from 7666.99170 to 7181.65576, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 981.0002 - val_loss: 7181.6558\n",
      "Epoch 20/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 893.6326\n",
      "Epoch 20: val_loss improved from 7181.65576 to 6740.14014, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 892.2153 - val_loss: 6740.1401\n",
      "Epoch 21/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 860.9214\n",
      "Epoch 21: val_loss improved from 6740.14014 to 6339.52588, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 855.0362 - val_loss: 6339.5259\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 766.0861\n",
      "Epoch 22: val_loss improved from 6339.52588 to 5964.16260, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 766.0861 - val_loss: 5964.1626\n",
      "Epoch 23/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 722.0441\n",
      "Epoch 23: val_loss improved from 5964.16260 to 5583.64258, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 722.0711 - val_loss: 5583.6426\n",
      "Epoch 24/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 682.3543\n",
      "Epoch 24: val_loss improved from 5583.64258 to 5209.81299, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 679.1985 - val_loss: 5209.8130\n",
      "Epoch 25/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 569.9106\n",
      "Epoch 25: val_loss improved from 5209.81299 to 4901.15771, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 569.1796 - val_loss: 4901.1577\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 526.7612\n",
      "Epoch 26: val_loss improved from 4901.15771 to 4639.37305, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 526.7612 - val_loss: 4639.3730\n",
      "Epoch 27/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 487.9264\n",
      "Epoch 27: val_loss improved from 4639.37305 to 4385.72217, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 490.7277 - val_loss: 4385.7222\n",
      "Epoch 28/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 464.3084\n",
      "Epoch 28: val_loss improved from 4385.72217 to 4171.08838, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 461.0567 - val_loss: 4171.0884\n",
      "Epoch 29/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 428.0435\n",
      "Epoch 29: val_loss improved from 4171.08838 to 3957.79102, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 426.8755 - val_loss: 3957.7910\n",
      "Epoch 30/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 397.6523\n",
      "Epoch 30: val_loss improved from 3957.79102 to 3765.23218, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 397.2371 - val_loss: 3765.2322\n",
      "Epoch 31/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 368.9577\n",
      "Epoch 31: val_loss improved from 3765.23218 to 3591.81055, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 378.3733 - val_loss: 3591.8105\n",
      "Epoch 32/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 347.7217\n",
      "Epoch 32: val_loss improved from 3591.81055 to 3421.12451, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 348.6373 - val_loss: 3421.1245\n",
      "Epoch 33/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 304.7383\n",
      "Epoch 33: val_loss improved from 3421.12451 to 3224.84546, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 308.2504 - val_loss: 3224.8455\n",
      "Epoch 34/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 282.8420\n",
      "Epoch 34: val_loss improved from 3224.84546 to 3043.42456, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 278.3390 - val_loss: 3043.4246\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 254.2088\n",
      "Epoch 35: val_loss improved from 3043.42456 to 2873.68823, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 254.2088 - val_loss: 2873.6882\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 231.6901\n",
      "Epoch 36: val_loss improved from 2873.68823 to 2729.02100, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 231.6901 - val_loss: 2729.0210\n",
      "Epoch 37/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 220.1957\n",
      "Epoch 37: val_loss improved from 2729.02100 to 2587.02148, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 218.4141 - val_loss: 2587.0215\n",
      "Epoch 38/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 202.4078\n",
      "Epoch 38: val_loss improved from 2587.02148 to 2456.40210, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 200.7359 - val_loss: 2456.4021\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 182.8402\n",
      "Epoch 39: val_loss improved from 2456.40210 to 2344.29761, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 182.8402 - val_loss: 2344.2976\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 167.3540\n",
      "Epoch 40: val_loss improved from 2344.29761 to 2235.69434, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 167.3540 - val_loss: 2235.6943\n",
      "Epoch 41/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 155.1295\n",
      "Epoch 41: val_loss improved from 2235.69434 to 2130.22827, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 157.0688 - val_loss: 2130.2283\n",
      "Epoch 42/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 141.3474\n",
      "Epoch 42: val_loss improved from 2130.22827 to 2036.67383, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 143.5249 - val_loss: 2036.6738\n",
      "Epoch 43/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 136.1306\n",
      "Epoch 43: val_loss improved from 2036.67383 to 1944.86633, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 133.3839 - val_loss: 1944.8663\n",
      "Epoch 44/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 132.7919\n",
      "Epoch 44: val_loss improved from 1944.86633 to 1850.65955, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 127.5925 - val_loss: 1850.6595\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 112.2220\n",
      "Epoch 45: val_loss improved from 1850.65955 to 1771.66333, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 112.2220 - val_loss: 1771.6633\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 104.4920\n",
      "Epoch 46: val_loss improved from 1771.66333 to 1696.39258, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 104.4920 - val_loss: 1696.3926\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 96.3398\n",
      "Epoch 47: val_loss improved from 1696.39258 to 1618.97656, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 96.3398 - val_loss: 1618.9766\n",
      "Epoch 48/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 92.9302\n",
      "Epoch 48: val_loss improved from 1618.97656 to 1557.92151, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 91.1796 - val_loss: 1557.9215\n",
      "Epoch 49/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 86.4880\n",
      "Epoch 49: val_loss improved from 1557.92151 to 1488.84021, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 85.9535 - val_loss: 1488.8402\n",
      "Epoch 50/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 80.2754\n",
      "Epoch 50: val_loss improved from 1488.84021 to 1430.76782, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 79.3969 - val_loss: 1430.7678\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 75.3492\n",
      "Epoch 51: val_loss improved from 1430.76782 to 1376.36609, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 75.3492 - val_loss: 1376.3661\n",
      "Epoch 52/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 71.9039\n",
      "Epoch 52: val_loss improved from 1376.36609 to 1327.86145, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 71.0034 - val_loss: 1327.8615\n",
      "Epoch 53/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 66.1879\n",
      "Epoch 53: val_loss improved from 1327.86145 to 1283.38855, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 67.8086 - val_loss: 1283.3885\n",
      "Epoch 54/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 63.6132\n",
      "Epoch 54: val_loss improved from 1283.38855 to 1240.75049, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 64.6257 - val_loss: 1240.7505\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 61.1613\n",
      "Epoch 55: val_loss improved from 1240.75049 to 1199.23303, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 61.1613 - val_loss: 1199.2330\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 59.5891\n",
      "Epoch 56: val_loss improved from 1199.23303 to 1157.86853, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 59.5891 - val_loss: 1157.8685\n",
      "Epoch 57/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 56.4197\n",
      "Epoch 57: val_loss improved from 1157.86853 to 1118.01379, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 56.3646 - val_loss: 1118.0138\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 52.0766\n",
      "Epoch 58: val_loss improved from 1118.01379 to 1078.50439, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 52.0766 - val_loss: 1078.5044\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 49.9896\n",
      "Epoch 59: val_loss improved from 1078.50439 to 1040.86987, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 49.9896 - val_loss: 1040.8699\n",
      "Epoch 60/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 49.4801\n",
      "Epoch 60: val_loss improved from 1040.86987 to 1011.20874, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 50.0839 - val_loss: 1011.2087\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 47.0686\n",
      "Epoch 61: val_loss improved from 1011.20874 to 985.37573, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 47.0686 - val_loss: 985.3757\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 46.3760\n",
      "Epoch 62: val_loss improved from 985.37573 to 957.71075, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 46.3760 - val_loss: 957.7108\n",
      "Epoch 63/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 45.0913\n",
      "Epoch 63: val_loss improved from 957.71075 to 930.35510, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 45.6783 - val_loss: 930.3551\n",
      "Epoch 64/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 46.2580\n",
      "Epoch 64: val_loss improved from 930.35510 to 903.64838, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 47.5378 - val_loss: 903.6484\n",
      "Epoch 65/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 46.9059\n",
      "Epoch 65: val_loss improved from 903.64838 to 888.24377, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 46.5889 - val_loss: 888.2438\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 42.0667\n",
      "Epoch 66: val_loss improved from 888.24377 to 872.29657, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 42.1183 - val_loss: 872.2966\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 37.4235\n",
      "Epoch 67: val_loss improved from 872.29657 to 851.61377, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 37.4235 - val_loss: 851.6138\n",
      "Epoch 68/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 36.6659\n",
      "Epoch 68: val_loss improved from 851.61377 to 828.72217, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 36.5212 - val_loss: 828.7222\n",
      "Epoch 69/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 36.5962\n",
      "Epoch 69: val_loss improved from 828.72217 to 805.46283, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 36.5452 - val_loss: 805.4628\n",
      "Epoch 70/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 40.2931\n",
      "Epoch 70: val_loss improved from 805.46283 to 784.34155, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 40.2807 - val_loss: 784.3416\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 35.4015\n",
      "Epoch 71: val_loss improved from 784.34155 to 768.31549, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 35.4015 - val_loss: 768.3155\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 31.4240\n",
      "Epoch 72: val_loss improved from 768.31549 to 751.50836, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 31.4240 - val_loss: 751.5084\n",
      "Epoch 73/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 31.6098\n",
      "Epoch 73: val_loss improved from 751.50836 to 737.21552, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 31.4702 - val_loss: 737.2155\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 30.5755\n",
      "Epoch 74: val_loss improved from 737.21552 to 719.31848, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 30.5755 - val_loss: 719.3185\n",
      "Epoch 75/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 30.5100\n",
      "Epoch 75: val_loss improved from 719.31848 to 702.05078, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 30.1922 - val_loss: 702.0508\n",
      "Epoch 76/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 29.3067\n",
      "Epoch 76: val_loss did not improve from 702.05078\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 29.6529 - val_loss: 705.2703\n",
      "Epoch 77/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 29.7912\n",
      "Epoch 77: val_loss improved from 702.05078 to 679.31781, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 29.7062 - val_loss: 679.3178\n",
      "Epoch 78/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 28.7353\n",
      "Epoch 78: val_loss improved from 679.31781 to 670.19922, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 29.2697 - val_loss: 670.1992\n",
      "Epoch 79/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 29.7022\n",
      "Epoch 79: val_loss improved from 670.19922 to 655.80225, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 29.6820 - val_loss: 655.8022\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 26.2272\n",
      "Epoch 80: val_loss did not improve from 655.80225\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 26.2272 - val_loss: 656.4905\n",
      "Epoch 81/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 25.7276\n",
      "Epoch 81: val_loss improved from 655.80225 to 631.50970, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 25.7794 - val_loss: 631.5097\n",
      "Epoch 82/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 23.7088\n",
      "Epoch 82: val_loss improved from 631.50970 to 616.13470, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 24.0779 - val_loss: 616.1347\n",
      "Epoch 83/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 22.1325\n",
      "Epoch 83: val_loss improved from 616.13470 to 603.64166, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 22.4008 - val_loss: 603.6417\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 24.3922\n",
      "Epoch 84: val_loss improved from 603.64166 to 589.56732, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 24.3922 - val_loss: 589.5673\n",
      "Epoch 85/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 23.0880\n",
      "Epoch 85: val_loss improved from 589.56732 to 579.62903, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 22.9051 - val_loss: 579.6290\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 22.8450\n",
      "Epoch 86: val_loss improved from 579.62903 to 573.99829, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 22.8450 - val_loss: 573.9983\n",
      "Epoch 87/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 21.4975\n",
      "Epoch 87: val_loss improved from 573.99829 to 551.62408, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 21.5298 - val_loss: 551.6241\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 23.3060\n",
      "Epoch 88: val_loss improved from 551.62408 to 543.83234, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 23.3060 - val_loss: 543.8323\n",
      "Epoch 89/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 21.0926\n",
      "Epoch 89: val_loss improved from 543.83234 to 531.01544, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 20.8901 - val_loss: 531.0154\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 30.1661\n",
      "Epoch 90: val_loss improved from 531.01544 to 517.58405, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 30.1661 - val_loss: 517.5840\n",
      "Epoch 91/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 24.2087\n",
      "Epoch 91: val_loss did not improve from 517.58405\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 24.0327 - val_loss: 518.5392\n",
      "Epoch 92/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 19.4928\n",
      "Epoch 92: val_loss improved from 517.58405 to 511.43518, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 19.4274 - val_loss: 511.4352\n",
      "Epoch 93/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 19.7810\n",
      "Epoch 93: val_loss did not improve from 511.43518\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 19.8089 - val_loss: 522.2828\n",
      "Epoch 94/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 19.7705\n",
      "Epoch 94: val_loss improved from 511.43518 to 491.44464, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 19.4679 - val_loss: 491.4446\n",
      "Epoch 95/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 19.8045\n",
      "Epoch 95: val_loss improved from 491.44464 to 479.98914, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 19.5559 - val_loss: 479.9891\n",
      "Epoch 96/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 17.6541\n",
      "Epoch 96: val_loss improved from 479.98914 to 468.89322, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 17.5463 - val_loss: 468.8932\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 18.0001\n",
      "Epoch 97: val_loss improved from 468.89322 to 464.93625, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 18.0001 - val_loss: 464.9362\n",
      "Epoch 98/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 19.5875\n",
      "Epoch 98: val_loss improved from 464.93625 to 452.40164, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 19.3660 - val_loss: 452.4016\n",
      "Epoch 99/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 20.8769\n",
      "Epoch 99: val_loss did not improve from 452.40164\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 21.0129 - val_loss: 453.6903\n",
      "Epoch 100/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.0035\n",
      "Epoch 100: val_loss improved from 452.40164 to 448.70996, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 17.5796 - val_loss: 448.7100\n",
      "Epoch 101/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.2751\n",
      "Epoch 101: val_loss improved from 448.70996 to 427.55182, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 17.1082 - val_loss: 427.5518\n",
      "Epoch 102/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.4023\n",
      "Epoch 102: val_loss improved from 427.55182 to 420.06201, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 30ms/step - loss: 17.2920 - val_loss: 420.0620\n",
      "Epoch 103/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.4991\n",
      "Epoch 103: val_loss improved from 420.06201 to 418.41263, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 17.4021 - val_loss: 418.4126\n",
      "Epoch 104/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 17.3486\n",
      "Epoch 104: val_loss improved from 418.41263 to 410.51819, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 17.2180 - val_loss: 410.5182\n",
      "Epoch 105/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 17.9215\n",
      "Epoch 105: val_loss improved from 410.51819 to 396.66101, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 17.3359 - val_loss: 396.6610\n",
      "Epoch 106/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 15.7200\n",
      "Epoch 106: val_loss improved from 396.66101 to 393.05179, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 15.8354 - val_loss: 393.0518\n",
      "Epoch 107/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.1941\n",
      "Epoch 107: val_loss improved from 393.05179 to 384.93826, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 15.6810 - val_loss: 384.9383\n",
      "Epoch 108/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.8189\n",
      "Epoch 108: val_loss improved from 384.93826 to 376.90112, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 14.9077 - val_loss: 376.9011\n",
      "Epoch 109/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 14.1343\n",
      "Epoch 109: val_loss improved from 376.90112 to 375.79147, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 14.7428 - val_loss: 375.7915\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.7424\n",
      "Epoch 110: val_loss improved from 375.79147 to 364.20615, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 14.7424 - val_loss: 364.2061\n",
      "Epoch 111/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.5167\n",
      "Epoch 111: val_loss improved from 364.20615 to 363.52301, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 16.6885 - val_loss: 363.5230\n",
      "Epoch 112/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.5598\n",
      "Epoch 112: val_loss improved from 363.52301 to 355.26193, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 14.3875 - val_loss: 355.2619\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 13.5027\n",
      "Epoch 113: val_loss improved from 355.26193 to 349.64856, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 13.5027 - val_loss: 349.6486\n",
      "Epoch 114/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.7552\n",
      "Epoch 114: val_loss improved from 349.64856 to 348.35080, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 17.7823 - val_loss: 348.3508\n",
      "Epoch 115/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 13.5966\n",
      "Epoch 115: val_loss improved from 348.35080 to 339.27716, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 13.6689 - val_loss: 339.2772\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.4224\n",
      "Epoch 116: val_loss improved from 339.27716 to 335.37759, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 13.2464 - val_loss: 335.3776\n",
      "Epoch 117/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.0335\n",
      "Epoch 117: val_loss improved from 335.37759 to 324.92520, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 12.1166 - val_loss: 324.9252\n",
      "Epoch 118/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 13.1536\n",
      "Epoch 118: val_loss did not improve from 324.92520\n",
      "37/37 [==============================] - 1s 29ms/step - loss: 13.3131 - val_loss: 328.4581\n",
      "Epoch 119/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.1883\n",
      "Epoch 119: val_loss improved from 324.92520 to 318.41736, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 12.5187 - val_loss: 318.4174\n",
      "Epoch 120/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 13.1329\n",
      "Epoch 120: val_loss improved from 318.41736 to 310.48846, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 13.0816 - val_loss: 310.4885\n",
      "Epoch 121/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.8695\n",
      "Epoch 121: val_loss did not improve from 310.48846\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 14.5376 - val_loss: 324.2462\n",
      "Epoch 122/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.2121\n",
      "Epoch 122: val_loss did not improve from 310.48846\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 15.8392 - val_loss: 310.5854\n",
      "Epoch 123/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 10.8580\n",
      "Epoch 123: val_loss improved from 310.48846 to 301.51147, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 11.1033 - val_loss: 301.5115\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8304\n",
      "Epoch 124: val_loss improved from 301.51147 to 297.35410, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 10.8304 - val_loss: 297.3541\n",
      "Epoch 125/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.2936\n",
      "Epoch 125: val_loss improved from 297.35410 to 291.64169, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 10.5108 - val_loss: 291.6417\n",
      "Epoch 126/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.3489\n",
      "Epoch 126: val_loss improved from 291.64169 to 288.26968, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 11.5397 - val_loss: 288.2697\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.5083\n",
      "Epoch 127: val_loss improved from 288.26968 to 284.95157, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 12.5083 - val_loss: 284.9516\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.0610\n",
      "Epoch 128: val_loss did not improve from 284.95157\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 12.0610 - val_loss: 293.5299\n",
      "Epoch 129/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.4357\n",
      "Epoch 129: val_loss did not improve from 284.95157\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 10.9767 - val_loss: 342.2234\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.1657\n",
      "Epoch 130: val_loss improved from 284.95157 to 277.70740, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 14.1657 - val_loss: 277.7074\n",
      "Epoch 131/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.5356\n",
      "Epoch 131: val_loss improved from 277.70740 to 269.15152, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 11.4269 - val_loss: 269.1515\n",
      "Epoch 132/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.3251\n",
      "Epoch 132: val_loss improved from 269.15152 to 266.00790, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 9.2415 - val_loss: 266.0079\n",
      "Epoch 133/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.7728\n",
      "Epoch 133: val_loss improved from 266.00790 to 263.38266, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 9.7519 - val_loss: 263.3827\n",
      "Epoch 134/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.4261\n",
      "Epoch 134: val_loss improved from 263.38266 to 260.60590, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 10.3339 - val_loss: 260.6059\n",
      "Epoch 135/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 8.3732\n",
      "Epoch 135: val_loss improved from 260.60590 to 257.95563, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.3143 - val_loss: 257.9556\n",
      "Epoch 136/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.6028\n",
      "Epoch 136: val_loss improved from 257.95563 to 254.97134, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 8.5691 - val_loss: 254.9713\n",
      "Epoch 137/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.3814\n",
      "Epoch 137: val_loss improved from 254.97134 to 252.66461, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 8.4721 - val_loss: 252.6646\n",
      "Epoch 138/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.1155\n",
      "Epoch 138: val_loss did not improve from 252.66461\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 9.3830 - val_loss: 257.3841\n",
      "Epoch 139/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.0789\n",
      "Epoch 139: val_loss improved from 252.66461 to 250.79762, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 9.8280 - val_loss: 250.7976\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.5096\n",
      "Epoch 140: val_loss improved from 250.79762 to 246.45428, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 9.5096 - val_loss: 246.4543\n",
      "Epoch 141/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.8183\n",
      "Epoch 141: val_loss improved from 246.45428 to 243.66280, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.7577 - val_loss: 243.6628\n",
      "Epoch 142/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.2381\n",
      "Epoch 142: val_loss improved from 243.66280 to 242.46268, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.3840 - val_loss: 242.4627\n",
      "Epoch 143/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.8955\n",
      "Epoch 143: val_loss improved from 242.46268 to 240.00070, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.8621 - val_loss: 240.0007\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.7837\n",
      "Epoch 144: val_loss did not improve from 240.00070\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.7837 - val_loss: 242.3361\n",
      "Epoch 145/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.0685\n",
      "Epoch 145: val_loss improved from 240.00070 to 236.67950, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.0417 - val_loss: 236.6795\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.4929\n",
      "Epoch 146: val_loss improved from 236.67950 to 233.98422, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.4929 - val_loss: 233.9842\n",
      "Epoch 147/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.8505\n",
      "Epoch 147: val_loss did not improve from 233.98422\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.7881 - val_loss: 234.4402\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.4451\n",
      "Epoch 148: val_loss improved from 233.98422 to 233.48985, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.4451 - val_loss: 233.4899\n",
      "Epoch 149/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.2149\n",
      "Epoch 149: val_loss improved from 233.48985 to 233.28787, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.5295 - val_loss: 233.2879\n",
      "Epoch 150/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.8307\n",
      "Epoch 150: val_loss improved from 233.28787 to 230.76909, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.8725 - val_loss: 230.7691\n",
      "Epoch 151/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.3394\n",
      "Epoch 151: val_loss improved from 230.76909 to 228.35744, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 7.2954 - val_loss: 228.3574\n",
      "Epoch 152/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.4873\n",
      "Epoch 152: val_loss did not improve from 228.35744\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.3382 - val_loss: 228.8534\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.1601\n",
      "Epoch 153: val_loss improved from 228.35744 to 226.06339, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.1601 - val_loss: 226.0634\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.1429\n",
      "Epoch 154: val_loss improved from 226.06339 to 225.71164, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 7.1429 - val_loss: 225.7116\n",
      "Epoch 155/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.7526\n",
      "Epoch 155: val_loss improved from 225.71164 to 223.69482, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.7677 - val_loss: 223.6948\n",
      "Epoch 156/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.9710\n",
      "Epoch 156: val_loss did not improve from 223.69482\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.8417 - val_loss: 236.1303\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.6643\n",
      "Epoch 157: val_loss improved from 223.69482 to 215.28311, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.6643 - val_loss: 215.2831\n",
      "Epoch 158/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.1722\n",
      "Epoch 158: val_loss did not improve from 215.28311\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.1575 - val_loss: 233.6285\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.6841\n",
      "Epoch 159: val_loss improved from 215.28311 to 213.59074, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 7.6841 - val_loss: 213.5907\n",
      "Epoch 160/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.3783\n",
      "Epoch 160: val_loss improved from 213.59074 to 211.44629, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.3333 - val_loss: 211.4463\n",
      "Epoch 161/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.4835\n",
      "Epoch 161: val_loss did not improve from 211.44629\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.4495 - val_loss: 211.5206\n",
      "Epoch 162/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.5727\n",
      "Epoch 162: val_loss did not improve from 211.44629\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.5818 - val_loss: 213.0463\n",
      "Epoch 163/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.4972\n",
      "Epoch 163: val_loss did not improve from 211.44629\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.3612 - val_loss: 219.1638\n",
      "Epoch 164/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.6895\n",
      "Epoch 164: val_loss improved from 211.44629 to 208.71022, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.6736 - val_loss: 208.7102\n",
      "Epoch 165/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.0346\n",
      "Epoch 165: val_loss improved from 208.71022 to 207.89297, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.9566 - val_loss: 207.8930\n",
      "Epoch 166/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.7358\n",
      "Epoch 166: val_loss did not improve from 207.89297\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.6641 - val_loss: 208.3127\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6540\n",
      "Epoch 167: val_loss did not improve from 207.89297\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.6540 - val_loss: 214.6026\n",
      "Epoch 168/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1810\n",
      "Epoch 168: val_loss improved from 207.89297 to 205.22313, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 6.0799 - val_loss: 205.2231\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.3388\n",
      "Epoch 169: val_loss improved from 205.22313 to 204.51872, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.3388 - val_loss: 204.5187\n",
      "Epoch 170/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8209\n",
      "Epoch 170: val_loss improved from 204.51872 to 203.60098, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.7915 - val_loss: 203.6010\n",
      "Epoch 171/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.4064\n",
      "Epoch 171: val_loss did not improve from 203.60098\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.4497 - val_loss: 206.0824\n",
      "Epoch 172/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.9065\n",
      "Epoch 172: val_loss did not improve from 203.60098\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.1052 - val_loss: 204.0285\n",
      "Epoch 173/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.8729\n",
      "Epoch 173: val_loss did not improve from 203.60098\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.9099 - val_loss: 222.8713\n",
      "Epoch 174/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.1002\n",
      "Epoch 174: val_loss improved from 203.60098 to 203.09488, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.9415 - val_loss: 203.0949\n",
      "Epoch 175/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7867\n",
      "Epoch 175: val_loss did not improve from 203.09488\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.7080 - val_loss: 218.7383\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.8429\n",
      "Epoch 176: val_loss improved from 203.09488 to 199.63641, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.8429 - val_loss: 199.6364\n",
      "Epoch 177/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 9.7641 \n",
      "Epoch 177: val_loss improved from 199.63641 to 197.58176, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 9.8126 - val_loss: 197.5818\n",
      "Epoch 178/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.9304\n",
      "Epoch 178: val_loss did not improve from 197.58176\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.9907 - val_loss: 197.9953\n",
      "Epoch 179/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.9119\n",
      "Epoch 179: val_loss did not improve from 197.58176\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9140 - val_loss: 202.3145\n",
      "Epoch 180/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.5924\n",
      "Epoch 180: val_loss did not improve from 197.58176\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.6053 - val_loss: 197.9061\n",
      "Epoch 181/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3299\n",
      "Epoch 181: val_loss did not improve from 197.58176\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3305 - val_loss: 197.9968\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4566\n",
      "Epoch 182: val_loss improved from 197.58176 to 194.50201, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.4566 - val_loss: 194.5020\n",
      "Epoch 183/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.5608\n",
      "Epoch 183: val_loss improved from 194.50201 to 193.52385, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.4674 - val_loss: 193.5238\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.3034\n",
      "Epoch 184: val_loss did not improve from 193.52385\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.3034 - val_loss: 193.5981\n",
      "Epoch 185/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4149\n",
      "Epoch 185: val_loss improved from 193.52385 to 193.27716, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.3719 - val_loss: 193.2772\n",
      "Epoch 186/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4154\n",
      "Epoch 186: val_loss did not improve from 193.27716\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.3859 - val_loss: 194.8106\n",
      "Epoch 187/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.3109\n",
      "Epoch 187: val_loss did not improve from 193.27716\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.8186 - val_loss: 193.7448\n",
      "Epoch 188/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.2396\n",
      "Epoch 188: val_loss improved from 193.27716 to 191.80548, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.3258 - val_loss: 191.8055\n",
      "Epoch 189/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6374\n",
      "Epoch 189: val_loss did not improve from 191.80548\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.5600 - val_loss: 198.5024\n",
      "Epoch 190/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7335\n",
      "Epoch 190: val_loss did not improve from 191.80548\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.7134 - val_loss: 192.7724\n",
      "Epoch 191/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.3032\n",
      "Epoch 191: val_loss improved from 191.80548 to 190.89095, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.2248 - val_loss: 190.8909\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0552\n",
      "Epoch 192: val_loss improved from 190.89095 to 187.03017, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.0552 - val_loss: 187.0302\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1050\n",
      "Epoch 193: val_loss improved from 187.03017 to 186.68623, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.1050 - val_loss: 186.6862\n",
      "Epoch 194/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.6196\n",
      "Epoch 194: val_loss did not improve from 186.68623\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.5228 - val_loss: 205.4845\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.5024\n",
      "Epoch 195: val_loss did not improve from 186.68623\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.5024 - val_loss: 191.1746\n",
      "Epoch 196/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4162\n",
      "Epoch 196: val_loss improved from 186.68623 to 183.02162, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.4109 - val_loss: 183.0216\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.2786\n",
      "Epoch 197: val_loss improved from 183.02162 to 180.04152, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.2786 - val_loss: 180.0415\n",
      "Epoch 198/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.6340\n",
      "Epoch 198: val_loss did not improve from 180.04152\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.5133 - val_loss: 187.0564\n",
      "Epoch 199/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3224\n",
      "Epoch 199: val_loss did not improve from 180.04152\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.3231 - val_loss: 185.0766\n",
      "Epoch 200/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3759\n",
      "Epoch 200: val_loss did not improve from 180.04152\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3492 - val_loss: 182.5269\n",
      "Epoch 201/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.3599\n",
      "Epoch 201: val_loss improved from 180.04152 to 176.03041, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 5.3003 - val_loss: 176.0304\n",
      "Epoch 202/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.9952\n",
      "Epoch 202: val_loss did not improve from 176.03041\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.7880 - val_loss: 184.1535\n",
      "Epoch 203/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.1217\n",
      "Epoch 203: val_loss did not improve from 176.03041\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 9.2214 - val_loss: 176.2380\n",
      "Epoch 204/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.1972\n",
      "Epoch 204: val_loss did not improve from 176.03041\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.1248 - val_loss: 183.3100\n",
      "Epoch 205/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.3077\n",
      "Epoch 205: val_loss improved from 176.03041 to 175.69281, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.2323 - val_loss: 175.6928\n",
      "Epoch 206/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3662\n",
      "Epoch 206: val_loss improved from 175.69281 to 173.78978, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3200 - val_loss: 173.7898\n",
      "Epoch 207/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3588\n",
      "Epoch 207: val_loss did not improve from 173.78978\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.3128 - val_loss: 176.6777\n",
      "Epoch 208/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9933\n",
      "Epoch 208: val_loss improved from 173.78978 to 171.82962, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.9434 - val_loss: 171.8296\n",
      "Epoch 209/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.9898\n",
      "Epoch 209: val_loss improved from 171.82962 to 170.69930, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.9437 - val_loss: 170.6993\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0142\n",
      "Epoch 210: val_loss improved from 170.69930 to 169.61247, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.0142 - val_loss: 169.6125\n",
      "Epoch 211/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.9666\n",
      "Epoch 211: val_loss did not improve from 169.61247\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.9320 - val_loss: 177.0788\n",
      "Epoch 212/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7745\n",
      "Epoch 212: val_loss improved from 169.61247 to 166.27364, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.7523 - val_loss: 166.2736\n",
      "Epoch 213/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9952\n",
      "Epoch 213: val_loss did not improve from 166.27364\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.9801 - val_loss: 166.8235\n",
      "Epoch 214/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1309\n",
      "Epoch 214: val_loss did not improve from 166.27364\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.1071 - val_loss: 167.9708\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.3928\n",
      "Epoch 215: val_loss did not improve from 166.27364\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.3928 - val_loss: 167.6219\n",
      "Epoch 216/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4129\n",
      "Epoch 216: val_loss improved from 166.27364 to 165.44807, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.3025 - val_loss: 165.4481\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1108\n",
      "Epoch 217: val_loss did not improve from 165.44807\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.1108 - val_loss: 166.1069\n",
      "Epoch 218/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7976\n",
      "Epoch 218: val_loss did not improve from 165.44807\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7687 - val_loss: 180.8043\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1074\n",
      "Epoch 219: val_loss improved from 165.44807 to 164.44258, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.1074 - val_loss: 164.4426\n",
      "Epoch 220/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4131\n",
      "Epoch 220: val_loss did not improve from 164.44258\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.4370 - val_loss: 173.6334\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3631\n",
      "Epoch 221: val_loss improved from 164.44258 to 162.46407, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.3631 - val_loss: 162.4641\n",
      "Epoch 222/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.7117\n",
      "Epoch 222: val_loss did not improve from 162.46407\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7646 - val_loss: 171.2193\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5146\n",
      "Epoch 223: val_loss improved from 162.46407 to 161.69035, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.5146 - val_loss: 161.6904\n",
      "Epoch 224/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7657\n",
      "Epoch 224: val_loss did not improve from 161.69035\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7432 - val_loss: 166.5464\n",
      "Epoch 225/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2582\n",
      "Epoch 225: val_loss improved from 161.69035 to 159.91298, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.2848 - val_loss: 159.9130\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4183\n",
      "Epoch 226: val_loss did not improve from 159.91298\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.4183 - val_loss: 160.3888\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5124\n",
      "Epoch 227: val_loss did not improve from 159.91298\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.5124 - val_loss: 160.1899\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1719\n",
      "Epoch 228: val_loss did not improve from 159.91298\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.1719 - val_loss: 166.3325\n",
      "Epoch 229/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4127\n",
      "Epoch 229: val_loss improved from 159.91298 to 155.86751, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.5382 - val_loss: 155.8675\n",
      "Epoch 230/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3089\n",
      "Epoch 230: val_loss improved from 155.86751 to 154.22757, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.2645 - val_loss: 154.2276\n",
      "Epoch 231/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.0938\n",
      "Epoch 231: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.0308 - val_loss: 154.9928\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4290\n",
      "Epoch 232: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.4290 - val_loss: 196.6176\n",
      "Epoch 233/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1810\n",
      "Epoch 233: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.2548 - val_loss: 161.5989\n",
      "Epoch 234/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.7175\n",
      "Epoch 234: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.6749 - val_loss: 154.7836\n",
      "Epoch 235/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6491\n",
      "Epoch 235: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.6676 - val_loss: 159.6705\n",
      "Epoch 236/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3301\n",
      "Epoch 236: val_loss did not improve from 154.22757\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.3525 - val_loss: 161.0857\n",
      "Epoch 237/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1064\n",
      "Epoch 237: val_loss improved from 154.22757 to 151.45442, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.0796 - val_loss: 151.4544\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3368\n",
      "Epoch 238: val_loss did not improve from 151.45442\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.3368 - val_loss: 160.0015\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1184\n",
      "Epoch 239: val_loss improved from 151.45442 to 148.90459, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.1184 - val_loss: 148.9046\n",
      "Epoch 240/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1907\n",
      "Epoch 240: val_loss did not improve from 148.90459\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2154 - val_loss: 156.2649\n",
      "Epoch 241/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.2694\n",
      "Epoch 241: val_loss improved from 148.90459 to 147.23146, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.4124 - val_loss: 147.2315\n",
      "Epoch 242/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4414\n",
      "Epoch 242: val_loss improved from 147.23146 to 145.55107, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.4067 - val_loss: 145.5511\n",
      "Epoch 243/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0458\n",
      "Epoch 243: val_loss did not improve from 145.55107\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2425 - val_loss: 149.2217\n",
      "Epoch 244/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7068\n",
      "Epoch 244: val_loss did not improve from 145.55107\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7617 - val_loss: 147.8013\n",
      "Epoch 245/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3909\n",
      "Epoch 245: val_loss did not improve from 145.55107\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.3414 - val_loss: 145.9956\n",
      "Epoch 246/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7317\n",
      "Epoch 246: val_loss did not improve from 145.55107\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.9405 - val_loss: 146.9729\n",
      "Epoch 247/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2134\n",
      "Epoch 247: val_loss improved from 145.55107 to 142.58754, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.0740 - val_loss: 142.5875\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3140\n",
      "Epoch 248: val_loss did not improve from 142.58754\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.3140 - val_loss: 144.5970\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4465\n",
      "Epoch 249: val_loss did not improve from 142.58754\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.4465 - val_loss: 143.6458\n",
      "Epoch 250/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1453\n",
      "Epoch 250: val_loss improved from 142.58754 to 138.23264, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.1193 - val_loss: 138.2326\n",
      "Epoch 251/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5566\n",
      "Epoch 251: val_loss did not improve from 138.23264\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.4830 - val_loss: 141.1019\n",
      "Epoch 252/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9182\n",
      "Epoch 252: val_loss did not improve from 138.23264\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.9913 - val_loss: 140.9749\n",
      "Epoch 253/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9904\n",
      "Epoch 253: val_loss did not improve from 138.23264\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.0573 - val_loss: 141.7291\n",
      "Epoch 254/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4262\n",
      "Epoch 254: val_loss improved from 138.23264 to 138.22508, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.3976 - val_loss: 138.2251\n",
      "Epoch 255/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2940\n",
      "Epoch 255: val_loss did not improve from 138.22508\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.1727 - val_loss: 142.4276\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9794\n",
      "Epoch 256: val_loss did not improve from 138.22508\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9794 - val_loss: 143.5686\n",
      "Epoch 257/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.2328\n",
      "Epoch 257: val_loss did not improve from 138.22508\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2264 - val_loss: 140.1314\n",
      "Epoch 258/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9196\n",
      "Epoch 258: val_loss improved from 138.22508 to 138.10159, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.8947 - val_loss: 138.1016\n",
      "Epoch 259/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2173\n",
      "Epoch 259: val_loss did not improve from 138.10159\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.1873 - val_loss: 139.0158\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3205\n",
      "Epoch 260: val_loss did not improve from 138.10159\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.3205 - val_loss: 141.2627\n",
      "Epoch 261/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0757\n",
      "Epoch 261: val_loss improved from 138.10159 to 136.74818, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.0755 - val_loss: 136.7482\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.2611\n",
      "Epoch 262: val_loss improved from 136.74818 to 135.70084, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.2611 - val_loss: 135.7008\n",
      "Epoch 263/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8707\n",
      "Epoch 263: val_loss did not improve from 135.70084\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8693 - val_loss: 140.8283\n",
      "Epoch 264/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4063\n",
      "Epoch 264: val_loss improved from 135.70084 to 132.91095, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.3780 - val_loss: 132.9109\n",
      "Epoch 265/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8769\n",
      "Epoch 265: val_loss did not improve from 132.91095\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8649 - val_loss: 146.1438\n",
      "Epoch 266/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.2323\n",
      "Epoch 266: val_loss did not improve from 132.91095\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2808 - val_loss: 136.0862\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.2534\n",
      "Epoch 267: val_loss improved from 132.91095 to 130.73953, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.2534 - val_loss: 130.7395\n",
      "Epoch 268/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9080\n",
      "Epoch 268: val_loss improved from 130.73953 to 129.65323, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.8429 - val_loss: 129.6532\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.6777\n",
      "Epoch 269: val_loss did not improve from 129.65323\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.6777 - val_loss: 136.8001\n",
      "Epoch 270/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.6660\n",
      "Epoch 270: val_loss did not improve from 129.65323\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.6229 - val_loss: 140.3779\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0941\n",
      "Epoch 271: val_loss improved from 129.65323 to 128.15468, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.0941 - val_loss: 128.1547\n",
      "Epoch 272/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8483\n",
      "Epoch 272: val_loss did not improve from 128.15468\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8852 - val_loss: 128.9743\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5305\n",
      "Epoch 273: val_loss did not improve from 128.15468\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5305 - val_loss: 134.3184\n",
      "Epoch 274/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6161\n",
      "Epoch 274: val_loss did not improve from 128.15468\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5922 - val_loss: 129.1965\n",
      "Epoch 275/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5961\n",
      "Epoch 275: val_loss improved from 128.15468 to 127.44006, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5800 - val_loss: 127.4401\n",
      "Epoch 276/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9005\n",
      "Epoch 276: val_loss improved from 127.44006 to 126.76942, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8844 - val_loss: 126.7694\n",
      "Epoch 277/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9458\n",
      "Epoch 277: val_loss improved from 126.76942 to 123.68784, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9551 - val_loss: 123.6878\n",
      "Epoch 278/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8646\n",
      "Epoch 278: val_loss did not improve from 123.68784\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8965 - val_loss: 135.7326\n",
      "Epoch 279/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1707\n",
      "Epoch 279: val_loss did not improve from 123.68784\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.1242 - val_loss: 127.3351\n",
      "Epoch 280/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8248\n",
      "Epoch 280: val_loss improved from 123.68784 to 117.57492, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.8479 - val_loss: 117.5749\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8942\n",
      "Epoch 281: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8942 - val_loss: 121.5647\n",
      "Epoch 282/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5934\n",
      "Epoch 282: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.7108 - val_loss: 120.0992\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0872\n",
      "Epoch 283: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.0872 - val_loss: 120.9030\n",
      "Epoch 284/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0656\n",
      "Epoch 284: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.0106 - val_loss: 140.4070\n",
      "Epoch 285/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8474\n",
      "Epoch 285: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9669 - val_loss: 119.8537\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7258\n",
      "Epoch 286: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7258 - val_loss: 124.7453\n",
      "Epoch 287/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3749\n",
      "Epoch 287: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3618 - val_loss: 121.2664\n",
      "Epoch 288/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3519\n",
      "Epoch 288: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3948 - val_loss: 128.0410\n",
      "Epoch 289/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3963\n",
      "Epoch 289: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6620 - val_loss: 119.5617\n",
      "Epoch 290/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2933\n",
      "Epoch 290: val_loss did not improve from 117.57492\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.4501 - val_loss: 126.7896\n",
      "Epoch 291/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.2762\n",
      "Epoch 291: val_loss improved from 117.57492 to 117.39165, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.2554 - val_loss: 117.3916\n",
      "Epoch 292/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6220\n",
      "Epoch 292: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6100 - val_loss: 125.9252\n",
      "Epoch 293/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1977\n",
      "Epoch 293: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2167 - val_loss: 125.6673\n",
      "Epoch 294/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4272\n",
      "Epoch 294: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4355 - val_loss: 119.2552\n",
      "Epoch 295/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3513\n",
      "Epoch 295: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3627 - val_loss: 117.6499\n",
      "Epoch 296/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4798\n",
      "Epoch 296: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5955 - val_loss: 126.3658\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8229\n",
      "Epoch 297: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.8229 - val_loss: 128.4092\n",
      "Epoch 298/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9404\n",
      "Epoch 298: val_loss did not improve from 117.39165\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9218 - val_loss: 119.9689\n",
      "Epoch 299/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8587\n",
      "Epoch 299: val_loss improved from 117.39165 to 115.17485, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.8938 - val_loss: 115.1749\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2480\n",
      "Epoch 300: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2480 - val_loss: 119.0042\n",
      "Epoch 301/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2396\n",
      "Epoch 301: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2008 - val_loss: 121.9599\n",
      "Epoch 302/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1007\n",
      "Epoch 302: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2811 - val_loss: 120.6025\n",
      "Epoch 303/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7641\n",
      "Epoch 303: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.7664 - val_loss: 118.0256\n",
      "Epoch 304/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5817\n",
      "Epoch 304: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.6044 - val_loss: 118.1370\n",
      "Epoch 305/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7823\n",
      "Epoch 305: val_loss did not improve from 115.17485\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7208 - val_loss: 128.0589\n",
      "Epoch 306/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9117\n",
      "Epoch 306: val_loss improved from 115.17485 to 113.36702, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.8861 - val_loss: 113.3670\n",
      "Epoch 307/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2843\n",
      "Epoch 307: val_loss did not improve from 113.36702\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3188 - val_loss: 118.7747\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1945\n",
      "Epoch 308: val_loss did not improve from 113.36702\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1945 - val_loss: 118.1662\n",
      "Epoch 309/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0358\n",
      "Epoch 309: val_loss did not improve from 113.36702\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0303 - val_loss: 122.7394\n",
      "Epoch 310/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3642\n",
      "Epoch 310: val_loss improved from 113.36702 to 109.45792, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 3.4444 - val_loss: 109.4579\n",
      "Epoch 311/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5083\n",
      "Epoch 311: val_loss did not improve from 109.45792\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4478 - val_loss: 116.9131\n",
      "Epoch 312/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0291\n",
      "Epoch 312: val_loss did not improve from 109.45792\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.5263 - val_loss: 136.4108\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.6170\n",
      "Epoch 313: val_loss improved from 109.45792 to 108.95947, saving model to Best_BiLSTM_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.6170 - val_loss: 108.9595\n",
      "Epoch 314/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.7879\n",
      "Epoch 314: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.8267 - val_loss: 117.2439\n",
      "Epoch 315/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2506\n",
      "Epoch 315: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2012 - val_loss: 114.3073\n",
      "Epoch 316/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6848\n",
      "Epoch 316: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7350 - val_loss: 109.8652\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6258\n",
      "Epoch 317: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.6258 - val_loss: 114.8481\n",
      "Epoch 318/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1562\n",
      "Epoch 318: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3405 - val_loss: 113.9610\n",
      "Epoch 319/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1998\n",
      "Epoch 319: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2055 - val_loss: 111.2365\n",
      "Epoch 320/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6518\n",
      "Epoch 320: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6396 - val_loss: 121.4390\n",
      "Epoch 321/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2728\n",
      "Epoch 321: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2347 - val_loss: 116.9733\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0615\n",
      "Epoch 322: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0615 - val_loss: 114.7246\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3436\n",
      "Epoch 323: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3436 - val_loss: 114.6128\n",
      "Epoch 324/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8592\n",
      "Epoch 324: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8664 - val_loss: 120.5016\n",
      "Epoch 325/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2803\n",
      "Epoch 325: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2737 - val_loss: 111.1181\n",
      "Epoch 326/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3123\n",
      "Epoch 326: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2804 - val_loss: 123.2723\n",
      "Epoch 327/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1027\n",
      "Epoch 327: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0758 - val_loss: 114.6079\n",
      "Epoch 328/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9563\n",
      "Epoch 328: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.9239 - val_loss: 120.1837\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2341\n",
      "Epoch 329: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2341 - val_loss: 116.9745\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3081\n",
      "Epoch 330: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3081 - val_loss: 121.5524\n",
      "Epoch 331/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8147\n",
      "Epoch 331: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7273 - val_loss: 114.4491\n",
      "Epoch 332/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3733\n",
      "Epoch 332: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3598 - val_loss: 127.2223\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3654\n",
      "Epoch 333: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3654 - val_loss: 115.0367\n",
      "Epoch 334/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9561\n",
      "Epoch 334: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9487 - val_loss: 117.3174\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2447\n",
      "Epoch 335: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2447 - val_loss: 114.7181\n",
      "Epoch 336/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4661\n",
      "Epoch 336: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.4184 - val_loss: 111.6756\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1705\n",
      "Epoch 337: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1705 - val_loss: 110.4992\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9874\n",
      "Epoch 338: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.9874 - val_loss: 109.0090\n",
      "Epoch 339/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6698\n",
      "Epoch 339: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.6669 - val_loss: 123.1464\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2271\n",
      "Epoch 340: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2271 - val_loss: 112.8816\n",
      "Epoch 341/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7566\n",
      "Epoch 341: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.7354 - val_loss: 117.8363\n",
      "Epoch 342/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9316\n",
      "Epoch 342: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9781 - val_loss: 112.4457\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1944\n",
      "Epoch 343: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1944 - val_loss: 118.6831\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0242\n",
      "Epoch 344: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0242 - val_loss: 117.3230\n",
      "Epoch 345/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7351\n",
      "Epoch 345: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8403 - val_loss: 117.3977\n",
      "Epoch 346/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9975\n",
      "Epoch 346: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9770 - val_loss: 112.1548\n",
      "Epoch 347/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4596\n",
      "Epoch 347: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4588 - val_loss: 121.1432\n",
      "Epoch 348/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9264\n",
      "Epoch 348: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9850 - val_loss: 125.9377\n",
      "Epoch 349/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9074\n",
      "Epoch 349: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9693 - val_loss: 120.2218\n",
      "Epoch 350/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1317\n",
      "Epoch 350: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1350 - val_loss: 122.8516\n",
      "Epoch 351/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4088\n",
      "Epoch 351: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3814 - val_loss: 118.2623\n",
      "Epoch 352/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1555\n",
      "Epoch 352: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3166 - val_loss: 124.4216\n",
      "Epoch 353/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5158\n",
      "Epoch 353: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.4992 - val_loss: 117.7502\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8032\n",
      "Epoch 354: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8032 - val_loss: 124.6427\n",
      "Epoch 355/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8014\n",
      "Epoch 355: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.8280 - val_loss: 115.7485\n",
      "Epoch 356/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4122\n",
      "Epoch 356: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3620 - val_loss: 112.4573\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9328\n",
      "Epoch 357: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9328 - val_loss: 121.7156\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6228\n",
      "Epoch 358: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6228 - val_loss: 114.1781\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1000\n",
      "Epoch 359: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1000 - val_loss: 120.3175\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7486\n",
      "Epoch 360: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.7486 - val_loss: 134.5270\n",
      "Epoch 361/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0740\n",
      "Epoch 361: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0742 - val_loss: 122.0676\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7868\n",
      "Epoch 362: val_loss did not improve from 108.95947\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.7868 - val_loss: 120.0694\n",
      "Epoch 363/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2308\n",
      "Epoch 363: val_loss did not improve from 108.95947\n",
      "Restoring model weights from the end of the best epoch: 313.\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.2765 - val_loss: 114.7643\n",
      "Epoch 363: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "bi_lstm_adam_model = TimeSeriesModel(model_type='bi_lstm')\n",
    "# Train the model\n",
    "bi_lstm_adam_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_BiLSTM_Model_ADAM_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f17a699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = bi_lstm_adam_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39ba65fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.873805938866253\n",
      "R2 Score: 0.36029990233547293\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd8d5425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAHUCAYAAAAwUBnrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADn5UlEQVR4nOydd3wT9f/HX2mb7kVpS2kppew9ZCkb2RtRUBHZjp8DQXHgQFCRIYoCIihLhqJ82VL2RkD23lA2HRToHmlzvz/efHpJmrRJmtm+n49HHne5u9x9crm7fF6f91JIkiSBYRiGYRiGYRiGMRoXezeAYRiGYRiGYRjG2WAhxTAMwzAMwzAMYyIspBiGYRiGYRiGYUyEhRTDMAzDMAzDMIyJsJBiGIZhGIZhGIYxERZSDMMwDMMwDMMwJsJCimEYhmEYhmEYxkRYSDEMwzAMwzAMw5gICymGYRiGYRiGYRgTYSHFMAwAYPHixVAoFFqvkJAQtGvXDv/880+B7RUKBSZMmJD/fvfu3VAoFPjf//5X6HGSkpIwbtw41K5dGz4+PggICEDNmjXx6quv4vTp0/n7Nua1e/du3LhxI/+9Zns0GT58eP421uLMmTNQKBRQKpW4f/++3m3atWuX3w4XFxf4+fmhatWq6N+/P/73v/9BrVZbZP+VK1eGJEkF1u/duzf/+IsXLzbqe92+fRvvvPMOqlSpAk9PT5QpUwbt2rXD8uXL9R7DWGJiYgz+XpUqVcLQoUPN3ret9mkP3n//fSgUCvTs2dPsfZw/fx4TJkzAjRs3LNewQnCUc6/7/AgICEC7du2wceNGmxx/woQJBZ5B5pybjIwMTJgwAbt377Zc454gnuPW2DfDlETc7N0AhmEci0WLFqFmzZqQJAlxcXGYPXs2evXqhfXr16NXr1752x08eBAVKlQwad9paWl4+umnkZaWhg8//BANGjRAZmYmLl++jNWrV+PkyZOoX78+Dh48qPW5r7/+Grt27cLOnTu1lteuXRsPHz4EAPj5+WHx4sUYP348XFxctI65cuVK+Pv7IyUlxdTTYTTz588HAOTm5mLJkiX4+OOP9W5XuXJlLF++HACQnp6O2NhYrF27Fv3790fr1q2xYcMGBAQEmL1/Pz8/xMbGYufOnejQoYPWuoULF5p0Hv7991/07NkTvr6++PDDD1G/fn0kJyfj77//xqBBg7Bhwwb88ccfWufbWGJiYvDzzz/rFVNr1qyBv7+/yfssDGvs09aoVCosW7YMALB582bcvXsXERERJu/n/PnzmDhxItq1a4dKlSpZuJWOzQsvvIAPPvgAarUa169fxzfffINevXphw4YN6NGjh83bY851mZGRgYkTJwKgwROGYeyIxDAMI0nSokWLJADSkSNHtJZnZGRIHh4e0ssvv1zo53ft2iUBkFauXGlwm4ULF0oApJ07d+pdn5eXp3f5kCFDJB8fH73rYmNjJQDSyJEjJQDS1q1btdbPnz9f8vLykgYNGiRZ65GXlZUllS1bVmrQoIEUEREhVa9eXe92bdu2lerUqaN3nTg3AwYMKPb+n376aWngwIFa61JSUiRvb2/ptddekwBIixYtKvQ7PXr0SAoNDZWioqKkuLi4AuunTJkiAZAmT55c6H4M8fbbb1vt93AEcnNzpaysLIvuc+XKlRIAqUePHhIAadKkScXaz65duyzaPkNERUVJQ4YMscmxCgOA9Pbbb2stu3r1qgRA6tixo8HP5eTkSCqVqtjH//LLLy1yzScmJkoApC+//LLY+9JFPMdtdW0wjLPDrn0MwxSKp6cn3N3doVQqtZYX5kpniKSkJABA+fLl9a43x7IhqFGjBlq0aIGFCxdqLV+4cCH69eun18pjKdauXYukpCSMHDkSQ4YMweXLl7F//36T9jFs2DB0794dK1euxM2bN4u1/+HDh2P16tV4/Phx/rIVK1YAAF566SWj2jN//nwkJCRgypQpKFeuXIH1H330EWrWrInvvvsOKpUKgOwWtGzZMrz//vsICwuDl5cX2rZtixMnTuR/dujQofj5558BaLtbCVczXXcnsd8//vgDH3/8McqXLw9fX1/06tUL8fHxSE1Nxeuvv47g4GAEBwdj2LBhSEtL02qv7j413Sx1X5puj3FxcXjjjTdQoUIFuLu7Izo6GhMnTkRubm7+NsK9dNq0afjmm28QHR0NDw8P7Nq1y6hzbSwLFiyAu7s7Fi1ahMjISCxatEive+XFixfx8ssvo1y5cvDw8EDFihUxePBgZGdnY/Hixejfvz8AoH379gW+syFXs3bt2mlZP7KysvDBBx+gYcOGCAgIQFBQEJ555hmsW7fOrO/WqFEjtG7dusDyvLw8REREoF+/fvnLfvnlFzRo0AC+vr7w8/NDzZo18emnn5p13CpVqiAkJCT/nhPX2tKlS/HBBx8gIiICHh4euHr1KgBg+/bt6NChA/z9/eHt7Y2WLVtix44dBfa7ceNGNGzYEB4eHoiOjsb06dP1Hl/f+X78+DE++OADVK5cGR4eHggNDUX37t1x8eJF3LhxAyEhIQCAiRMn5v9+mvu4cuUKBg4ciNDQUHh4eKBWrVr595smFy9eRNeuXeHt7Y3g4GC8+eabSE1NNec0MkyphYUUwzBa5OXlITc3FyqVCnfu3MHo0aORnp6OgQMHFnvfzzzzDABg8ODB+eLAkowYMQJr167Fo0ePAACXLl3CgQMHMGLECIseR5cFCxbAw8MDr7zySn481oIFC0zeT+/evSFJEvbt21es/b/00ktwdXXFn3/+qbWPF154wWg3om3btsHV1VXLnVMThUKB3r174+HDhzh27JjWuk8//RTXr1/H/PnzMX/+fNy7dw/t2rXD9evXAQBffPEFXnjhBQDkIipehgS25n4TEhKwePFifP/999i9ezdefvllPP/88wgICMCff/6Jjz76CEuXLi2yYz1nzhytYx88eBAdO3aEq6sratSoAYBEVLNmzbBlyxaMHz8emzZtwogRIzB58mS89tprBfY5c+ZM7Ny5E9OnT8emTZtQs2bNQttgCnfu3MHWrVvRp08fhISEYMiQIbh69Sr27t2rtd2pU6fQtGlTHDp0CF999RU2bdqEyZMnIzs7Gzk5OejRowe+/fZbAMDPP/+c/91NdWvLzs7Gw4cPMXbsWKxduxZ//vknWrVqhX79+mHJkiUmf79hw4Zh//79uHLlitbyrVu34t69exg2bBgAGhB466230LZtW6xZswZr167FmDFjkJ6ebvIxAeDRo0dISkrKFyeCcePG4datW5g7dy42bNiA0NBQLFu2DJ07d4a/vz9+//13/P333wgKCkKXLl20xNSOHTvQp08f+Pn5YcWKFfjuu+/w999/Y9GiRUW2JzU1Fa1atcK8efMwbNgwbNiwAXPnzkX16tVx//59lC9fHps3bwZAzzvx+33xxRcAyG2zadOmOHv2LL7//nv8888/6NGjB0aNGpXvDggA8fHxaNu2Lc6ePYs5c+Zg6dKlSEtLwzvvvGPWeWSYUou9TWIMwzgGwrVP9+Xh4SHNmTOnwPbQcS0xxrVPkiTpq6++ktzd3fP3Hx0dLb355pvSqVOnDH7GGNe+7777TkpNTZV8fX2l2bNnS5IkSR9++KEUHR0tqdVqq7mS3bhxQ3JxcZFeeuml/GVt27aVfHx8pJSUFK1tC3PtkyRJ2rRpkwRAmjp1arH3P2TIEKlJkyaSJEnSuXPnJADS7t27pSNHjhjl2lezZk0pLCys0G1++eUXCYD0119/SZIkXwNPPfWUpFartb6DUqmURo4cmb+ssN9D1xVM7LdXr15a240ePVoCII0aNUpred++faWgoKBC96nLd999JwGQfv311/xlb7zxhuTr6yvdvHlTa9vp06dLAKRz585JkiRfg1WqVJFycnIMHqM4fPXVVxIAafPmzZIkSdL169clhUIhvfrqq1rbPfvss1JgYKCUkJBgcF+FufYZOk9t27aV2rZta3Cfubm5kkqlkkaMGCE1atTIqH1q8uDBA8nd3V369NNPtZYPGDBAKleuXL5r3TvvvCMFBgYWui9DAJDeeustSaVSSTk5OdKFCxekbt26SQCkn3/+WZIk+Vpr06aN1mfT09OloKCgAtdgXl6e1KBBA6lZs2b5y5o3by6Fh4dLmZmZ+ctSUlKkoKCgAte87rkRv/O2bdsMfo/CXPu6dOkiVahQQUpOTtZa/s4770ienp7Sw4cPJUmSpI8//lhSKBTSyZMntbbr1KkTu/YxjAmwRYphGC2WLFmCI0eO4MiRI9i0aROGDBmCt99+G7Nnz7bI/r/44gvcunULCxcuxBtvvAFfX1/MnTsXjRs31rKgmIOvry/69++PhQsX5idlGDZsmNHZ+iRJQm5urtarKBYtWgS1Wo3hw4fnLxs+fDjS09Px119/mdR+SY+blrn7Hz58OI4ePYozZ85gwYIFqFKlCtq0aWNSe4xtr+75HThwoNayqKgotGjRotiubrqZ6mrVqgUABawptWrVwsOHDwu49xlCWLI+//xzLUvTP//8g/bt2yM8PFzrmujWrRsAYM+ePVr76d27dwEXWH2o1Wqt/eXl5RW6vSRJ+e58nTp1AgBER0ejXbt2WLVqVX7ykIyMDOzZswcDBgwoYGGxBitXrkTLli3h6+sLNzc3KJVKLFiwABcuXDB5X2XLlkWvXr3w+++/52evfPToEdatW4fBgwfDzY1yYzVr1gyPHz/Gyy+/jHXr1uHBgwcmHWfOnDlQKpVwd3dHrVq1cODAAXz11Vd46623tLZ7/vnntd4fOHAADx8+xJAhQ7R+O7Vaja5du+LIkSNIT09Heno6jhw5gn79+sHT0zP/835+fgatu5ps2rQJ1atXR8eOHU36XgC5W+7YsQPPPfccvL29tdrZvXt3ZGVl4dChQwCAXbt2oU6dOmjQoIHWPizhecAwpQkWUgzDaFGrVi00adIETZo0QdeuXTFv3jx07twZH330kVbMTXEoV64chg0bhrlz5+L06dPYs2cP3N3d8d577xV73yNGjMDx48cxadIkJCYmmpRaeM+ePVAqlVqvwlJEq9VqLF68GOHh4WjcuDEeP36Mx48fo2PHjvDx8THZvU/EaYSHhxd7/23atEG1atUwb948LF26NN8l0FgqVqyIxMTEQl2mxLmJjIzUWh4WFlZg27CwsGK7cgYFBWm9d3d3L3R5VlZWkfvctWsXhg4disGDB+Prr7/WWhcfH48NGzYUuCbq1KkDAAU68UW5JgqGDx+utT/d7Iq67Ny5E7Gxsejfvz9SUlLyr4MBAwYgIyMjfwDi0aNHyMvLMzmbpjmsXr0aAwYMQEREBJYtW4aDBw/iyJEjGD58uFHnXR/Dhw/H3bt3sW3bNgAkcLOzs7Xu4VdffRULFy7EzZs38fzzzyM0NBTNmzfP/0xRDBgwAEeOHMHRo0dx6dIlJCUl5bvFaaL7W8bHxwOgrH+618PUqVMhSRIePnyIR48eQa1WG7wHiiIxMdHs3y8pKQm5ubmYNWtWgTZ2794dgHzNJiUlmd1GhmFkOP05wzBFUr9+fWzZsgWXL19Gs2bNLL7/Nm3aoHPnzli7di0SEhIQGhpq9r5atmyJGjVq4KuvvkKnTp0KdPILo3Hjxjhy5IjWMiFq9LF9+/Z88VO2bNkC6w8dOoTz58+jdu3aRh1//fr1UCgU+Zaj4u5/2LBh+Pzzz6FQKDBkyBCj2iDo1KkTtm7dig0bNuhNUCFJEtavX4+goCA0btxYa11cXFyB7ePi4vR+B3ty+vRp9O3bF23btsVvv/1WYH1wcDDq16+PSZMm6f287rVhrFCdMGGCViyKn59fodsLwfzDDz/ghx9+0Lv+jTfeQFBQEFxdXXHnzh2j2qEPT09PZGdnF1j+4MEDBAcH579ftmwZoqOj8ddff2l9b32fNZYuXbogPDwcixYtQpcuXbBo0SI0b968wPU9bNgwDBs2DOnp6di7dy++/PJL9OzZE5cvX0ZUVFShxwgJCUGTJk2KbIvubym++6xZs/D000/r/Uy5cuWgUqmgUCgM3gNFERISYvbvV6ZMGbi6uuLVV1/F22+/rXeb6OhoAPQ8MbeNDMPIsJBiGKZITp48CQDFdheKj49HSEhIgex8eXl5uHLlCry9vREYGFisYwDA559/jv/9738GOxOG8PPzM6qTJViwYAFcXFywevXqAlkB79y5kz96bihjlyaLFi3Cpk2bMHDgQFSsWNEi+x8yZAj+++8/1KpVy+R6QyNHjsR3332HcePG4dlnny0gbqdNm4aLFy9iypQpBdzZ/vzzz/zCsQBZ2g4cOIDBgwfnb+Ph4QEAyMzMhJeXl0ltswS3bt1Ct27dULlyZaxatUqvS17Pnj0RExODKlWqoEyZMhY7dqVKlYyu3/To0SOsWbMGLVu2xDfffFNg/fz587F8+XKcPXsWdevWRdu2bbFy5UpMmjRJS/hoonnu9bVNFMYWXL58GZcuXdLan0KhgLu7u5bgiIuLMztrH4B8EfDjjz9i3759OHr0KObNm2dwex8fH3Tr1g05OTno27cvzp07V6SQMpeWLVsiMDAQ58+fLzQhg7u7O5o1a4bVq1fju+++y3fvS01NxYYNG4o8Trdu3TB+/Hjs3LkTzz77rN5tDP1+3t7eaN++PU6cOIH69evnW2b10b59e0ybNg2nTp3Scu/7448/imwjwzAyLKQYhtHi7Nmz+bFBSUlJWL16NbZt24bnnnsufzSzMIQPvi5t27bF0qVLMW/ePAwcOBBNmzZFQEAA7ty5g/nz5+PcuXMYP358oX/+xjJo0CAMGjSo2PspjKSkJKxbtw5dunRBnz599G4zY8YMLFmyBJMnT87vqGdmZuafo8zMTFy/fh1r167FP//8g7Zt22Lu3LnF2r8m4eHhWLt2rVnfLzAwEKtXr0bPnj3RuHHj/ALKKSkp+Ouvv7B8+XK8+OKL+PDDDwt8NiEhAc899xxee+01JCcn48svv4SnpyfGjRuXv029evUAAFOnTkW3bt3g6upaZOfPknTr1g2PHz/G7Nmzce7cOa11IiX2V199hW3btqFFixYYNWoUatSogaysLNy4cQMxMTGYO3eu1d3oli9fjqysLIwaNUpv8dWyZcti+fLlWLBgAWbMmIEffvgBrVq1QvPmzfHJJ5+gatWqiI+Px/r16zFv3jz4+fmhbt26AIBff/0Vfn5+8PT0RHR0NMqWLYtXX30VgwYNwltvvYXnn38eN2/exLRp0woMovTs2ROrV6/GW2+9hRdeeAG3b9/G119/jfLlyxfIvGcKw4cPx9SpUzFw4EB4eXnhxRdf1Fr/2muvwcvLCy1btkT58uURFxeHyZMnIyAgAE2bNjX7uEXh6+uLWbNmYciQIXj48CFeeOEFhIaGIjExEadOnUJiYiJ++eUXAFRAvGvXrujUqRM++OAD5OXlYerUqfDx8ckvIG6I0aNH46+//kKfPn3wySefoFmzZsjMzMSePXvQs2dPtG/fHn5+foiKisK6devQoUMHBAUFITg4GJUqVcJPP/2EVq1aoXXr1vi///s/VKpUCampqbh69So2bNiQX9R89OjRWLhwIXr06IFvvvkG5cqVw/Lly3Hx4kWrnUOGKZHYM9MFwzCOg76sfQEBAVLDhg2lH374oUBxURjI2mfotWvXLun8+fPSBx98IDVp0kQKCQmR3NzcpDJlykht27aVli5darBtxmbtKwxLZ+378ccfJQDS2rVrDW4zd+5cCYC0atUqSZIo85nmOfHx8ZEqV64svfDCC9LKlSu1ChKbu//CsgJKkmR01j7BrVu3pLfffluqXLmy5O7uLgUEBEht2rSRli1bppWZT5Lka2Dp0qXSqFGjpJCQEMnDw0Nq3bq1dPToUa1ts7OzpZEjR0ohISGSQqGQAEixsbGSJBnO2qebEdJQEWlR+DQxMTF/me4+C7tWNc9NYmKiNGrUKCk6OlpSKpVSUFCQ1LhxY+mzzz6T0tLSJEky/ho0h4YNG0qhoaFSdna2wW2efvppKTg4OH+b8+fPS/3795fKli0rubu7SxUrVpSGDh2qdQ//+OOPUnR0tOTq6qr1ndVqtTRt2jSpcuXKkqenp9SkSRNp586derP2TZkyRapUqZLk4eEh1apVS/rtt9/0Fp01tSBvixYtJADSK6+8UmDd77//LrVv314qV66c5O7uLoWHh0sDBgyQTp8+XeR+oacgry5FZR/ds2eP1KNHDykoKEhSKpVSRESE1KNHjwLbr1+/Xqpfv37++Z8yZYrR5+bRo0fSe++9J1WsWFFSKpVSaGio1KNHD+nixYv522zfvl1q1KiR5OHhIQHQ2kdsbKw0fPhwKSIiQlIqlVJISIjUokUL6ZtvvtE6zvnz56VOnTpJnp6eUlBQkDRixAhp3bp1nLWPYUxAIUl60kQxDMMwjIns3r0b7du3x8qVK/PrRDEMwzBMSYWz9jEMwzAMwzAMw5gICymGYRiGYRiGYRgTYdc+hmEYhmEYhmEYE2GLFMMwDMMwDMMwjImwkGIYhmEYhmEYhjERFlIMwzAMwzAMwzAmwgV5AajVaty7dw9+fn5aVdoZhmEYhmEYhildSJKE1NRUhIeHw8XFsN2JhRSAe/fuITIy0t7NYBiGYRiGYRjGQbh9+zYqVKhgcD0LKQB+fn4A6GT5+/vbtS0qlQpbt25F586doVQq7doWxn7wdcAAfB0wBF8HDMDXAUPwdWAbUlJSEBkZma8RDMFCCsh35/P393cIIeXt7Q1/f3++QUoxfB0wAF8HDMHXAQPwdcAQfB3YlqJCfjjZBMMwDMMwDMMwjImwkGIYhmEYhmEYhjERFlIMwzAMwzAMwzAmwjFSDMMwDMMwDGMkkiQhNzcXeXl5Nj+2SqWCm5sbsrKy7HL8koKrqyvc3NyKXfaIhRTDMAzDMAzDGEFOTg7u37+PjIwMuxxfkiSEhYXh9u3bXPu0mHh7e6N8+fJwd3c3ex8spBiGYRiGYRimCNRqNWJjY+Hq6orw8HC4u7vbXMyo1WqkpaXB19e30EKxjGEkSUJOTg4SExMRGxuLatWqmX0uWUgxDMMwDMMwTBHk5ORArVYjMjIS3t7edmmDWq1GTk4OPD09WUgVAy8vLyiVSty8eTP/fJoD/wIMwzAMwzAMYyQsYEoGlvgd+UpgGIZhGIZhGIYxERZSDMMwDMMwDMMwJsJCimEYhmEYhmEYxkRYSDEMwzAMwzBMCUWhUBT6Gjp0qL2b6LRw1j6GYRiGYRiGKaHcv38/f/6vv/7C+PHjcenSpfxlXl5eWturVCoolUqbtc+ZYYsUYxMePQJ69AD++MPeLWEYhmEYhrEMkgSkp9vnJUnGtTEsLCz/FRAQAIVCkf8+KysLgYGB+Pvvv9GuXTt4enpi2bJlmDBhAho2bKi1nx9//BGVKlXSWrZo0SLUqlULnp6eqFmzJubMmWOZE+sksEWKsQmbNwMxMUBsLDBwoL1bwzAMwzAMU3wyMgBfX1se0QVAIAAgLQ3w8bHMXj/++GN8//33WLRoETw8PPDrr78W+ZnffvsNX375JWbPno1GjRrhxIkTeO211+Dj44MhQ4ZYpmEODgspxibExdH08mUgKwsws+4ZwzAMwzAMY2FGjx6Nfv36mfSZr7/+Gt9//33+56Kjo3H+/HnMmzePhRTDWBIhpPLygAsXgEaN7NsehmEYhmGY4uLtTZYhW6FWq5GSkgJ/f394e1suQqdJkyYmbZ+YmIjbt29jxIgReO211/KX5+bmIiAgwGLtcnRYSDE2QQgpADh9moUUwzAMwzDOj0JhOfc6Y1CraVDax4eObSl8dL6Ei4sLJJ0gLJVKpdEONQBy72vevLnWdq6urpZrmIPDQoqxCbpCimEYhmEYhnFMQkJCEBcXB0mSoHii2E6ePJm/vly5coiIiMD169fxyiuv2KmV9oeFFGMTWEgxDMMwDMM4B+3atUNiYiKmTZuGF154AZs3b8amTZvg7++fv82ECRMwatQo+Pv7o1u3bsjOzsbRo0fx6NEjvP/++3Zsve3g9OeMTWAhxTAMwzAM4xzUqlULc+bMwc8//4wGDRrg8OHDGDt2rNY2I0eOxPz587F48WLUq1cPbdu2xeLFixEdHW2nVtsetkgxVic3F0hMlN8nJJCwCguzX5sYhmEYhmFKG0OHDsXQoUPz31eqVKlALJTgzTffxJtvvqm17NNPP9V6P3DgQAwsxXVt2CLFWJ3ERCoa5+oKVK1Ky9gqxTAMwzAMwzgzdhVSe/fuRa9evRAeHg6FQoG1a9dqrU9LS8M777yDChUqwMvLC7Vq1cIvv/yitU12djbeffddBAcHw8fHB71798adO3ds+C1KJ6dPA6mpxm0r3PpCQuRsfSykGIZhGIZhGGfGrkIqPT0dDRo0wOzZs/WuHzNmDDZv3oxly5bhwoULGDNmDN59912sW7cuf5vRo0djzZo1WLFiBfbv34+0tDT07NkTeXl5tvoapY4jR4AGDYD+/Y3bXgipsDCgfn2aZyHFMAzDMAzDODN2jZHq1q0bunXrZnD9wYMHMWTIELRr1w4A8Prrr2PevHk4evQo+vTpg+TkZCxYsABLly5Fx44dAQDLli1DZGQktm/fji5dutjia5Q6jh+n6ZYtVFy3Vq3Ct2chxTAMwzAMw5Q0HDrZRKtWrbB+/XoMHz4c4eHh2L17Ny5fvoyffvoJAHDs2DGoVCp07tw5/zPh4eGoW7cuDhw4YFBIZWdnIzs7O/99SkoKACo0pllszB6I49u7HYVx+7YLACq2NnduHqZPVxe6/d27tH1oqBq1auUBUOL8eQkZGblQKq3eXKfEGa4DxvrwdcAAfB0wBF8H9kelUkGSJKjV6vyCtLZGJIYQ7WDMR61WQ5IkqFSqAkWEjb3PHFpIzZw5E6+99hoqVKgANzc3uLi4YP78+WjVqhUAIC4uDu7u7ihTpozW58qVK4c4zXzbOkyePBkTJ04ssHzr1q3w9va27Jcwk23bttm7CQY5fLgBgEoAgIUL89Cq1Ra4uxu+mf/7ry6AKkhPv4pz5y7Ay6s7MjOVmD9/H6KijAy0KqU48nXA2A6+DhiArwOG4OvAfri5uSEsLAxpaWnIycmxa1tSjQ1UZwySk5ODzMxM7N27F7m5uVrrMjIyjNqHwwupQ4cOYf369YiKisLevXvx1ltvoXz58vmufPrQrMKsj3HjxmkVCktJSUFkZCQ6d+6sVWjMHqhUKmzbtg2dOnWC0kHNNXPnyqo9Lc0dGRnd0Lev/tSZALBsGW3fokUV9OgRjUaNXHHgABAU1Abduxv+XGnGGa4DxvrwdcAAfB0wBF8H9icrKwu3b9+Gr68vPD097dIGSZKQmpoKPz+/Qvu6TNFkZWXBy8sLbdq0KfB7Cm+1onBYIZWZmYlPP/0Ua9asQY8ePQAA9evXx8mTJzF9+nR07NgRYWFhyMnJwaNHj7SsUgkJCWjRooXBfXt4eMDDw6PAcqVS6TAPJ3Pa8vgxMHgwMHAg8NJL1mkXANy/T9NnngEOHgQWLHBD167AsWNAtWr00iQhgaYREa5QKl0RFQUcOAAkJrqxa18RONI1ydgPvg4YgK8DhuDrwH7k5eVBoVDAxcUFLi72ydcm3PlEOxjzcXFxgUKh0HtPGXuPOewvIOKVdC8SV1fX/IuocePGUCqVWmbu+/fv4+zZs4UKqZLK1q3Ahg3A1Kn61x89SuJn377iHefePZp+8QXg4kL7CwsDevQAWrQAsrK0t9dMNgEAoaE0FQKLYRiGYRiGYZwNuwqptLQ0nDx5EidPngQAxMbG4uTJk7h16xb8/f3Rtm1bfPjhh9i9ezdiY2OxePFiLFmyBM899xwAICAgACNGjMAHH3yAHTt24MSJExg0aBDq1atXqOtfSSU+nqa3b+tfv2IFcOgQ8Mcf5h8jJ4cK7AJA06ZyCnSFAlAqgQcPgI0btT9jSEiJ9jIMwzAMwzDOz4QJE9CwYcP890OHDkXfvn1t3o4bN25AoVDkawxrYVchdfToUTRq1AiNnlRpff/999GoUSOMHz8eALBixQo0bdoUr7zyCmrXro0pU6Zg0qRJePPNN/P3MWPGDPTt2xcDBgxAy5Yt4e3tjQ0bNhTIvlEaEBaepCQgM9Pw+uRk848h3PqUSqBsWWDhQuDwYXIrHDOG1mkKtYwMQLiZCiFVrpx2exjGUixaBHz8McBl5BiGYRhGZujQoVAoFPmubJUrV8bYsWORnp5u1eP+9NNPWLx4sVHb2kr8WBK7xki1a9cuP42jPsLCwrBo0aJC9+Hp6YlZs2Zh1qxZlm6e06EpTO7cMRyrVBwhJdz6wsPJCuXtTZYpgGKzpk0ji9Tjx0BgoGx18vQERB4Pdu1jrIEkAe++C6SnA23bAt2727tFDMMwDOM4dO3aFYsWLYJKpcK+ffswcuRIpKen45dfftHaTqVSWSwOLyAgwCL7cVQcNkaKMR3hcgfod+8T6y0hpCIiCq6rXx+oXRvIzgbWrKFlmm59IrkMu/Yx1iAxkUQUAPz5p33bwjAMw5Qy0tMNv3SDxwvbVtelyNB2ZuDh4YGwsDBERkZi4MCBeOWVV7B27dp8d7yFCxeicuXK8PDwgCRJSE5Oxuuvv47Q0FD4+/vj2WefxalTp7T2OWXKFJQrVw5+fn4YMWIEsnS+q65rn1qtxtSpU1G1alV4eHigYsWKmDRpEgAgOjoaANCoUSMoFAq0a9cu/3OLFi1CrVq14OnpiZo1a2LOnDlaxzl8+DAaNWoET09PNGnSBCdOnDDrHJkKC6kShK5FShdLCKm7d2kaHl5wnUJBVilAdu/TjY8CtC1ShRgkGcYkbtyQ59euJbdSQzx6BMybBzx8aO1WMQzDMKUCX1/Dr+ef1942NNTwtt26aW9bqZLWehd/fwRWqGCRJnt5eeUXnr169Sr+/vtvrFq1Kt+1rkePHoiLi0NMTAyOHTuGp556Ch06dMDDJ3+ef//9N7788ktMmjQJR48eRfny5QsIHF3GjRuHqVOn4osvvsD58+fxxx9/oNyTmI/Dhw8DALZv34779+9j9erVAIDffvsNn332GSZNmoQLFy7g22+/xRdffIHff/8dAJCeno6ePXuiRo0aOHbsGCZMmICxY8da5BwVhcOmP2dMR1NI6VqkJEle//ix+cfQdO3Tx8CBwOefAzt3UjxVYUIqKwtISwP8/MxvD8MIbt6U59PSgH/+AQYM0L/trFnAl1/SZ7791jbtYxiGYRhH4fDhw/jjjz/QoUMHAFScdunSpQgJCQEA7Ny5E2fOnEFCQkJ+yaDp06dj7dq1+N///ofXX38dP/74I4YPH46RI0cCAL755hts3769gFVKkJqaip9++gmzZ8/GkCFDAABVqlRBq1atACD/2GXLlkWYRsfx66+/xvfff49+/foBIMvV+fPnMW/ePAwZMgTLly9HXl4eFi5cCG9vb9SpUwd37tzB//3f/1n6tBWAhVQJojAhlZZGLneA9Vz7ACA6Wq4vtWSJbBXQFFI+PvRKT6c2s5BiLIGmRQog9z5DQurqVZpevGjVJjEMwzClhbQ0w+t0E6AVFiSuWxtK589NrVYjJSUF/qa1DgDwzz//wNfXF7m5uVCpVOjTpw9mzZqFOXPmICoqKl/IAMCxY8eQlpaGsmXLau0jMzMT165dAwBcuHBBKwEcADzzzDPYtWuX3uNfuHAB2dnZ+eLNGBITE3H79m2MGDECr732Wv7y3Nzc/PirCxcuoEGDBvD29tZqhy1gIVVCyM7WFki6rn2a8VOpqZTVzJzEhkVZpABg5EgSUt98A7RsScs0hRRAVqnYWIqTqlLF9HYwjC7iv6ZXL6qnFhMjJz3RRVzHmlYshmEYhjEbHx/bbKtWm52atn379vjll1+gVCoRHh6ulVDCR+c4arUa5cuXx+7duwvsJ1DfH6sReHl5mfwZUTv2t99+Q/PmzbXWiQzdhSWuszYcI1VCePBA+72uRUp38CM11bzjFBYjJRg6FGjdmgZntmyhZfqElL52MYy5CFHUqxdQty7VPHviXl0AkcZf14rFMAzDMCUVHx8fVK1aFVFRUUVm5XvqqacQFxcHNzc3VK1aVesVHBwMAKhVqxYOHTqk9Tnd95pUq1YNXl5e2LFjh9717u7uAIA8DaFYrlw5RERE4Pr16wXaIZJT1K5dG6dOnUKmRqKOwtphSVhIlRB0BYmukNK0SAHmu/cZY5FycQEWLKCU5wJRO0r3PQspxlIIURQVBbz8Ms2vWqV/W3EdP3xo/qACwzAMw5RUOnbsiGeeeQZ9+/bFli1bcOPGDRw4cACff/45jh49CgB47733sHDhQixcuBCXL1/Gl19+iXPnzhncp6enJz7++GN89NFHWLJkCa5du4ZDhw5hwYIFAIDQ0FB4eXlh8+bNiI+PR/KTzuqECRMwefJk/PTTT7h8+TLOnDmDRYsW4YcffgAADBw4EC4uLhgxYgTOnz+PmJgYTJ8+3cpniGAhVUIQgiQqiqaPHmlnx9QVLOYIqbQ0ubiuoRgpQbVq5NonYIsUY00kSRZSlSqRRRTQHwOVkaGdcIXd+xiGYRhGG4VCgZiYGLRp0wbDhw9H9erV8dJLL+HGjRv5WfZefPFFjB8/Hh9//DEaN26MmzdvFpng4YsvvsAHH3yA8ePHo1atWnjxxReR8KQz6ObmhpkzZ2LevHkIDw9Hnz59AAAjR47E/PnzsXjxYtSrVw9t27bF4sWL8y1Svr6+2LBhA86fP49GjRrhs88+w9SpU614dmQ4RqqEIARJ1apAUhKJnjt3gBo1aLklLFLCHcrX17gEEaNHA3v3AleuUI0pTbiWFGNJkpLkgYOKFWWX8ps3gdxcwE3jSSeuY8HNm+QKyDAMwzAllcWLFxtcN2HCBEyYMKHAcj8/P8ycORMzZ840+NlPP/0Un376qdYyTRGje1wXFxd89tln+Oyzz/Tub+TIkflZADUZOHAgBooaO3p4+umn89O2C2wRO8UWqRKCEErlygGRkTSv6d6nK6TMSYFuTHyUJq6uVM/n/HlAI5FKfjsBtkgxlkFYlcqXJ5fS8uUBDw+Kx9VNvKIrpDhOimEYhmEYc2AhVUIQgiQ0VL+QsoRrX1Gpz/WhUOhfzq59jCXRjI8CKE6vUiWav35de1txHQvYtY9hGIZhGHNgIVVCEIIkJAQQBa81R+It4dpnTKIJY2EhxVgSzfgoQeXKNC1KSLFFimEYhmEYc2AhVUIoyiIlhJRI+mCOkDLVta8wOEaKsSTCqqQppJ7EoCI2VntbIaTEtmyRYhiGYRjGHFhIlRCEUCrKta9aNZra2yIlYqSSkigZAMMUB13XPsCwRUrESImi5yykGIZhGFOwZwFYxnJY4ndkIVVC0LRI6br2SZIstCwhpEyJkTJEUBDFsQAFiwkzjKmY49onhFR8PKBRw49hGIZh9CKK2GZkZNi5JYwlEL9jUcWJC4PTn5cQNGOk/P1pXlikUlOB7Gyar1qVpqYKKbVa7qxawiLl6goEB1O74+ML1pkq6cyeDfz4I7Bjh7YVhTEd3RpSAuHaZ0hI1alDafxTU4Fbt+RSAQzDMAyjD1dXVwQGBubXPfL29obCUFYtK6FWq5GTk4OsrCy4uLA9xBwkSUJGRgYSEhIQGBgIV1dXs/fFQqoEkJ5ORUYBOfYIILGUmipbo3x8zI+R+vVXsnB5ewO1axe/zaKtCQmlL+GEJAFTplDMWUwMUETtOqYIHj+m6xzQFqVCSD14QOtF7TNNy2pUFHD2LAkxFlIMwzBMUYQ96Ugl2KnzIkkSMjMz4eXlZXMRV9IIDAzM/z3NhYVUCUDcy56eVCxXoSCrVEoKiR8hmkJCgIAAmjeljtTt28BHH9H85MlAmTKWaXe5ctSJdXYhlZMDxMVRIVhjOHNGTtyhW9OIMR1hjQoNBby85OUBAUDZshSHFxtLRaHT0+m+AKjWVKVKdA1ynBTDMAxjDAqFAuXLl0doaChUKpXNj69SqbB37160adOmWC5ppR2lUlksS5SAhVQJQDPRhBiciIwEzp0jEZSVJa8XQspYi5QkAW+8QSP6LVoAb79tuXaXlBTob78NzJ8PHDggx90URkyMPK+bipsxHX1ufYLoaBJS16+TkBLC1ceHLFTCgsUp0BmGYRhTcHV1tUhH3Jzj5ubmwtPTk4WUA8DOlSUAzfgogehUnjsnC62QECAwkOaNFVJr1gCbNgHu7iQWLPnMMDcF+vXrZAFyBFJTgWXLaH7PHuM+s2mTPM9CqvjoS30uEAknRAp0zcyTCgWnQGcYhmEYxnxYSJUANDP2CZ59lqYxMdpCy1SL1JYtNP2//wNq1Sp+WzUxxyK1cSPFsrRsSdYye7Nhg2zxu3q16O2Tk4F//5Xfs2tf8fnnH5rqi3HSzdynm8KfLVIMwzAMw5gLC6kSgD4h1aMHTffskTuRmq59aWlAXl7R+754kaZNm1qmrZqIWlLGCql9+4AXXqC6U9evmxbnZS3++kuev3Kl6O23baPz7ulJ79kiVTyOHKHMh25uwIgRBdfrZu4T57t8eZqyRYphGIZhGHNhIeWkpKQACxYADx9qx0gJqlenVOcqFbBqFS3TtEiJfRSFEFI1a1qm3ZqYYpE6fRro1Uu2/gD2tyI8fgxs3iy/N8YiJdz6XniBpomJ9Bsx5jF5Mk0HDtSfRl7XIiUsgLoWqXv3KGkIwzAMwzCMsbCQclJ+/hkYORLo2pVq4ADaMVIKhWyVevSIpqGhFOskrCFFufc9fCiLHGukhjYlRurzz6m9rVpR0gDA/laE9eup8x0ZSe/v3aOscIaQJFlIvfoqWVEkyfQYMYa4cIFi+ADg44/1byOE1I0bVAtN17UvJIQy/UmSfB8xDMMwDMMYAwspJ+XSJZoeOQL87380r2mRAoCePbXfC6FlbAp0YY2KjKS06pZGuPbFx1MntzDOnqXppEmydcweFqnt24FvvwWuXZPd+kaOlFPC6xZ/1eTUKbKI+PgAbdvK7mXs3mceU6fStG9fw7XNIiMBFxeyZMbFFRRSmgkn7G3hZBiGYRjGuWAh5aSIOkSa6AqpNm20BZCukCrKImVNtz4AqFCBrDLZ2YWLiZwc2fpUrZp9O76vvgp89hm5TQrr0oAB9B4oPE7q+HGaPvMM4OEhCylOOGE6Fy8Cy5fT/LhxhrdTKuX6XlevFhRSgBxHJTL7MQzjHKjVVHCbYRjGXrCQclKEkBLue0BBIeXuDnTuXHC9sSnQrS2k3NzkTmxhAuT6dfrD9PUFwsLsJ6Sys7XTrksS0KABnZ9q1WhZYXFSwlolthWdebZImYZaDbz2GiUd6dEDaNas8O2FtWrwYNl9T4hYgIUUwzgrr79Ong0//2zvljAMU1phIeWkCCE1fTrwySeUvKBBg4LbaQotR7NIAbIlpzABItZVrWpfVywRy+TuTq59P/4I/Pmn3Dag8O8hOuqi486ufebx66/A/v3kImlMB2raNIqVunlTTlbCQophnBuVCvj7bxpYeecd+i9kGIaxNSyknJDUVDnjXkQEZS5buZIsPLr07EkWqFq1KKgeMF5IXbhAU0vXj9JEWGcKs0iJdWJbewkpYY0KC6OO+XvvyefGGCElLFIiAYKwSLFrn/HcvQt89BHNf/ut/kx9utSpA5w4AQwaRO/DwwE/P3k9CymGcT7++4/+C0WR+A8/BL77zr5tYhim9MFCygkR1ig/P+0OoT5CQyl1+J498jJjhFR2ttzxt7dFSggpsa3oPCcn27aWlKaQ0sWYGCldixS79pnOl19S56l5c+Dtt43/nL8/sHQpsHOnXGRawEKKYZyPrVtp2r8/8PXXND9xYtGJixiGYSwJCyknRAipChWM2z4yUjs1ujFC6upV+kPy99cvHCyFKUJKWKS8veXvY8sU6IUJKdG2O3eAzMyC69PTZddAYZHiZBOmIxJ2jBsnj0SbQvv2QN262suEhTMhofD09QzDOA5CSHXuTO7t7u50/3IZA4ZhbAkLKSfkzh2aRkSY93lj0p9rxkcpFOYdxxg0kzQYGknUFVKAfdz7ChNSZcvK51VfCnTRzsBAOdkHW6RMR1z7xrj0GUuZMvJvxynQGcbxefiQSn8AQKdO5NZevTq9F/9dDMMwtoCFlBMiLFLFFVKFWaRsER8FUIfY1ZWsOPosM1lZ8gijIwsphaJw65pufBQgW6QSEihwmimc7GwgMZHmjbXGGgu79zGM87BzJw281a4tPwuEC7r472IYhrEFLKScEFNd+3QxJv25LTL2AVTnp7AU6LGxlGbcz087vbujCSmg8Dgp0UHXFFLBwXKCEOH2xxhGWO48PMgCaElYSDGM86Dp1icQg35skWIYxpawkHJCbGGRspWQAgq35GgmmtB0MbSnkCpXTv/6wmpJCYuU6LADgIsLp0A3Bc3r3tLupiykGMax+eMPyth57Jh+IcUWKYZh7IGehNmMo2OpGClDQkqS7COk9Fly9MVHAQWF1PvvU5vXrqWgY2tgrEXKWNc+gITU7duccMIYxHVvabc+gIUUwzgy8fFUUDsvT05x7u4OtGkjbyP+q9gixTCMLWGLlBNibYvU3buU/cjVFahSxbxjmEJhlhxjhNSRI8CMGcCmTXJWN0sjScYLqYsXCybO0E19LjAm4cTDh0BurmntLYkUdwChMFhIMYzjsnQpiaiyZcm1FwA6dqSi3IIaNWiamAgkJdm+jQzDlE5YSDkZKpUcT2PuyHxRQkp0JqOiKIbJ2phjkRJZ2x4/ptS3Amt1hFNT5bTmhlz76tShosd37wLjx8vLJalwixRgWEidOkWxYbVrA//8Q/sqrRQ3NrAwNIVUaT7HDONoSBKwaBHNf/stWe9XrwYWLtTezscHqFiR5tkqxTCMrWAh5WTcv09/LEqldm0oUxBCKj1dv6XDkPXEWmhapHQ7scJKpSukfHzk779zp7zcWjFTwhrl56c9CqpJYCDw6680P2kS8PffNJ+YCGRkUFyP+KMXCIuUIde+I0cUyMsjQdmrF9C9u22LEDsS1rRICQtnSgrw6JHl988wjHkcPgycP0+DVC++SOUKnntO/4CWSDjBcVIMw9gKFlJOhhiVL1+ekhWYgxBSgH6rlK2FVKVK+lOgZ2VR/BAgW6000awlJM6FtSxSRbn1CQYNAsaOpfmhQ8miJKxRFSrIbimColz77t6lrArR0RQTsHkzxYGVRqxpkfL2ljtm7N7HMI6DsEY9/7z2f5c+OE6KYRhbw0LKybBEZ1KppI4jULiQEqP01kaplI915Qpw8yawbh3wyy9kofL3129902zfm2/S1NoWqaKEFABMmQJ07UrC8I03gGvXaLmuWx8gu/YZskjdu0dCatgwCrYG6PyURqyZbAIoGCeVlWWd4zAMYxwZGcCff9L88OFFb88WKYZhbA0LKSejuIkmBMLF7ODBgutsbZECZIvTyJF03L59KRMfQEHE+tJdi8906AAMGEDz9rZIAWRdW7QI8PUF/vtPzjKl73wKi5T4XXURlqqICCAykuaFla40kZcni01ruPYB8u9z4ADQqRONfp84YZ1jMQxTNGvWkLttpUpA27ZFb88WKYZhbA0LKSfDUnEiL75I099/L7jOnkJKxEk99RRlZerXD5g6Vf9n3nkHGDUK+O032Tp18yZ1ui2NKUJKbPfppzR/6hRN9VmkxO+YmKjfAnLnDinIChVKt5BKSKB4PhcX438DUxHX+4wZwPbtQE4OsHGjdY7FMEzR7N9P0wEDjHNlF0IqNlZODsQwDGNNWEg5GZaySAk3se3bta0hOTnye1sKqTfeoJogY8eSe9+xY8C2bcCqVUD79vo/ExEB/PQTtTMiAnBzo6yG1qjJJDIlmtKJHzNGO45L3/ksW1Z2sxQiWRO2SBHi3ISF0e9sDTR/H/GbHD1qnWMxDFM0t27RVF+MrD5CQykZhSTpzwLLMAxjaVhIORmWCrivXBlo3Zr+cJYtk5ffvk01kLy8DKf5tgb16gF79pAbnLF/mpq4uclCwxrufcIiZco58fQEpk2T3+uzSGlm8tONfcrOdsGjR2SR0hVSpS1FtzUTTQi6dQMaNADefVdO6MFCimHshxg00s12agiFQrZKcZwUwzC2gIWUk2HJFNBDhtD099/ljrlmogl9cUmOjLAoWCPhhKmufYL+/YGBA4FmzchdUR/CaiVGXwUPH3oBIOtIQIAspNLSDNcAK6lYM/W5ICICOHkSmDkTeOYZciW6e9c6Fk6GYYpGPBPFs88YRMIJjpNiGMYWsJByIiTJcq59AHXyPT1p5E6MvNsjPspS6GZdsyTmCimFAli+nJJOeHrq38aQRSopiT4QEUH78fYGgoJoXWlz77OFRUoTX1+5Q3bsmG2OyTCMTEqKPGBkipAS/wO6A1MMwzDWgIWUE/HwIZCdTfMi21tx8PenwoaAnHTC1qnPLYlos6UtUmq1eTFSxmLIIpWURBYpTfFQWuOkrJ36XB9NmtCU3fsYxvaIZ1xgIBVCNxYxyGgoEyrDMIwlYSHlRCQm0jQgwLB1w1RE0onVq0kwsEWqIElJcibA0FDL7hswziIlKK1CypKWWGNp3JimLKQYxvaYGh8lYCHFMIwtYSHlRDx8SNOyZS23z/btyY3p/n3g+HHnFlLWskgJt77gYCoebGkMx0ixkBLY2yJV2pJ7MIy9MSc+CmAhxTCMbWEh5UQkJdFUxMlYAg8PoHNnmt+wQRYhziikRJtv36aaQ5bC3PgoYxEjrrdukVVQIFz7SruQkiTbJJvQpUEDKq4cH8+dMoaxNeZapITb+6NHXEuKYRjrY1chtXfvXvTq1Qvh4eFQKBRYK3IOP0GhUOh9fffdd/nbZGdn491330VwcDB8fHzQu3dv3NFXkKcEICxSlhRSANCrF01XrpRjgZxRSIWFkTDMy7Os0LC2kIqIoAxxOTny+QfYtU/w+LHcIbKlkPL2BurUofnC3PssLdwZhjHfIhUYSOU7AB4AYRjG+thVSKWnp6NBgwaYPXu23vX379/Xei1cuBAKhQLPP/98/jajR4/GmjVrsGLFCuzfvx9paWno2bMn8kRQSwnCWkKqe3fKCifqbgQEUFFDZ8PFRXaTs6R7n7WFlFIpj6JquvdxsglCjIsEBckdJFtRVMKJo0dpxPz1123XJoYpDZhrkVIo2L2PYRjbYVch1a1bN3zzzTfo16+f3vVhYWFar3Xr1qF9+/ao/KSyaXJyMhYsWIDvv/8eHTt2RKNGjbBs2TKcOXMG27dvt+VXsQnWiJECKIFC8+bye2fM2CewRsIJ4VIZHGy5feoiBKBIOJGXBzx65AFAv0Xqzp3SE7djj/goQVFCau9emh4/bpv2MExpwVyLFMBCimEY2+Fm7wYYS3x8PDZu3IjfRZ5uAMeOHYNKpUJnEeQDIDw8HHXr1sWBAwfQpUsXvfvKzs5GtsgjDiAlJQUAoFKpoFKprPQNjEMcX187HjxwAeCKgIA8qFTqAuuLQ7duLjh0yBUAEBWlhkrlnBa9ihXpHF27ZrlzlJZG+/T0tPx5F0RGugJwQWwsHePuXRXUaiVcXCQEBeVCXA6UNVCJrCzg/n0VQkKs0hyHYvduOv81a9r+umzYUAHADcePS1CpCvrvXbhAbUtM1L++uBT2PGBKD6XtOlCrgTt33AAoUL68CqZ+7fLl6Xl665bhZ3ZODvDcc66oW1fC1KnWea5bmtJ2HTD64evANhh7fp1GSP3+++/w8/PTsl7FxcXB3d0dZXT80MqVK4c44Y+lh8mTJ2PixIkFlm/duhXe3t6Wa3Qx2LZtW4Fl5841BlABcXHnERNz3aLHCwjwB9D+ybvriIk5Z9H924rs7KoA6uDff+8hJsYyZoJLlxoCiMLt25cRE3PZIvvURaWqBaA69u69iZo1z+Dq1UAAbREYmIWtW7dqbRsY2AWPH3tixYp/UaVKslXa40j89Vc7AAGIiDiBmBjbxj+mpSkBdEdiogJr126Gu7t2h+vgwZYAgpGQoMbGjTFQKKzTDn3PA6b0UVqug8ePPZCd3RUKhYTTpzfh/HnTzO9ZWbUBVMO//95ArVpn9W5z8WIZbNvWBnv25KJt2xgLtNp2lJbrgCkcvg6sS0ZGhlHbOY2QWrhwIV555RV4GlFASZIkKArp0YwbNw7vv/9+/vuUlBRERkaic+fO8Pf3t0h7zUWlUmHbtm3o1KkTlDq5tn/+mSxGLVvWQvfuNS16XEkCfvhBwq1bCrRvH43u3aMsun9bkZ6uwJIlgEoVge7dLRPUtGIFnfeGDauje/eqFtmnLnfuuGDVKsDFpRK6d4/E6tXUYa9c2R3du3fX2rZKFVccOwZERbVC9+4l27/v5k3g5k0lXF0lfPxxfQQF1bfp8SUJGDFCQna2Ag0bdi3g9vrmm/QIzc11RevW3WHpx0dhzwOm9FDaroNjx+j/u3x5oHfvbiZ//to1F6xdC7i7R6N7d/1BVnFxdIycHDd06NAdHh5mN9dmlLbrgNEPXwe2QXirFYVTCKl9+/bh0qVL+Ouvv7SWh4WFIScnB48ePdKySiUkJKBFixYG9+fh4QEPPU9NpVLpMBelvraIGKnQUDer1DOaOBGYNQvo398VSqWr5Q9gA56Ez+HOHRcolZYJAczKoqmvr/XOi5y6ndodH08ubBERigLXQcWKwLFjwP371rkOHIktW2jasqUC5crZ58uGhZGgS0pSolo1eXlKipyIBAAeP1ZaPH5R4EjPJsZ+lJbr4N49mkZGFnz+GYNIUBEXZ/h/4OJFeT49XQlfX5MPYzdKy3XAFA5fB9bF2HPrFHWkFixYgMaNG6NBgwZayxs3bgylUqll3rx//z7Onj1bqJByVqyVbEIwdCh10G2ZYtrSiD/Qu3ctl5JapN62ptenbrIJESQdEVHQ4lSaMvdt2EDTnj3t1waRrfH+fe3lly5pv09MtE17GKakIxJNmJqxT2BMsonz5+X5R4/MOw7DMIxdhVRaWhpOnjyJkydPAgBiY2Nx8uRJ3NLIAZ2SkoKVK1di5MiRBT4fEBCAESNG4IMPPsCOHTtw4sQJDBo0CPXq1UPHjh1t9TVshrXSn5ckwsIonXheXsGOr7kIN1lrpt4WHYbHj8nSce8euZ2ItOialBYhlZYG7NpF86LWmT0oX56mumGXLKQYxnLMng3UrUuWIvFsMydjHyALqXv3tIuca3JOIwz48WPzjsMwDGNX176jR4+iffv2+e9F3NKQIUOwePFiAMCKFSsgSRJefvllvfuYMWMG3NzcMGDAAGRmZqJDhw5YvHgxXF2d0zXNELm5QPKTvAIspAzj4kJpsmNj6c/Y3D9iTYSQsqZFys+Panc9ekSjscK1JTy89Fqktm2jzFpVqgA1ativHYYsUpd18o6wkGIY81m8mMTN6NH0PATMt0iVL0/1pFQq4MEDke1U5vFjbWsVW6QYhjEXu1qk2rVrB0mSCryEiAKA119/HRkZGQgICNC7D09PT8yaNQtJSUnIyMjAhg0bEGmJ3rODoTli5ozFcm2J+Pk1i9sWB1u49gFyp+H8eeDaNbJI6audVFqE1D//0LRXL1gtG54xGGuRevDANu1hmJKIuL+2bAFEolJz/8qVSlk86XPvE8XnBWyRYhjGXJwiRoqR3fr8/QE3p0gRYj+EILGUkLKFax8gx0kNHAjcvEnKoUqVghYpOTGFbKUsiYhEEz162LcdRcVICWsZW6QYxjzUaiA+Xn4vkmWZa5ECCo+TOqdT3YMtUgzDmAsLKSchKYmm7NZXNJYWUra2SOXlAZUrS/jss0N6R2TLlweqVqXOx5491m2TvcjMlDtAjRvbty3CIqUppNRq2bWvVSuaspBiGPN48EBODhQYKC8vjnNJYUJKM9EEwEKKYRjzYSHlJFg7Y19JwlktUoMGAU2bAlOmAKdO5aJp03iD24pcKjt2WLdN9kL8dn5+2h0re6DPte/OHRJ7SiX9ZgALKYYxF3FvBQcDX3xB8x4eQEiI+fs0xiIlni3s2scwjLmwk5iTwBn7jEcIKUvFENnKItW8OXD4MM2rVIVv26EDMHduyRVSIg18VJR946MA2bUvPp4sUS4usltflSqy0GIhxTDmIay95csDb79NMUy1atG9Zi7GCKkWLYCYGLZIMQxjPmyRchJYSBmPJZNNqFSyy4m1LVKm0L49CYxz5yyX5t2R0BRS9qZcOZrm5soutkJIVa9Oo+gACymGMRdNIeXhAfz2G/Akia/ZGBJSycnyspYtacoWKYZhzIWFlJPAQsp4hEXq4UOqRVQchFsfYH2LlCmULQs0akTzO3faty3WwJGElFIpiyXR4dNMNCHcj1hIMYx5CNc+Yf21BIaElIiPiogAKlWiebZIMQxjLiyknAQWUsbj7w+IbPnFde8Tbn0KBY2UOhIdOtB0+3b7tsMaOJKQAgrGSekTUunp8vXCMIzxaFqkLEVRQqp2bTlGioUUwzDmwkLKSWAhZRqWSjihmWjC3rE6umgmnJAKZkl3aoSQKk76Y0uimwJdU0gFBJDVCuBaUgxjDmKAwhpC6tEjbc8CER9Vp45ck5Fd+xiGMRcWUk6CiM3grH3GYSkhZatEE+bQqhXg7k5Wt6tX7d0ay+LIFqkHD+Trqk4dEtiG4qQyMoDly4ErV2zXVoZxNsQAhSVd+wIC5IHHwYPJzXvfPuDPP2kZW6QYhrEELKScBLZImYZIOFFc1z5bpT43B29vyjoFlCz3vtxc2R3HUYSUpkXqv/9ovmZNeUTbUJzU9OmU1r56daBTJ2DbNtu0l2GcCWu49ikUwOzZZC1etQqoVw9o144GQ6pWBV54Qb5/k5MpIyfDMIypsJByElhImUZpsEgBQJs2ND161L7tsCR371JRYnd3y45QFwdNi9ShQzTfvLm83pBF6uBBeX77dqBLFznFPcMwhDWSTQDAyy8Du3YBoaHAjRsklgYPBo4fJxElLFKSBKSkWPbYDMOUDlhIOQkspEzDGjFSjkj16jS9ds2+7bAkwq0vMrJ4dWQsiRBSmhapp5+W1xuySJ05Q9M//gC6daMO2/jx1m0rwzgTaWlydlVLWqQELVvSQNObbwJ//w38/jsV+gYAT096AezexzCMeXBBXicgL08OhmUhZRyWFlKOapGqWpWmJSlGytHiowB5pPzePSAhgeb1CSnNZBNJSbKLYs+eZMGqUQPYsgXYv59i3BimtCPc+nx8ZIFjaSIjgV9+0b+uTBlqAyecYBjGHBxkvJcpjORkOSub8OlmCkcIqdu3i+f77uiufUJI3b1b/NTb9+7JxYftiSMKKTFSfvUquQB5ewN168rr9VmkhDUqOpo6iJUrA8OH07IvvrB+mxnGGbCWW5+xiP9UtkgxDGMOLKScAJGxz8+P4kaYogkPp2DjnJziFUp1dNe+oCC5Ztb16+bv59gxShfcsKH9M8w5opDS7eQ1aQK4adjzCxNS9erJyz7/nO7h3btLZiFlhjEVaySaMAURJ8UWKYZhzIGFlBPA8VGmo1SSmAKK597n6BYphcIy7n0igcK5c0DTpsDGjcVvm7k4opDy89O+BjTd+gD9Qur0aZrWry8vi4wEXn+d5n/80eLNZBinw95Cii1SDMMUBxZSTgALKfMQ7n03bpi/D0e3SAGykCpOwgkhXpRKciXt1YusVPbAEYWUQqFtldLM2Afoz9qnT0gBQO/eNC2OBZFhHJnLl4E5c4D09KK3tbdrH9eSYhimOLCQcgJYSJlHnTo0PXLE/H04ukUKsIxFSojNb74B2ralmLxdu4rdNJORJNmCKISwo6A5Yl6URUqtBs6epXlN1z4AKFeOpvHxlm8jAHz7LdWu4ro4jL0YMwZ4+20acLh0qfBtHcUixa59DMOYAwspJ4CFlHmIGkt795q/D2ewSFWpQlNLCKnq1eUiv/awmCQkAFlZZAESRZUdBTFiHhkpu40KhJB69IgSdly/TteOp6csdAVCSCUlWSe5x+TJwPLlRXdgGcZa3LlDU+EqvGaN4W3tbZFi1z6GYYoDCykngIWUeQghdeyYXKfEVBw9/TlgGdc+IaQqVZKFmT1qUwlrVPnyjpdYRYyY61qjAKBsWRJ/AAkk4dZXp452UgqA3ABdXMj6VpxEKPpQqeRr3dxrnmGKixAlVasCqalA//7A5s36t7W3RYqTTTAMUxxYSDkBQkiVLWvfdjgbUVHkHpabKydTMBVncu27cYOyFJpKRobcoY+Ksq+QcsT4KMHzzwPVqgEjRhRc5+oqD3QkJurP2Ke5rYipsrR7n2ZnkIUUYy/Ef9Y//5CbaV4e8MIL+uMu7S2k2CLFMExxYCHlBIj052yRMh1hldq3z7zPO4NrX1gYCT21WhYipiA+4+9Po7NCSN28afu6Uo4spNq1oyD6Ll30r9eMkzKUaEJgrTgpTSFlTKA/w1ianBz52gsJARYsADp2pGU9egCxsfK2KpVcxNreySbYIsUwjDmwkHICxB8NCynTKW6clDNYpBQK0+KkJIkEiyjyrOnWp1BQPSl3dxJRt29bo8WGEYlBqle37XEtQWgoTT/5BDhwgObtKaTYIsXYA2HZUSioxp27O7BqFdCgAV3v3brJg4MJCfQccnWVByJsDVukGIYpDiyknADRma1Qwb7tcEaEkDp0CMjONv3zzmCRAoyPk7p2DejQgUTTzJm0TNcK5OICREcbtz9LolLJcRTdutnuuJbi9dfpOjl8WA6g1+faB1hPSGl2BtkixdgDcQ0GBJBAAsjaHRNDiVouXaISAJmZsltfuXL03LEHLKQYhikOLKQcHM100I7o7uToVK9OloKsLODoUdM/7wwWKcC4FOjz5lHHXqQ1F0V3NS1SAnvESf37L9WwCgmhTF/Oxiuv0Pn6v/+jBBN168pWKl3YIsWUVIQg0fWgCA+ngZLAQLLYNm0KvPwyrbOXWx/Arn0MwxQPFlIOzqNHcofI0dJBOwMKBdC6Nc2b497nDFn7gKKF1I0b1MHPzCQXG4AsJ2q14wipf/6haffu8ki2s1G+PBUivX8fOHjQ8HYcI8WUVESiCWHp0aR2bWDdOnL3O3dOfl4JzwF7INqZnS0PnDEMwxgLCykHR1ijQkMd373MUSlOnJT4Y3X0c1+U8PnvP7JuNmpEcUheXmT9uXxZf4IHewqpnj1td0xrERwM+PoaXm8L1z62SDH2QFyD+oQUQM/jffvIQr5pE3D+PPDDD7Zrny6+vrJbIVulGIYxFbeiN2HsiejkVqxo33Y4M0JI/fsvWWBM8cV3NovU9euUaljXonP8OE2bNweUSqBJE+rMHDpUuEXKVkV5r1yh2Ak3N6BzZ9sc056wRYopqRhT97BZM3o5Ai4u5N738CGJQHulYWcYxjlhi5SD48jpoJ2FunXJApOaSh12U3CWZBMVKpC7TE4OcOdOwfWifstTT9FUFJXdvVtOjKAppCpXpum1a3J2P2si4rXatqXA9JIOx0gxJZWiLFKOCCecYBjGXFhIOTjCtY8tUubj5ibHBekrCFkYzpJswtWV0pYDwN272uskSbZINW5M0+bNabp2LU19fLRHkEXWvtRUOf2+NSlJbn3GIIRUYiJZEC0FW6QYe+OMQooTTjAMYy4spBwctkhZBiEghKAwBklyHosUILukiJTCgps3qXOjVAJ16tAyYZFKTqapqCEl8PKShZm146RSU4E9e2i+tAgpUTNHrZZr6lgCjpFi7I0xrn2OBlukGIYxFxZSDkRWFvDOOy4YO7ZNviWEU59bBiGkTLFI5eTIbm2ObpECZCF17572cvGd69UDPDxoPiJCFkqAtlufwFYJJy5fpuK/YWFyrFdJR6kEypaleUu697FFirE3bJFiGKY0wULKgfDwANatc8HVq2Vw8iSZBzjZhGUQsUHHj5MVwBiENQpwDiEVHk5TXYuUsMKJcyAQ7n2AfqFuq4QTItmFcCcsLZgSJ3XnDlkTZ88ufDuOkWLsDVukGIYpTbCQciAUCqBpUzKB/PefAllZcieLLVLFo3ZtEqopKcYLA2EVdHUlC4KjY8i1TzfRhEC49wH2tUjpyxpYGjBFSO3ercD588DSpYVvp9kRZIsUYw+c0SIlCgILDxBrcesW8PHH+hMCMQzjnLCQcjCaNychdfiwArdv0zJvb+ca3XNElErTE044S+pzgT4hpS/RhEDTIqVPxGhm7rMmQkiVtsECU4RUSgpZqAsbMZcktkgx9scZhVS9ejQ9dcq6x/n5Z2DaNKqhxTBMyYCFlIPRrJkspDQTTWgmAmDMQ1hkTBVSzpBoAtAvpO7epcxwrq5yZ0HQuLFcb6ow1z5rCylxnbNFyjAiKYhwm9JHVhbF9QnYIsXYGklyTte+hg1peuYMxWtaC1FqorD7mGEY54KFlIPRpIkEhULCrVsK/PcfLeP4KMtgauY+Z0l9LtAnpIRorFOnoCD08QHGjgW6dgUaNSq4PxGzdP++dgddkJUFfP45FfUtDuzaR9PkZCA7W/+2Qkg9emQ4xk83UJ4tUoytycyUnxXOZJGqUoWeh1lZptcaNAUhoHiQg2FKDiykHAw/PyAyMhUAsHIlLSttLk/WQjPhhDFFZp3VIpWYCKhUNG8o0YRgyhRg0yb9MWDBwVTkFygYdwUAmzcDkyaRz7+5SBK79sXH06t6dSpIrI+UFJqq1ZQuXh/CpUpYGXNy5OuAYWyBEApuboCvr33bYgouLkD9+jRvTfc+cY+ykGKYkgMLKQekRg36NxIP9NLWwbQWdeuSMHj0CIiNLXp7Z7NIlS1LHRhAtnIUJaQKQ6GQU6TrC44W4qo4gdOPH8vCoLRd55pCaskSICEBOHxYv8UpOVn27TXkFiQsUkJQA9xhY2yLZnyUs7mjixjakyetdwy2SDFMyYOFlANSvbp2RDm79lkGd3c5TsgY9z5nSzbh4iJnnxIi58IFmurGRxmLEFJ37xZc9+ABTePijLPw6UNYo8qVcx7Ln6XQFFKLFtG8JMlufJoIixRQtJAKDZUFNXfYGGtw+DDQsmVBt15nTDQhEHFSbJFiGMYUWEg5INWqaQup0jZSb02EZWbXrqK3FRYpZ+rga8ZJZWXJlreaNc3bX4UKNNVndUpKomlGhvnxOKU1PgqQhdS9e7LgBfRn5tMUV4Yy9wkhVaYMxXsAHCfFWIclS4ADB4APP9Re7oyJJgTWtkhpJuJgIcUwJQcWUg5IZGQqfH3lIX62SFmO55+n6YIFRbukOZtFCtAWUlevkptYQIDcaTeVwixSQkgBcjYqUymt8VEAWY70oc/iZIxrnxBYgYFyfAp32BhrkJhI0/37gdOn5eXObJGqV4/cEePijMukaSqaiTj4vmSYkgMLKQfE1ZWy9wHkriU6s0zx6dwZaN2asqN99VXh2zpbsglAW0hdvEjzNWuaH69QmEVKuPYB5gup0pr6HKAC0YGB8nuR2EOfxckU1z62SDHWRggpAJgzR553ZouUjw9QrRrNW8O9T/O+ZSHFMCUHFlIOiqgnFREhxzswxUehACZPpvmFCwtPdetsySYAbSF16RLNm+vWB9jOIlUahRQgWwqjo4Gnn6Z5/RYpeb4oIcUWKcbaaA6iLFumnZ4fcE6LFGDdOCkWUgxTMmEh5aC0a0dCqm5dOzekBNKyJdCjB5CXB4wfb3i7kmSRMhdjYqQAdu0zFyFUhw2jrItAQYtUXh6QliabFA3FSOlz7WOLFGMNhEXK15dEwZIl9N7ZhZQ146Q071sWUgxTcmAh5aB06CAhJoasJozlmTSJpitWyJ15XZzdIiWEVI0a5u9PdPTv3SuYlptd+4rPxInAqFHA6NFy51PX4pSZqV3kyxTXPu6wMZZGkuR7/913aTpnjnYyBWd07QNsZ5HKzgZycy1/DIZhbA8LKQdFoQC6dZPTWTOWpUED4JlnaH7fPv3bOHOyiXv3LGORKl+erkWVSjsuQqXSjtsxR0g9fix3/kurRapVK+Cnn6gQt+h86gql9HRt315TXPvYIsVYmuRkWQSMGUOi/eJF4NixkmORuniRsp5aEl1LMg9yMEzJgIUUU2pp0YKmBw7oX+/M6c/v3aNOtKsrUKWK+ftTKuU4Hs04Kd3OvDlCSlijgoNlC0ppRnQ+C3a4TLNIBQayRYqxHppufSEhQMeO9H7LFue3SIWHk4ttXh5w/rxl911wgMSy+2cYxj6wkGJKLUUJKWe0SJUrp52hr0oVORucueiLk9J06wPME1KlPdGELoYsUhkZ2kKKY6QYeyLu/ZAQmnbpQtOtW53fIqVQAHXq0Py5c5bdN1ukGKZkwkKKKbUI174zZ7Td1ATOaJFyc5M7OEDx3PoE+jL3aSaaAIpnkWIhRRiySAkhpXyipzhGirEnwiIVHExTIaQOHKDYTMB5hRRgPSHFFimGKZmwkGJKLeXLU9ppSQL++6/geme0SAGyex9gWSGlaZESQkoUi46PL5iMoihKe8Y+XYqKkRLnSZ+QkiSOkWJsgxBSYsCmcmWgalWKmxLiwFld+wAWUgzDmAYLKaZUI6xS+tz7nDH9OWB5ISVc+zQtUsK9p3ZtmublFbRSFcW1azRlixRRlEVKnKfMzIKB8KmpspDlGCnGmui69gFU6FwTtkgVhF37GKZkYlchtXfvXvTq1Qvh4eFQKBRYu3ZtgW0uXLiA3r17IyAgAH5+fnj66adx69at/PXZ2dl49913ERwcDB8fH/Tu3Rt39BW9YRg9FBYn5YzpzwHbWqTCwmQXH1Pc+x4/BrZto/kmTYrdxBJBUTFSkZGUPAQo2CkT1igPDxL+bJFirIWuax8gu/cBdP15etq2TZZECKnYWMuKHbZIMUzJxK5CKj09HQ0aNMDs2bP1rr927RpatWqFmjVrYvfu3Th16hS++OILeGo8pUePHo01a9ZgxYoV2L9/P9LS0tCzZ0/k5eXZ6mswTowQUocOFXRNKwmufcWpISXQZ5ESQqpsWTlFvylCaulSEqp16wLNmxe/jSUBMYqfkUF1ZgTCtS8wkF5AwU6ZplsfwBYpxnros0i1b0/xmYBzW6MA+l6hoTR/4YLl9isGP/jeZJiShVvRm1iPbt26oVu3bgbXf/bZZ+jevTumTZuWv6xy5cr588nJyViwYAGWLl2Kjk9ysC5btgyRkZHYvn07umgOkzGMHurVoz+2lBRKd1u3rrzOGZNNALKQCgmxTKyCPouU6EwFB9Pxzp41XkhJEjBvHs2/8YZ2lsHSTEAAnQtJok6XEKjCIhUQQL9nUlLRQootUoy10I2RAqgOWsuWwJ49zi+kALJKJSSQe5+lLObino2MpDpVfG8yTMnArkKqMNRqNTZu3IiPPvoIXbp0wYkTJxAdHY1x48ahb9++AIBjx45BpVKhs4aDdnh4OOrWrYsDBw4YFFLZ2dnI1hjyTXmSsk2lUkGlUlnvSxmBOL6921GaaNbMFbt2uWDfvlzUqCHlL8/IcAOggFKpgq1/juJcB9HRCgBuaNhQDZWq+JZZGp1VIi0NSEpSwd8fSEx0BeCCwMBchIa6AHDB3bt5UKmKzjhx4IAC5865wctLwosv5tr83DoygYFuePRIgYQEFcqWpd+frkPA1zcPZcooALggISEXKpV8rSYm0m8eEEC/uYcHvU9Lk6BS5drluzCWw5H+FxIS5Htf8xrs2NEFe/a4okwZyzx37EmtWi7YtcsVp08b90wrirw8IDmZ/k8qVFDj4kUXpKSYvm9Hug4Y+8HXgW0w9vw6rJBKSEhAWloapkyZgm+++QZTp07F5s2b0a9fP+zatQtt27ZFXFwc3N3dUUZnCKxcuXKIK2R4fPLkyZg4cWKB5Vu3boW3g/hxbRMBJIzVCQ6uCaAGpkzJwOHDt1C37gNUrZqMtLQeANxw6NAuxMZm2qVt5lwHajXw/vsRqFHjIWJiLNNub+/uyMhQ4s8/9yEyMhXXrrUCUBY3bhxHenoZANVw8GAsYmKKjtCeMeMpAJFo0eIWDhw4aZH2lRQ8PDoA8EVMzCHExtIQdkbG0wCAmzdPIzc3HEA57NlzGm5ut/M/t3dvJICnkJubiJiYQ7h8uQyANkhMzEBMzHabfw/GOjjC/8Lt2x0B+ODKlQOIiZGD9SpU8ED9+o3x9NM3EBNzz34NtABqdSUADbB79wPExBwq9v5SU5WQpO4AAEm6DSAKJ09eRkzMZbP25wjXAWN/+DqwLhkivqMIHFZIqZ8ErPTp0wdjxowBADRs2BAHDhzA3Llz0bZtW4OflSQJikL8hcaNG4f3338//31KSgoiIyPRuXNn+Pv7W+gbmIdKpcK2bdvQqVMnKEXhGMaq+PsrsHIlcOuWPxYvJt++KVPykJNDkf09erTP95m3FcW9Dnr2tGx7KlVyw/nzQJUqbdCxo4QPP6RHR6dOT6FsWQXWrgW8vSuje/fCc5knJQGHDtFnv/oqAk2bhlu2oU5ORIQr4uKAmjWfQffuElQqFT7+mFL0tWpVD4mJLjh+HIiMbIDu3evlf+7aNQp3rVo1BN27d89PSy9J3ujevbvNvwdjWRzpf0HE7PXq9QyqVdNe98orANDwyct58fdXYO5c4MGDUIvcP1ev0tTHR0LduhWwYwcQHl4d3btXNWk/jnQdMPaDrwPbkKKvwKgeHFZIBQcHw83NDbVFfuUn1KpVC/v37wcAhIWFIScnB48ePdKySiUkJKCFyCKgBw8PD3h4eBRYrlQqHeaidKS2lHTat6dkE7t2AXv3Aps2AZ984pq/PiBACXv9FI5yHVSoQDFkcXFuUCplf/+wMLf8GKqEBBcolYXnr9m3jxIp1K0LPPOMG8dH6VC2LE1TUtzyr7mMDHLNCw52y8+UlpzsCqVSvkbF8z4oiH4D8ThMS1M4xPXDWAZ7Pw+ysuTYnvBw+z0XrU2DBjS9dUuBrCwl/PyKtz9xzoKCFPD3p/s2K0v7HjYFe18HjGPA14F1MfbcOmwdKXd3dzRt2hSXLl3SWn758mVEPalM2bhxYyiVSi3z5v3793H27NlChRTD6NK8OfDJJ8DGjcB772mvc7ZkE9ZAM3NfXp6cgcrUrH3379O0dm1OMqEPfbWkdJNNAAWTTZw+TdPISJqKzGCZmfR7MYwlEElm3NzoeiypBAXJz7Xz54u/P3G/BgVx1j6GKWnY1SKVlpaGq8LmDSA2NhYnT55EUFAQKlasiA8//BAvvvgi2rRpg/bt22Pz5s3YsGEDdu/eDQAICAjAiBEj8MEHH6Bs2bIICgrC2LFjUa9evfwsfgxjCgoF8P33lKFu1Sqqh+Jq3qBhiSI6mqYXLlCGOJEqXrPDYYyQEtuIzzDa6BNK6ekFhZSm0MrNBXbsoHnx2BNZ+wBKp17cEXWGAbRrSJX0gZA6deh5de5c8Us0iPu1TBkWUgxT0rCrkDp69Cjat2+f/17ELQ0ZMgSLFy/Gc889h7lz52Ly5MkYNWoUatSogVWrVqFVq1b5n5kxYwbc3NwwYMAAZGZmokOHDli8eDFcuffLmImrK9U5Cg0Fqprmwl5iadaMpgcPyjWk/P0Bd3dZFD18SG57erxm8xFCqlw567XVmdG1SOXlAVlZ9JgOCJDXawqtw4fJtS8oCGjcmJZ5esqp1NPTWUgxlkFfDamSSp06NEBxruj8OUXCFimGKbnYVUi1a9cOkiQVus3w4cMxfPhwg+s9PT0xa9YszJo1y9LNY0oxXl7AnDn2boXj0Lw5dcxjY2VXFxHPU6YMoFQCKhXVXhHuZfpgi1Th6FqkNGNdDbn2bd1K044dZeupQkFWqdRUrlfDWA59NaRKKqKmoHCbLQ5skWKYkovDxkgxDOM4BATQCC0A/PMPTYWQUiiMd++Lj6cpCyn96FqkkpNp6ukpwd29cCGlUU4PAHfYGMuj6dpX0hHufAcPoti17tgixTAlFxZSDMMYxTPP0FQIKc3OlLFCii1ShaMrlISQEoH9ujFSjx8D//1H8506ae9LxEmxRYqxFKXJta9uXbrf0tOB48eLty9xP2tapPi+ZJiSAQsphmGMQiTCFFYlYZECgPLlaXr3ruHPq9XyZzlGSj+6FqmUFIroF+XtxPrHjyl+audOOq81ayK/dpSAR74ZS1OaXPtcXIDWrWl+z57i7Uvcz2yRYpiSBwsphmGMQlikBJpCSjM9uiGSkuRU3LYucOwsGLZIUSypEFKSROsMufUBbJFiLI+wSJUG1z4AaNuWpsUVUvosUiykGKZkwEKKYRijqF5d7ugD+oXU7duGPy+sUcHBKLGFPIuLpkVKiCVAdu1zd5cF0sOHhQsp7rAxlqY0WaQAWUjt3y8PAu3bR2UgTIEtUgxTcmEhxTCMUSgUwNNPy+81R6VFpr47dwx/nuOjikYI1dxcsiTpuvZpbjN0KGVRVCrlDp8mbJFiLE1pSjYBAA0a0CBGSgpw8iSwdy/Qpg0NXBSRcFgLfckmsrO5WDbDlARYSDEMYzQiTgrQb5EyRkhxfJRhvLzI6gTQKLauRQqQrVb//kvpzn/8UbsAr4BHvhlLU5qSTQB0f4mylbt2AU9KXeLOHeDWLeP3o5n+XPNe5XuTYZwfFlIMwxiNZpyUISFlaKSWU58XjUKhHSelGyMFyIk9IiKA3buBt97Svy+2SDGWRK2Wi3GXFiEFyNbeyZOBY8fk5cZm8svMpBdA97aHByWyAFhIMUxJgIUUwzBG06yZ3AnQFFIRETRNT5c7/7qwa59xaMZJiYK8mhapyZOBCRPI1UiMlutD0yIlSdq1pxjGVB4+JDEFaN/7JR0hpMT9I9xsT5ww7vPCGuXiAvj50WAJW4sZpuTAQophGKPx9QVGjwY6dKA6KwIvL7lzZci9j137jEPbIkUxUppCqmFD4Msvi45TERap5GSgVy/avrj1cJjSy6JFNA0LK13JYp56ShY+UVHA+PE0b+y9pFkuQgxCsZBimJIDCymGYUzi+++B7dsLdqaKipNii5RxaBbdlS1SJkS2P0F01pYsATZuJKvUkSMWaiRTqjh0CPj0U5qfMMGuTbE5bm5Az540P3267N5srEXqyhWaVq0qL2MhxTAlBxZSDMNYhKKEFMdIGYdw7Xv4kArvAtpZ+4xFWKSys+VlIusawxjLo0fASy9RJskXXwRef93eLbI98+cD588DL7xAmfwUCuDePXlwqDCuXqVptWryMiGkTI1fnDrVBT//3MCkjIEMw1gXFlIMw1gEtkhZBmGRWrYMuHGjoGufsYjOGiC7U4qsawxjLJ9+Cty8CVSpAvz6K4mI0oavL1CrFs37+AA1atC8MVYpS1mksrKACRNcsG1bJZw7Z/znGIaxLiykGNujm43gt98o6GPNGiAjwz5tYopNYUV5VSq5E88xUoXTuzfg7Q2cOQPExQkhZfoQdLNmFLv2yivABx/QMhZSjKkId9DJk82zjJZEGjWiqTFCqjCLlClC6uJFIC+PngdigIVhGPvjZs6HcnNzsXv3bly7dg0DBw6En58f7t27B39/f/jqK2jClD6uXgVu3CBhJF4PHgCrVwN379IQp4i8XbqUysUDFBE/ahTw9tvy0DzjFBRmkUpMpBgdV1c7ZfxSqYCcHPJP8vWlhmiSnS0HJVWsCHh62qGRRPv2NIr95ZfAwoUSACn/3JpCjRrkGujuDvz+Oy1j1z7GVMQ1U7GifdvhSDz1FPDnn8YlnLCURersWXk+NpaFFMM4CiYLqZs3b6Jr1664desWsrOz0alTJ/j5+WHatGnIysrC3LlzrdFOxhFRq4H9+4F16ygaedcuuZroTz8Bs2fr/5yLC3DqlDysN3gw/cvs3EkCa/x4YOpUcsYfMwaIjLTN97E1WVnA1q3A2rUUEBMYCHz7LRAebu+WmUVhQkrER4WGFtQwVuPWLeCvv4AVK7R7PGXKUEEc4aNUtSpw7Zq83tOTch63bAlUrkwmHcHDhzYR+OHhZKgdMyYXW7b8i9DQlmbtR9yOou4PW6QYUxHXTFFZIh2KjAy6j12s43RjrEUqJUV+9llSSN24YfznGIaxLiYLqffeew9NmjTBqVOnUFZjaPm5557DyJEjLdo4xkKkpFDv1sWFOu8nTsj5kAHy3bh/n3yKjOH6dYq+Xb5cu7z70aNAixY0HxkJ1KtHPkri5eMDPP008PLL2oEyI0fSKzcXWLmSRNSpU8CMGfSPsXp1wTZIEi2fPZs6wS+/TJ8DgLw8Gj6NjqZc0QMGAK1bO4Zz/9Gj1LE/dQr47z8gNVV7/Vdf5c+GHj8Oxb171P7cXKoGeeYMDXEGBQHTpsmf27WLBELdupRmyg4UJqRsmvpckoCxY4Eff5QL32hSqZL2tSCyOygU5AuXkQFs2UKv1q21hVSjRnTfDBtGkfdWrkxarRpw5YqBwlwmIG51FlKMKQhnAsCBi/CmpgKbNwP//EPPx+vXyX189Gj6DxHcvSsXvCsmQkhdv05W38BA/duJ8ZngYO1tiiukrl93gP8yhmEAmCGk9u/fj3///RfuYqjzCVFRUbh7967FGsZYiOXLgTfeKPjEXrMG6NuX5s+do45hnz7ArFmGLUBnzwIffUR/WiJtkL8/0K8f0LmzHI0L0HYffWRaW93cSBC99BJ1YqdOBT78UF5/6BAJPk9P4IcfKAe3IDZWe/7ePXr9+y/w889kWRg8mF7R0aa1y1TOnydBuHmzLARFztxDhyh/uKBCBUoFVbMm/flrDPtWXbsWbqdPk5ujbpqmypW1hdT//R9w6RL1dj76CHjrLRKvNkT0UVJS6KUZT2HTRBMKBYlptRpo0wYYOJAGDgICyBymmypr1SqqlBkQQJ89d44shWfOANWry9tlZdH1d+sWWbjefZcKyzRsSNdUx45Ajx42+IKmIy4rdu1jTEEIb6WSbhGH4u5dCv5bs4bcdnXRzNBy7hwNMlWrRiqoXj16VpYpAyQkAM89Jz/AEhNpWZ06Bg8dFES3/s2bVBi7XTtafvs28Pzz5EwxcqTs1qcZHwXIGTXNt0ixkGIYR8FkIaVWq5GXl1dg+Z07d+DncE/aUkxmJvDee+QfBMidSIWC/iA0hXBgIImYdeuAbdvon2DgQPq3cHenjiJAcSabNtF8ly7AiBHUQbV0PIlCAXTtSi9NZs8mYSjw8CDLQ8+eJCwEUVH073b+PLBjB/D33zR0OGECvX78kc6NpTlzhs6JbrGeW7dkIfXUUySMGjSg+UaN9LufSBLin3oKwQoFFKdO0TmpUYO2r1FDThsFkLWqYkXq5Ccmkvj8/ntg3Dj6R7dRvI/QIsnJ1MfRFFJWTX2em0vVQuvXB5o3p2UTJ9K12aFDwe11z4du8EfdutrVhjU/d+8eXYOLF9M1dvMmvQC6h4SQSksjQTtmTMFelB0Q1oTMTLIw2FhjM06KEN4hIY5h0NfCzw+IiSERVa0aDQS2bk3pBStU0P6PO3CAvsCVK/T6+2/tfZUrB/TvT/NbtwKDBtHg1OTJBlNmPvUU3frHjslC6rff6PEfH09/BfoSTQCmW6RSU+XHDEBjhZLkgL+JA/D77+R00LatvVvClBokExkwYID02muvSZIkSb6+vtL169el1NRU6dlnn5WGDh1q6u4cguTkZAmAlJycbO+mSDk5OdLatWulnJyc4u3oxg1JCg+XJIVCkr78UpJycwvf/uxZSWrZUpLo+Sy/XnpJ3katlqRJkyTpypXitc1cxo+XpGeekaSaNSVpwABJunrVuM+lp0vSsmWS1LEjnY9jxyzbrrw8SZoxQ5I8POicKZWS1KOHJC1aRMdKTTV5l1rXwZ07kpSSUvSHVCpJWrhQkipVkn+/iAhJ2rDB5OObS506dNitW7WXv/ceLf/kEwsfMDFRktq3p5136mThnRfBo0eStGePJM2cKUkffihJMTHyuu3bqU0KhST16ydJ06dL0l9/SdLy5ZL0wQeSlJkpb3vzpiTt2EHXkQ6Weh6o1ZLk7k5NunGjWLti7IDF/hdMZPNmumbq17fpYfVz+bIkTZhAF7Pgjz8k6fhx7WWGSEyUpC1bJGnKFEkaNkyS+vSRpNatJalXL0natk3e7pdf5OdneLgk/f67JOk579Om0SYdO8rLGjeWP3rhgiQNHUrzX32l/dnJk2n5sGHGffVDh2j74GC1pFCoJUCS4uON+2xp4sYNcZ6MuyScFXs9D0obxmoDk4XU3bt3perVq0u1atWS3NzcpKeffloqW7asVKNGDSneSe/sEimkJEmSzp8v2KMtDLVakg4ckKR33pGksDBJCgmRpCeiucRw9672E3bpUkk6erR4+7xwQZL8/ekJ3qOHJN2/X7z9ScW8DrKzJWnuXEmqUIHatH9/sdtjLF260CEXLtRe/uKLtHzGDAse7ORJWTT6+tLOHeXf8+JFuhZ0BybES/OaGzeOllWsKEnffKMlmi35PIiIKHhoxjmwRsdJrS56fG3pUrpmOnSw2GHNY8kSSfLyosZs3Gj94+3cKUlVq8r3a8WKNGCSlZW/yZUrtMrVVZIePJCke/e0b/Eff5SkVq1o/s8/tXc/cyYt79/fuObMny9EW55UtmyGBEjSwYMW/L4lhKNH5fN/65a9W2M9WEjZBmO1gckpbcLDw3Hy5EmMHTsWb7zxBho1aoQpU6bgxIkTCA0NtbTBjDGF69fJNU9QqxbQqZPxn1coyAVt1ixyE0tIoAqMJYnwcNkfYuVK4NVXgW7dZGd2c6hZk+K1fvkF2LDB/hVn3d0pLu7qVYrPamlexjdzMJRwwuIxUhs3UmKTGzcoHdahQxRc7ii+LjVqyMHv48ZR7F/LlvR65x05SAKg3ysggFxAP/+cXJN+/JH88CwIJ5xgBKmp5P7UuXPB8EtN7J6xLz2dnmWDB9P98Oyz2unvrEX79sDp0+TaV64c3ZujRlGCmSdUrUrexHl5wPr1FBKryZYt+lOfA9quffHx9Bf0v/8Zbo6Ij6pTR0JYGPkDaoYFM4RmGUrNmDKGsSZmpffy8vLC8OHDMXz4cEu3hzGXTZsorikzk57owmmbMUyXLuTofvw49Sj+/df41ON5edSJr1KF3jdtSi9HwsODgqgFN24AkyZRD0qppA68eInKrYLvviNRfukSBWG/9hp1IooIrjFUlNeiMVLz5lEyDbWaBgr++kvOvOdo1K1LKe0LY8IE4JNPqCf11VfU+xozBpg0CS7vvw/Urm2RpnDCCUZw+DBpg1u3SOvXr69/O80YKZvy8CHFxM6cKZcq+PJLGmiwVf0ELy+6L997j2Iiv/qKxJQGzz9PemvVKjn08rnnKP/Fzp1Ung4oXEj99hv9ZSclUd4hfWgKqdOnM3DuHI2bMtpojj2dOUMClWGsjclCasmSJYWuHzx4sNmNYcxAkmjU7PPPab55c9uM2JUE/P1JgLZsSdabpk2BhQtJYBVGRgYFI+/aRYHJjiag9HH/Pllw7t/Xv97PT1tIbd5MPQGAelsHD1KGrKFDgTff1M5mp4FI+Gg1i1RODjB3LomoYcNIVCmVxdypA+DpSdfUiy9StPQ331B0+b17FhNSXEuKEZw+Lc//73+GhZTdLFKDB5PVGaDBqjlzaLDLHnh5UeKJoUNpXvD993jrRhx+wyhs2xYJDw9a/PHHcoJZoGDqc0BbSAlLlmYpO11kIQW2SBUCW6QYe2BWHSlNVCoVMjIy4O7uDm9vbxZStkStppHrmTPp/ZtvkkuQeKIzRRMaSmKoa1fg8mWaDhlC6dX1FV5NSKDsUIcOkSXn9m3nEFJhYdQ5P3aMxIhKRVPx0s1kN3w4Cavq1clSN3cuWbRmzKDvfuCA3sPoc+3LyqJaK4AF6ki5u1MHa8UKuvYdxZXPUiiVlDd56FBg9WqoGzWi7JMAcPEiCf3AQPo9e/c2qYfLrn2MQFNIrVxJSS713UriWrGKRSotjZ4nP/5IFqhFi+i6Byjl3Z07ZBF64QW71cbTQlNEPXgAfPklgtPTcRvT8V9OMyzPeQVrgl9H06ae6NyZxkMA/Uk7hZC6d08eZHr4UH+97wcP5G1q1ZIQGkpqgS1SBWEhxdgDk59Ojx49KrDsypUr+L//+z98qFnzh7EuubnU2V26lN7PnEl1bRjTiY6mIsWffELxYb//rl2jaf58YPdu4MIFKqSbl0euZOvWUbpdZ0ChoOvFWHdcTetUq1aUZn7LFooDe/lleV1iIrmUurgAAQGo07gPvNEXt2/75G8i3Prc3Q0XriyUx4/JciiOGx4OvP++GTtyItzcqBCzSkVCSpLo/tasnaZUUrr1UaMopqMIRGeYXfsYTSF18SJdYvrKJolrxaIWKZWKnqkTJ8oPB0A7WKtPH6pz6KgDJcHB5FI8ZQrU+/9FcxxGcxzG+Mzv4bJiMrp0egm//04h6EUJKU2uXgWaNdNedu4cTaOjKbQyLIzUAlukCqLp2nf+PHWTHEGDMyUbk5NN6KNatWqYMmVKAWsVY0WWLSMR5epKUxZRxcPbm8Torl1kEdAcgv3f/6h20PHjJKLq1iWLjLOIKEvg6gp0707JNAYOlJcvWUKd+61bgZUrUeGTQUhAKGY/fgXZa2IAlUorPsrkftGtWyTkBg4E/vzTYl/H6VCpyFo6ejSN1jduTMvWrqUA/BEj6L1AkshyOG4cFaS+fbuARerwYbqE//vP1l+GsSe5uXLnXJRLW7lS/7YWtUhJEh2odm2KcYyPJ7e9P/8kk8tLL8nburg4rogS9OgB7NuHc1vu4h3Mwm1UQHD6LeCVV9D74rT85uvztPfxKbgMkOtOaSIsK+K3KleOhNStW9q3PKNtkcrOLtxdkmEshUWEFAC4urrinu7wCmM9Bg+mGJE1ayi2grEM7dpR9K/mn/i77wJff01FHEV0ds2admuiQ/H00yTqlywBvvgCUpUq8EEGXsEf8OjXAzh4MN8txWS3vpMnKYvkuXNkhapVy9Ktdx7c3SlGbcYMGs0/epSuwzfeoGs1LU2OFTt9mnpdzzwDTJlCWQIrVsRL3zdFJ2zNtzL89huwf3/p1qelkcuXqZPp60uGZsBwxjiLWqTu3qWBgKtXSZnNnk1mg5deooeDpuucE1G3U3mcafMOOla4hKwvJgFly8LnjUH5tcGblbtJaRI1CLx5Cr9jMOZjBADK/wPoF1IXL9JUPP4CA7Pg6SlBrS6Y1Ke0oymkAHbvY2yDyUbP9evXa72XJAn379/H7Nmz0dKGaZZLMi45OQUXpqfTH88rr1AgiosLxUsw1qdHD3oxBREpvZ+gmDgR/SocRrt7yzGs5kH4tWqFuPm0zuhEE8nJlCFr5kwaPq9bF4iJkTNZMETduhS7NmgQpVsXXL1KHVQvL4qjunMHOHAAQdePYiu6oMfdCwBq5lslUlLs0nrGTgi3vnr1yINOqaSxigsXtMcq8vIoZgewkEWqQgVg3z6Kb3z3XUpwUwJQKMiRAfCGi8unwGcfAB4e+P13Wt557VvAxwfI/dbXF4iLQ8S2bRgM4B3Mgrc3heVOnKhfSIl406gomrq40PylSxQnVbmyjb6oE6ArpM6cocyKDGNNTBZSffv21XqvUCgQEhKCZ599Ft9//72l2lWqafHll3D75hvqvLu6kjP0tm2U6ODGDYpTYRhHRKFAYuXmeO9ec4RNBAa4kAePD9LQN2U1IL1auMvOmjVkZRFD4X36UOphs4KrSgmtWmm/r14dWLCAehABAbQsIQEP3v8Wa5an40hqTUiS7N6lM1jOlHCEkKpfn26rzp0pf8vff1OGccGjR5TPCADKli3GAW/elFVA5crAp58WY2eOiYumb8+TZE/VqwPVw9OAH69TnOeaNfmbSC4u2KjuhpXoj/btaUykL9ag1e5zQOp7WiJTCCmRyAcAKleWcOmSguOkdBAxUh4eZHVlixRjC0wWUmrxZGWsQ2oqyly5AkVurnZEMEB/QqUpLodxSkQpLuHpm3AvF2vRFx337ABa/0oxOw0aUC/t+nXqhYhh1TJlSETVrElubF272udLODN168oBFYLQUORO/xGvL5fgkkQeqm4pSWiMWKSkNLFPOxm7oCmkAMq4v3EjeeiOHy+Pc4j4qMDAYlQYmDUL+PBDio3q1as4zXZOfH1pxGLrVnrWpadTrNhz/dC7RlVIEj3iqlbKxRR8ghq3LwNVZlKG1REjAFfXfPc9TSFVqRIl5uDMfdoIi1SjRhQieuaMfdvDlA44n4mj4eeHLQsWoFNeHtz27CH3nOhoct3p3r1k1MxhSjS6QupeghvWoQ/auh+E8t9/qQhyYCCN0qrVVKNlzhzauG1bCtjo3ZuvdQtDVgUF1Grg0JZkbEEX1MRF/HD9F0D9is6wOlNS0RVSzz1HuXauXqXEI08/TcuLXYx3yRK5gO3x46VTSAF0X+kMCClAdc7v36e/9ZCyLngNE/EVxqN64hWyyv/6K1Sz5iI+ngY6NIVUdDRNWUhpI4RUs2YkpK5eJSuVk4bfMU6CUULqfRNSDf/www9mN4YhcgICIHXvTskkGMbJ0BVScXHAaryLbjP7ovvOseRDJIIvlEoapRUoFOzUbiWUSvL0S04G9h5wQ1kEwhfpGH91MND0R6rnwxbvEs3Dh3KCgnr1aOrrS7fc0qWkfYSQKlYx3vXr5f+v994jUxejxcaNNJZExngX7C73EurEP4/rH8xB5PwvgWPH4Nr5WVTCKdxzj0ZICIWMAkD9+mSR2rKFHp+GsgCWNoSQio6mgaOkJErW0aiRfdvFlGyMGoI8ceKEUa+TJ09aubkMwzg6ukJKpD8PqBtJtVeuXiV3l/v3KducqFzJWB1hXdj6rw96YCPG4VukKvzIYtCuHbBnj13bx1gX4epUqZIcPgcAr75K07/+ovrcQDEsUmlpwGuvkbV52DAqbu7oqcztQP36QJs28vuqVYFcKHGg6XuUWvGZZ+CSloqleBUVI/K0TmG7dhKqVqVBkWXLbN92R0XESPn4yN7N7N7HWBujLFK7KCUNwzBMkQghdf8+TQukP69SxeZtYojgYNKxlB3MA1MwDv/zH4kr7V+nmlSDBlHa+WJlF2AcFV23PsGzz9J9e+8eJcjs27cYFqkffqDESFWqUFZJdhk1imrVgH//fXJvvhgKLF+OnDoNcTSzCaIicgG45m/r4gK8/TYwZgyFob3+OmtVQLZIeXuTkNqzhxNOMNaHn3AMw1gUTYtUWprsuWd0+nPGauizLtxID4G0ZCnFYd65UyKzqjGEISHl6irX2V6yhKZmWaQSEoDvvqP5SZOo/hljFKJwb34K9OhozP/oCsbgR5Sr6FFg+6FDSTCcO8eGZIEQUl5ecir/S5fs1x6mdGBWsokjR45g5cqVuHXrFnJ0ah6tXr3aIg1jGMY5EUIqJUWuLO/jQ7EYjH3RtC64uJD3VW4ukK30heeff1IB32+/tV8DGasivO91hRRANd6nTwf++YdSn5tlkfL1JSG+YwfQv39xm1uqEELqyhV52eXHoQCeJJp48ACKmJh8n8zAQPrN5s4lq1S7djZtrkMiXPu8veXSeiykGGtjskVqxYoVaNmyJc6fP481a9ZApVLh/Pnz2LlzJwI0na4ZhimV+PnJounECZqyNcox0OwU16kjz6ekgCKy//qL3fpKKNnZwKlTNN+4ccH19erRNaFSUSIEsyxS3t7AuHFU95Bd+kyigEUKcmKQiuVVQP/+cBsyBE2mTYPLV18Bs2bhkzobUA2X8c8aFW7dsn2bHQ1N176aNWn+2jW6phnGWpj8pPv2228xY8YM/PPPP3B3d8dPP/2ECxcuYMCAAahYsaI12sgwjJNRvjxNjx+naX58FGNXNDvF9erJgldvUV5JskmbGNtw9ix1KIOC5PTZuvTtS9N164qZtY8DdkxGhI7Gx8v3oyjGG1HRlQLZAEQcOADXb74BRo1C1Lu9cRk1cEcKx851XFlbU0hFRJAnRG6u7BnBMNbAZCF17do19OjRAwDg4eGB9PR0KBQKjBkzBr/++qvFG8gwjPMh3PuEkGKLlGOg2SmuW5esh4COkNq9G+jcGfjoI1s2jbEyR4/StEkTwzqnd2+abt4M3L1L80ZZpHJyKIf6ihVyjm7GJAID5ftTdPyFkKpQ0QX44gvkbt+OS/37I+/11+l8N2yIHDcv/IbXcPyKn13abWsSEoDYWP3rNGOkFAp272Nsg8lCKigoCKlP/nUjIiJw9klKlMePHyNDXMUMw5RqhJASMRkspBwDzU5xnTqykEpJ0dgoOZlcs/78k4KomBKBppAyRJMmZE1OS5OzbRplkVq3Dli9Gvjgg2K3szRTrRpNz58n66HIfCqK8Upt2uDiK69APXs2FS4/cQJ//ZaKCZiQn0gEN28CGzbYvO22QJKAFi1oEEiUItREM0YKkN37Ll60TfuY0onRQkrUiGrdujW2bdsGABgwYADee+89vPbaa3j55ZfRoUMHqzSSYRjnQggpztjnWBhlkeralQLa796lfMxMieDIEZoWJqRcXGSrlMAoi9Rvv9F02DDAzawcVgzkYsh795KQlSQ6naGhhj9Tr6ErVHDH6dOAlPgA6NgReO65EllgKimJrHUZGZStUBNJ0nbtA9gixdgGo4XUU089hcaNG6NWrVp4+eWXAQDjxo3D2LFjER8fj379+mHBggVWayjDMM6DEFICjpFyDCIiaBoQQEVZ/f3pvZaQ8vCQg2X++suGrWOsRWamXE+nMCEFAH36yPPu7kZk24yNJQsmAIwYYXYbGTnz3p49GvFREYXn7ahVi9LXP3oE3M0oA7RqBeTlyWkYS1Cso2ZGQ82kHACQlSXPs0WKsSVGC6l///0XTz31FKZPn44qVapg0KBB2LNnDz766COsX78eP/zwA8qUKWPNtjIM4yToCim2SDkGkZFUJ2jVKuqc6XXtA4AXX6TpypUc81ICOHWK+tahobKbmCGefVYWTyEhRuSNWLiQph07Gs5iwRhF69Z0vi9elF0xi/q9PDxkwXD6nCuwYAHwzjskoD78EDdbDcSc79Kt23AboSmedBNIaEaWeHnRVFikLl4sUXqScTCMFlLPPPMMfvvtN8TFxeGXX37BnTt30LFjR1SpUgWTJk3CHTF8wjBMqYeFlOPy6quA8MLW69oHUKc4KIgiu7dvt2n7GMtjTKIJgYcHeXcCRsRH5ebKQuq114rVRgYoUwZo0IDmhWdeZGTRnxN1wU6fBo2QzJwJzJoFyc0NUQdWoN1HTXHzpzVWabMtKcwiJeKjlErZu7RaNbreNeuiMYylMTnZhJeXF4YMGYLdu3fj8uXLePnllzFv3jxER0eje/fu1mgjwzBOBrv2OQd6XfsA6o0MGkTzkybxcK6TI4RU06bGbS8MkmJE3yDr1wP37pHpStMnkDEb4d53+DBNi7JIATpCCiD18M47WDBwJ+JQDrVxAVl/O38CCk0hZcgiJdz6xLyoysPufYy1KFbFvCpVquCTTz7BZ599Bn9/f2zZssVS7WIYxokRdaQELKQcE4MWKQD4+GOgeXO7Z2JLTyfDGGM+xmTs0+T554FNm4Cffipiw8BAoGVLio3y8ChOE5knCCElMEVIiYLLABVg/mxza9TGeUzEeCwJ/8RibbQXmkLqyhXt8R19QgqQ3R7tnXAiJ4cqSixZYt92MJbHbCG1Z88eDBkyBGFhYfjoo4/Qr18//MsZnhiGARVCDAig+cBAwNPTrs1hDGAwRgogs+KhQ5R4wo4FVlu1AipXBh4/tlsTnJq0NODCBZpv3Ni4zygU5N5XpEvus88C+/cD33xTrDYyMiJOSmCKkLp0SU66sGoVDUA8VgRhAiZi3YXqtEKtdspsnJKkLaSSk7VToGvWkNJEM07Knnz+OfDdd3L4mj4OH6bvxTgXJgmp27dv4+uvv0aVKlXQvn17XLt2DbNmzcK9e/fw22+/4WmRu5NhmFKPcO/j+CjHpVCLlAPw6BHVIktPB65ft3drnJOTJ6nvHBFR0FJsMVxdrbTj0kdQkCyMAOOEVEQExVfl5cmi+eefafrWWzQ9fx5IScgC2rQhtfbff5ZtuJVJTKQBH4WiYOFioGANKYEjWKS2biURBdCzNimp4DZ//EEOAKNG6ay4dk0u6sY4JEYLqU6dOiE6Ohpz5szBCy+8gAsXLmD//v0YNmwYfHx8rNlGhmGcENFpY7c+x8VgjJQm6enAtGlUYMjGsVLnz8vz+jofTNGIkfh69Sy408xM4IcfOILfSmi69xmTbEKh0I6TOn4cOHCAQh0//xyIiqJb98gZT6BKFXrz5ptOlZFTJJeIjARq19ZeBhh27bO3RSo+njLRaxIbq/1erQa+/prmtfTtunX0BaKigDlzrNpOxnyMFlJeXl5YtWoV7ty5g6lTp6JGkVGoDMOUZtgi5fgU6tonSEkBJkwANmwA1q61QatkNItuarrxMMZz9y5NjemQG83SpRQ717o1JyKxAkJIuboaPxAlsv2tXEn1eAGKdQsLkwv9/vcfyDRSpgyZKv/+24Ktti7Cra9aNdKCgLZFqqgYqevXgZy9h2x+vX7wAYmpevWAp56iZTduaG+zfr0s9GJjybKIffuAl16iNzk5Fh4JYSyJ0UJq/fr16NOnD1zZhM8wjBFUrkzTqCj7toMxjFGufeXLywknPv4YUKms3i6BpkWKhZR5CCElijEXmxs3KGoeAEaOtGv8XEmlQweyurzwgvFek8IitXEjcOsWUL06MGUKLWvenKaHDoGKiQn/scWLLdlsq6IppKpWpXlNi5Rw7dONkSpfHvDxUuNL9Xi4t32GrOsCzSq+VkCSgM2baX72bFnUaVqkJEn+nQDSTPHbz5AHQFYW0KsXBU+1bm3VtjLmU6ysfcVl79696NWrF8LDw6FQKLBWZ7Rz6NChUCgUWi/dOKzs7Gy8++67CA4Oho+PD3r37s01rRjGAXjnHWDqVGDMGHu3hDGEUa59AHWcQ0KoN/Prr1Zvl4AtUsXHokIqN5fS4icnk5njvfcssFNGFz8/uvZXrDD+M5pxVV26kPVJDGJpWqQkCbKv2fbtgJP0l/QJKWMsUoqbN7BR6obxeOI7J+KN1Go6Ufv3W63N16+TS7K7O4lZUa9a0yK1dy/9Lh4eJPqa4AiCB7Sn7DotW9JFoFm3YP9+uIwezZZgB8KuQio9PR0NGjTA7NmzDW7TtWtX3L9/P/8VExOjtX706NFYs2YNVqxYgf379yMtLQ09e/ZEXl6etZvPMEwhhIRQ/5td+xwXo1z7xIYTJtD8xIlGfMAycIyUady8SXVxb96Ul1lUSH37LWV88/MDli+XK58ydqdxY+DddymB4saNlC1V0KgRxUslJDzpxFeuLLtlisq/Do4QUlWryq59hcZI5eYC06cDdeqgbdZWZMITp97/HZgxg9bPnUsq5rffrNZmEe/UsCEJpUqV6L2mkJo6labDhwNNG+ViOV6Be0oS1SrYsEFbGSYkAJ06wXXOHFTcudNq7WZMw65PwW7duqFbt26FbuPh4YEwAz2x5ORkLFiwAEuXLkXHjh0BAMuWLUNkZCS2b9+OLl266P1cdnY2srOz89+nPOkUqFQqqGzotqIPcXx7t4OxL3wdMID1rwNKS69EaqoElaqIwPOhQ+H2449QXLmCvLFjoRZpwazE48fAvXvK/PcPHqihUpXOATJjr4MJE1yxeLELvLzy8P33agDA3btuABQIDVUVzyvzzh24ffUVFAByZ86EFBlpUzdPpujr4PvvaapW00vg6go0aOCKo0dd8O+/uahQQYJi0CC47dsH9b59yLNzrbiioNTndB1XqqR6kshIifh44OFDFfz8gNRUFwCu8PTMg0qlhsuECXD99lsAwKnAtnjx8Vx8XLcqaj85d4o6deAGQFq9GrkzZxY0ZZnBhx+64OZNBZYty4O7O3DwILWpaVNqU2SkAoAbrl+n521GBrBlC32vd95RYd48F/THSiyp9hVqb/kN8PXVvsfKlIHL+PFw/fRT1J0/H7kjRwK1ahW73Yx+jP3fdfjhpN27dyM0NBSBgYFo27YtJk2ahNDQUADAsWPHoFKp0Llz5/ztw8PDUbduXRw4cMCgkJo8eTImTpxYYPnWrVvhbYGbyRJs27bN3k1gHAC+DhjAetdBWpoSQHdkZyuwbt0mKJWFu4uEDByIZ776CtLSpdjVtCkynzyLrcGFC0EA5LiAixfjERNzuMjPeSYloeYffyCpTh3cfvZZq7XPHhR1HWza1BGADw4cSERMzH9QqVzw4EEvAMD589tw546ejoEkwSshgX7LQuKdKm7bhkZ5eXhUrRr2likD6HiHMLbDnOdBaGg9AJXx11834ed3Fm5+fvCbOhWPqld3+N/y8WMPpKV1hYuLhMuXNyM2Vg0/v65ITfXAkiX7ER2dgnPnagGojri4G9iy6gi6/PgjXAGcHTYM71yeiEv/RmL//jMICnpSR0GS0DE0FD4JCTj19de4W8wYpORkd/z0ExkGJk8+jKZN47F1a2sAQXB3P4mYmDu4f98bQCfExqqxcWMMLl8uA191A3T23YMrVyRkZUXjNBrgjaDZGLdvn/4D1aiBlnXqIPjcOWT06YMdU6cij4thW4UMYeYsAocWUt26dUP//v0RFRWF2NhYfPHFF3j22Wdx7NgxeHh4IC4uDu7u7ihTpozW58qVK4e4QvLujxs3Du+//37++5SUFERGRqJz587wF0EDdkKlUmHbtm3o1KkTlEpl0R9gSiR8HTCA9a8DzezHrVp1Q9myRXyge3eoQ0IgtWiB9nXrWqQNCQnA2bMKtG8vafXj79+nNy4uEtRqBZTKcujevbvhHWVmwuXnn+EyaRLg4oLwZctQr8gv5BwYcx3cuQPEx9O6tDQ6VyKo3cNDwosvdtKrk1zGjIHrzz8jb8wYqIWfkT6io5EXFAS/ihUL/x0Yq1Gc58GDBwrExAAZGdHo3r2ilVpoHf79ly7cihWBPn26AgBq1XLF4cNA+fKt0b27hO3bKVKldu1K6NIvEoqgIKj//hs1fv4ZdUe7Yf+/QLlytdG9e838/boMGwZMnYqnLlxAg8mTjW6PJJH1qVo14I03yPS3bp18c9282QyffJKHGzeoi/366/VRpUp95OQAb78tISfHFY0bd0fOgeM4jqdQMf0OELYXbr1r49dfgbS0sELvsdwGDZDVuDECbtxA95gY5FnRPbE0k2KkC7tDC6kXX3wxf75u3bpo0qQJoqKisHHjRvTr18/g5yRJgqKQkTUPDw946FHwSqXSYTqtjtQWxn7wdcAA1rsOlEpy78vKArKylDDqEG+/DUvmbh07luKpf/2V4nsEIh1ww4YKHD8OPHzoAqVST1hvbCxVH124kCr4AkD79lCqVPQF1WoKqu/YEXCxa1hwsSnsOjh4UJ6/cUMBV1dyfQKAiAgF3N0N/Livvgr8/DNcZ8yAa+vWcu5sXerX185owNgNc54HIo16crKe+0itJmukg2ZgFAMC1aop8r931aqUzO7mTTcolXICPj8/VyjdXYHOnYHOneECitcFgMePXaFUajy9Bg8Gpk6Fy9atcElOliv9FsHRo8DMmRQi+OqrrggI0L7/NmxwweuvuyAnh3ZZo4YSCgU9jiIigNu3JeRNn41+sz+GG1R46F8JQa6uqFmTuuTXr9P9a/BxVbEiDo8dixZffgmX33+HS716cmZVxmIYe4851b9K+fLlERUVhStPog7DwsKQk5ODR+LP8wkJCQkox1VAGYZhisSoFOj6kCTKp3zgQLGOf/kyTSdMkFMYA3KiiVataKo3a9/vv1OMwPffk4iqVAlYtIiEU2QktbFNG8rOtWFDsdrp6OzZI89nZwP37smJJipU0NlYI0YYzZsDb79N88OGFawWypQIAgJoWmCQ/bXXSGWdOGHzNhmLZsY+gW4KdOGF5eVZ0D1ZGKYLJKypXZsyceTmUgEuI7l0iaa5uYDwstRM/pecTEk/AKBZM219Gh0NfIIpqDTzfbipVfgfnse+n04ATZogKorEWWYmcP9+4W14UK8e1CIBkI2S/zD6cSohlZSUhNu3b6M8RRqicePGUCqVWv7C9+/fx9mzZ9GiRQt7NZNhGMZpMDoFOihh21NPPek0zJkDPPMM8OmnxTq+6Nzcuwf88ou8XKQ+F6ELDx/qZPzNzqYCLNnZQNu2JJSuXgWGDpUtTwqFvINJk0p0yuC9e7XfX79uIGPfhQvUI924UV42YwblyE5OBl58UdvnEwC2bgVWraIMIIxTIu7z5GSdFXFxwIMHwI4dNm+TsZw6RdPateVlok5hbCyAhw/R/OLv+AhT8e6nvpQuVmPkxaCQAoBXXqHRpAInxjBC2AF0G6WnA8eP0/vevWm6dStNRQ0vQZ3yD/EJqHDUZ65T0B8rUbdVIAASUSKzn2ZGQkOoP/6YimN/8YW8MCmpRD/nHBG7Cqm0tDScPHkSJ0+eBADExsbi5MmTuHXrFtLS0jB27FgcPHgQN27cwO7du9GrVy8EBwfjuSeuBwEBARgxYgQ++OAD7NixAydOnMCgQYNQr169/Cx+DMMwjGGMToEO4I8/aOB65UpQj0GhIFNIMawYmpamyZNJ0FHGPlomLFK5uUBamsYHPTyAdeto6HfnTqBnT/3VS8eMoSqdR46QpaoEEh9PrpAKBaXBBgwIqbt3yTp3+zalMhep3ZRK4K+/gDJl6DwtX659gGnTqDrs0qU2+T6M5TFokerQgaYOLKSEsaxRI3lZeDhNpdt3gMaNMer4UEzFJ1DmZNAgj4YZqFAh9cYbdAN98onR7RFWdIDydBw8SM+nyEhyVdZEV0i9fHc6ApCCK971MTnvQ/j7K/LrSwH6iw0bRKGgum6iDIFKRRb4Hj1I4e3dSwMnLKysil2F1NGjR9GoUSM0enJ3vP/++2jUqBHGjx8PV1dXnDlzBn369EH16tUxZMgQVK9eHQcPHoSf+OcHMGPGDPTt2xcDBgxAy5Yt4e3tjQ0bNsDV2HLgDMMwpRhTXPtu39bYNjISEFnxzOxgq1TyccPDaWB80iTg9GlaVqEC1SGjNO1POkKaKWmrVwc++6zw2KfQUDn4atIks9rp6AhrVL16VH4GoGKlWkJKpaL4p9u36bytXat93ipWBD7+mOa/+Ua2SmVmyn5LnTpZ+6swVkJYpLKygJwcjRVi0HnvXm2XTwchPp7c3BQK7RC9cuWAUMRj7tUOwI0biPeIxBK8iss93ycRoZGErFAh5etLAy0moCmkEhKAn36i+VatqIbuE6cpAOTap0mQdyZy4YqxGV9BggsaNtS+DfXVyDKa//4jc9mmTTSw1LYtmfEGD9b50RlLYlch1a5dO0iSVOC1ePFieHl5YcuWLUhISEBOTg5u3ryJxYsXIzIyUmsfnp6emDVrFpKSkpCRkYENGzYU2IZhGIbRjymufUJI5VuGhgyh6ZIlZo16ivBWhUIuTDl1qjxIXqcOTYOCaJoc+xCoWZN6Lk+sKb//Tv2GQvnwQ7K67NlDEeolDCGk2raVXZ4KWKQmTiRrU2AgsHmzHIGvydtvk7vmF1/II/r79lEHu0IFoEYNa38VxkpoJiTWskrVqUOqJDOTYh4djCcOS6henTSPoLxPCraiM6rmXYZUsSJGVN+PIViCK29+TzeCBuL5UWRRbyPc+6imFc2LEk7//EPT1q1JFD3/PL2vUUNLzwEAHnw6A1VwDetBPoCaVjbARIuULq1aAWfOAP37UxXg6tXJSr9sGVmpOJbKKjhVjBTDMAxjWUxx7dOySAFAv37Uu7l2jQKoTES49QUGAgMHUrhVSIhsDBFuaqIjFDrpPVII8+YBOTm4coVConr31o5bKECFCnI2us2bTW6noyMSTbRpI49oawqpmon7yG8SoPSImr5Emvj6UvKQwYOpA5aRQSIZIMuFg2Z1Y4rGzU2uOat1rysUDu3eJ9z6GjbUXh7kn4v16IPTqIfEP3cgNo9SuusrBSosUhkZcnY/LU6dohEIXfORHhIS6PwpFMC772qvE27Ib79Nt9ibbxb8fKVKwC1EAaB7yaJCCiD19vffdOIuXSKV5+NDLn4mxIExxsNCimEYphRjrGtfRoY8opu/rY8Pxc4AcofbBISQCgqikdxJk8iNZ98+Sjzx0Ufy+lbYh/I7ltGGixYBnp75LoC5ucC4cUUcTIxSiyHuEsLDhzQIDZCQEhapq1cpzswPKaj17atkwRs6lEarjeHoUbL+iXipXr0s3nbGtog4qQL9aSGkHDCGUF98FAC4hgTh53JfoQFO4a5X1fysffqEVECA7D6nN/tnVBRw8yb57N25U2h7hFtfVBTQt6+8PDBQtqDXrEkDGaNHP1mZnk6DTmfPIiJCDmnS9700hZQxRn7dvDAF6NqVRlo2bSJ3bMbisJBiGIYpxRgrpIR1A9BJ+vDSSzQ1Iw26EGbC4gSQIaRVKxrNFR2/smWBl7CC3gwenB/BfeGC/LlVq4owig0YQB9Ytcrkdjoy4hxERVE4mBBSDx5QWEQ6fKDo9xytmDnTuJ3m5JCQkiT63M8/G64vxTgNwr2vgPW5Y0egaVOaOlhiAkNCCqD4SUCB+HgUKqRcXIpw7wsMlIMLi7DKCct39eoUC/XUU/S+ZUsDoZqSRDGaa9YAffvCDbn5esbDQ3YPFERHk7UrLY2sX4ZQqRSYONEFvr7AiBFF/GyNG1MAJWMVWEgxDMOUYgx2rnQQbn2Ajuhq3Ro4dswsS4+mRaowgspI6I319EZYwCDXmhLfYezYQjoUwcE0VFzC3NOEC5AYyQ4IkF2ZACA41BWuM2dQbJhGoqZCUSgoLuqXX2gI/q23Stx5K40YTIFesSJdH1995VC/c2qqfH3nCylJokx7MTEIC6U4ybg4uQadobwRhSacAIy2ygmLVPXqNB0xgqYDBhj4wJw5wJ9/khlq8WLAzS3fs7ZuXRQogu7hQT8HYNi97+xZ4KOP2mDSJFdkZ1MtcqPy6OTlAQsWFLtkBaMNCymGYZhSjLEWKU0hpWWR8vamYVlNfxUjMVZI1VMdRyTuIFvpI3d4IFtjpk0jL8NDh2jgtzShK6QAMiJ1QwyUyJGL8Wqqq6JQKoH33jOcUp5xSgymQHdQTp8m3RQRoZEbZccOivMbMADRZemLFGWRAkwQUjt2FGre0S0O/H//R8d/9VU9G2dlUaVxgB5ST4KoRK0ofVY2QKdGlh5efNENsbGBKFtWwhtv0LIvvjDC2H7iBDByJNXfE8W5mGLDQophGKYUY46QMibDnzEYK6Sa3F0HADgT3iU/F3peHtVOAigLuxgZ3rmzkB0dOUKuiPnBC87PtWs01RRSnQP+wwb0whZ0QVSY46W0ZuyDQYuUIDW1iBvIthRINCFJwHff0fywYfCLDARAz6a8PFpstpBq2ZKeLffvyw8WPehapBQKcqnVa8hbsYJ8bCtW1MpMMXQo5bUQzyxdxOCHpju1QKUCrlyhg+3fn4u5c4FRo2jd4MFFJKlo0oRMZ5JEGVc5+YRFYCHFMAxTijE2/bmmkMrM1AlyvnGDegUi76+RCCFVlLHkfssXMAmfIqbcsPxlN2/SgK+HB8UVCHeZQlMcp6dT4dn//c/hYkHMRXScRLY+ZGZi1ImhcIUadxGBchU97NY2xrEo1CKVmkrurx06kJhwAArER/3yC7B1K1lJ33sP5crRYk3LjdlCytOTxBRgME5KrZbvN2GRMogkyTGJb7+tZbFv3ZpKPj39tP6PigLa+oSU5m8nXAC//572mZFBnnuFMn06pbs/dQro08dAGkPGFFhIMQzDlGKMTX+um8wqPV3jjVJJjvpr15pkrjLWIqVoUB+fYxK2KnvmLxNufdWrUx8lOJjeP3hQyI6aNaON794Fbt0yup2OTAHXvvHjEZp0EfdQHqMwM79TxjCFWqT8/OS0cw5ildISUgcOkLspQMXmqlZ9kmxCFlIuLgVjjgRFCimA/PPeecdgYoY7d0h3KJWU3KVQDhygL+Dpadj0ZIDCLFKPH9PU0zM3/7u6uclWqT//zC+xp5/ISMrg5+dH2fxeeqnggbKzgXPnaMBp3z6T2l4aYSHFMAxTijHHta/A9hER5PivVptU1FNf1j59iPWaqYtFoonatWlqlJAS8VyAWXWvHI2HD+WixpUrAzh4kIanAbyOX/EIQSykmHyKjJHq2JGmDlBPKieH+vIA0CT8HiWZyc0l17T33weAAhYpb2/DuTKMElJDhgCzZhUo6CsQbn2VKxsREtq0KZUOmDjRtPhEyBYpfZnYhQj29lZpLe/Rg57lN28akUC1USNg3TrA3Z2mvXvL6/77jwJO69alUglt2pAVkDEICymGYZhSjCHXvgsXgJ9+kmMPChVSgFyNcv9+o49tlEVq+nRUOr0eHsjSElLCIiXSBxslpADZfceEdtoLraQeehDxUeXLAz7eEjBmDCBJSHthCDaCrHcspBhBkRk6NTPX2dn19epVElN+fkBk3BFyN6xTh3zXnqglYZES3mmG3PoAI4VUEejGRxWKuztVGRfF8EzAGIuUj4+2kPLyolJVAPDHH0YcpH17YONGeh5qphyMjqaHvr+/7C89eHDhudhLOSykGIZhSjGGXPvGjqWcDIsXU4de/IEHBtK0QCdfCCkTLD1FCqn0dODTTxE9ug8icRtJSXL/zpCQKrKj5CRCauZM+m2WLjW8jZZb3z//0Giylxe8fpwCjyehUflZ+5hSj8GCvIJWrUgA3L5dRNYC6yOsMVFRgKJvH2DGDGD9esDXN38bYZESWERIpaWRSSc+vsAqzRpS1kQMfty/X7DgrmyRKliJd+BAmv79NyWlKJKOHek5qCn2QkKokvfjx2QSrFOHzsWwYXYX144KCymGYZhSjBBSGRmy9QmQ3WW2bpU7Nf7+QHg4zRewSAmBcuiQkf/iRgip/fsBlQrqyIq4iqrIzaV+jiQVdO0THaXMTDkVsl5EO8+etVz6QQtz8ybwySc0v3at4e20hFT58uSGM2oUXCPC8N13FDehW/CTKb0UaZHy8QGeeYbm7ezel7d1B/yRLA8EjB4t5wV/Qtmy2tn5DdWQEtsCRgipvn3pGfHPPwVWCYtUkYkmPvkE+OYb/SYlIwgNpe+lVhfUc4YsUgBlLw0Npe+4bZsJB9T0h1Qo6FmiUNAJ/fNPyugTEwPMn2/ydykNsJBiGIYpxWjWaNW0MsXF0XTnTjkvQ2RkITFVtWuTuSo93agaJbm58uiqQSG1axcAQNHhWXh40J/9w4c0UpuSQsHlolPj60uD6UAR7n1hYeSy0qiR3lFnR2DMGLnAqAi414dw7atSBZTaePdu4OuvAVC25Z9+cqj6qoydKdIiBWjXU7IXx4+j4089cQRNUbuM4QyCLi4kHAQWsUiJXOt6CoyLz5YvX8jns7LInPzFF9pBnSbg6ioPWOlqMfHb6RNSbm7Aiy/S/PLlZh26IPXqkVl89WrK284UgIUUwzBMKcbDQ850JUaqc3LkJAYPHsiDs5GRsmdNAdc+FxdyDapVS/5wIYiRVQAoU8bARk+yhymefVYr4YSwRlWtinwXNoXChDipK1eAY8e0iy85CJs2UVFhMdIeG6t9rjQpkLFPoTCctowp9RRpkQIoqcPPPwPffguABL1NPboePAD69YMy9//bu/PwqMrrD+Dfyb4QEhLIRsIiELZQZN9UQCEKglBtAVsVautaUArqry4VtIs7LlCrVVyrxdoKrYpsIpsssoMgyBL2hLAnIWS/vz8O79w7yWx3MpOZTL6f58lzJ7Nk3iQ3N/fcc97zlmIfOqBphxSnTzeW97kTSJ0966Krneq1bieQUhc3nGW+sHatPDE1VRo2eMhRwwlnGSlAD6QWLfL4rWv7+c+Bn/6UxxYHGEgRETViFos+70ldQK05r1hd3czIcNHl77//lShn+HCX76uu7sbHO+iAdeGCBDsAMHSoNZA6c6b2/CjF7UDKWA8UQCoq9HU7p07VWyxv324/rbR/PzAZszHkf9Nc96+nRs+tjFTnzsD996OiTQc8+qj8vf/ud/UyPAlAbrkFOHwYJ2La4Tb8A+kZzk9TzQZS1dUuvn+Vkdq+vVbE5VYgpTrc5eTUKR3saC0pZ3OkAD12O3u2xhIV3sJ5UrUwkCIiauRUGcmJE7JVZX2KCrCMpX12O8qFuP8vxeX8qFWr5ESmQwcgI8PmirIKpNT8KMXtQEopL3d7vPVh924p12vaFJgxw3hxvPYJWVEREHLyBP6Mx5Hy8cuSxiJywpiRcnY+fOCATBN69lkNVVWSoFLHBp8pL5fMx6pVQFwcHsiYj/No5rJZiurcBzgPcCIjZQoY4KLirmNHeXJREXDwoM1DpgOpOnDUuc9VRio+Xj9G22uf7rHqauDpp6WO2KtfuOFjIEVE1MjVvPqppg4Z508BtqV9Tvs0VFW5qJ9xI5DatEm2115r87yTJ/VzFbV+qOJ2IFVeLuu8xMXVrR+ylx06JNusLBmas0Dq4EHgRTyEpigC+veXxUSJnFAZqcpKPSiwZ8wYIH3jAmwJ7YMJGWtQWQm8+aYPB1ZVJWs4ffmlLGD75ZdYeVYWxXXVvt/djBTg5jypsDB9Qd4a5X2qzXpUlIPXFhTokxrVmlweclTa52gdKSMVhNVcsqJOQkJk3lxuriy+TlYMpIiIGrmagZTKSA0aZDuZ22mzCWXsWDljU2V5DrgMpGbOlEvjl1vzque98orc3aKF7TqSgIkW6BERckZSXg5s3OjiyfXn8GHZqpK+moHU6dNy0f6DD4ALC77BL/BPVCFEUgYmsoHUOMXG6tVmjipBi4ul6/VILESPqs14KflZAMAbbwBlZT4aWH6+dPsMDwc++wylfa62Xgwxk5HySiAFOGw44TIjpRp0XHll7d7sJnmakQLkOA34IHF0992ynTvXtsVrI8cjLxFRI+coI5WWZnth1WVpHyCXbS9erHsgZbFIu+PLLY/V81S1zcyZtTNm6kTJrdK+Pn1k2wACqT17gLKyELz8cgj+/W+5eB/5vHTn+7rDfUDPnn4YLTU0ISF6eZ+jeUIqi/G3Jo8AISFI3/IlhiXvQEGBrE/kEy1byhpon38OjBhhLSOMinLSiOYyMxkp4zxLp269Va7YGBaq1TQ3AqmCAknZ17GsD6hbRkoFUl7NSAEyf61ZM2njerkREDGQIiJq9BwFUikpejdkQK6SuiztUyf1W7Y4fU8VSKngxxXj87KygLvuqv0cU3Ok+vaVbQAHUi1byvdUVWXBgQMJePdd+Zcdi2L0KJEFhXdfX1+dACgYuOrcp06+K9u0lw5+AN6I/z+EoAqvveblXgPGqzHJycD11wPQg4eMDNf9GoyBlNO5SzCRkbr2WuDBB4Gf/MR6V0WFXq3s8H0efFAObI895uINXDMek40/c5WRatLEN6V9VVXAunW1FwIGIJGtCi7/8x/zXzxIMZAiImrkHJX2paTIuU1srDTzio11o7SvVy/ZushIqZMZuxmpxx+XdrsrV1rvMj7v2Wftd+I1FUgZM1IB0omqZiBlsehZqQ8/7ILTpy3IyAA+/e1KRKACB3AFkge0889gqUFyN5DKzISshRQZiXb7FuGF0N9j0yaXf9buuXABePhhqct7771aD6vjkKv5UYCPSvvsMM4pcxqwhYfrk9HqQH3vly7ZLn/gqmsfULfSvscfBwYOBP72NwdP+OlPZfvf/7qcB9tYMJAiImrkHGWkUlPlsW3b9PJ/l6V9KpDaudPppAqnpX3z5wMLFtisR6UaSwweLNOw7DEVSF15pbRBz8+vPRHBT2oGUoCe4PvhBzkLvO8+YMSDWci97QnsHXKv9byGyB2uWqDbBFLZ2dZAZ1rVi/g13sauXZefuGAB8OKLwOLFMr9p61bJQq9eLYsYGU+yy8rkYsWPPwJPPikp5RdflBLg+fNrpT+MGSlXvN5sQvnhB1mIdt8+AHogZbHoC3/b8PIEsqgofbzq56Fp5uZImc1IFRfrAZTDyr2hQ2UnUvPaCPZW7yAiokZEBVKnT8v5gLG0D7Bdt9ZlaV/r1lJHf+6czFp3MH/HYSCVlycnMRaLRE2XDRokyaPOnR2X+5gKpGJi5ERx+3b5wu6ctflQSQlw6pTcNgZSKiMFABERGn7zGwuQ3AFtP/wj2tbvECkImMpIAcCECRIAzZiBLtit/229/74EU44YmxFMniwTrIxv2rEjMGsWMHJkrZeayUglJkqjvcpKLwdSjz0m39/LLwNTp9rMj7J7/Jk4UdJ1s2YBo0e78QautWwpYz1+XBoJlpToP1ZfdO374AP9V7R9u4MnRUQAkybJYNQChI0cAykiokYuMVGWTikrk/ViVGmfsWxGcVnaZ7FIVmrZMjmxMBtIffONbHv0qDXTvHdv59+HMZDSNDfWwxw9Wq6OuztRy4eOHJFtXJzt+YkxkPrZzzQkJ3u+yCeRqYyU8oc/4I2t/TB9wfX4vQqkcnIkgvnhBzmpLi2VP7jYWPkwdpHcs0fO0END5XW33y6NC+ymdswFUiEhMr3qxAkvzpECJHJZsEAy63DRaELTgBUr5AqUF8r6lIwMYMcO/eehslGhoRqiohx3zVO/uwsX5DhdsymPPZoGzJmjf56bK78yFXjbeOUVd4bfaDCQIiJq5CwWOWk5eFA+1D9sex18VUbKYWkfAAwfLmccaWkOn+IykLq8fpQZKpAqL5eqITVWh/74R9Pv4SvGsj5jANi+PZCUpOHMGQvuv78aWLdBuoMNHergLIfIMVcZKRXQ2wRSFgtO97oeWGDI9t53n3y4Y8kSWbMgJUXWLXDBTGkfIF/WnUBKHWsMFcOOqbWkLgdSTteQ2rNHgqioKKBfP7fG7I6anftU8JuQ4PwiUVycxHMXLshrO3d2/V7Ll0tMrOLgggIJ4q66qk7fQqPAOVJERGT9p63WkwwPt9962GVGCpC1n/73P2DUKIdPcRhIqeJ8DwKpmBj9RMet8r4AYm9+FCBX3BcsqMJjj21A374a8NprMknshRfqfYzU8DnLSGmanpFq1cr2MbfXaLMnOlrKaN0IogBzGSlAKs26dAGuvtr589TxzFQgtWsXUF3tPCO1YoVsBw6U1L6X1FxLSl3gcifppV7rbsOJ2bNlO3Gi3ofHYXkfIHPg1q2TyoNGjoEUERFZT1pU1/KUFPtXPVUgdfGi502bqqr0kwKbqrrDhyUlFhrq8aVQU/OkAPkmDhyQb8iPHAVSANCvn4a+ffNlrOrExQtr1VDj4ywjde6cVOkBtbNBpv+uPFRVBes6Uu5mpB54QOIdV4GXCqTURRyn2reXoKikBDh40HkgpbLoQ4a4N2A3OcpIuRNImWk4kZcnS3gBMp2te3e57TSQ+ugjCRynT3f9BkGOgRQREVn/aav2xvbK+gC9XE7T9JMuhw4d0iMEg/Pn9Y7jNlmvs2elq8SgQe4V9tth+oSvf385aVq92qP38xZngZTV9u3yjTVpIuMmMslZRkqddLdoUbuErb4CqYICCaZCQhwfgzylst8XLrhxESgsTG8VunOn40BKzY8CpNzWi2p2U9UzUq6XazATSG3aJD+P7GwpA3QrkBo5Uua47dghX6ARYyBFRETWf9o//ihbRycxMTH6PHKn5X1/+APQti3w0ku1HlJXhOPiaqwH1aMHsGaNfoXXA6ZP+FRLQlXT6CfuBFIhquxxyBD7C2kRueAsI2W30cRlKnPs60BKZV/S0iSW8SZ10UbTHDfbsGGYJ+UwkNq9W9ptRkfrNXFeUrP7npmMlJnSvh07ZKsCKLXdudO2+aKNpCRpGAIAb77p+k2CGAMpIiKqVRZjr2MfIOV+bjWcUN36Fi+u9ZDTNaQA245fJpkOpK68Urbbtnn8nt7gTiBlUVe+r7vO5+Oh4ORORspeIGWcI+XtdVjLy6Wk+NIl8/OjzIiI0FukuzVP6v77gS++AO65x3EgFREB3Hsv8MtfenV+FAC0aSPbc+ckG2VmjpSZjNTlfhr4yU9k2769fJ+XLgH79zt54b33yvbjj92MTIMTAykiIqp14uKsrMblWlKANIsIDZUU16FDNg/ZDaTOn/dwJrstjwMpP2akKir0E0hHgZSlogKWNWvkEw8acRABzjNSdjv2XaYyUtXV+gl9XS1YAIwYIZmiXr2kMk5lxH21rJupeVJ9+wI33gikpDgOpDp0kFVs33rLm8MEIMdZdRw+cMDYtc91aZ8nGSmVgAsN1W87Le+7+mqpBSwpkTlTjRQDKSIicjsjBbjZuS8+HhgwQG7XyEqpBX9V0ANAFvhs0UJmjteB6e5iKpDav9/FN+Q7x4/LCWpEhOMANuHgQVguXpQz2uzs+h0gBQ2VzXBW2lezYx8g+6YKwrxR3ldUBNx6K7BokT7XcsMGYMYMue2LjBRgsgW6gdP25z7Urp1sDxzQA1h3Vj1wNyNVWqoHryojBbg5T8piAe65R26/8YY+8bWRYSBFRERIT7f93FlGSgVSTkv7AL2z3JIlNnfn5spWla4AkDMqTXPRbcE103M5kpPlm9c0/dJsPVNlfa1aOa5qPJeVhYrdu6WMpg6lj9S4qZNws6V9gHcbTixeLCfxbdrIn92aNRKkqIDF1xkptwOphQuBGTMQdUxq3GwyUjt2SJMahxOJ6s4YSBnXkXJF/fwKCx2vGQbI2lFVVRJgGv8HuBVIAcAdd8gvrqhIv0LWyPBoTEREiIiwXealzqV9AHD99bL9+mugstJ6t6r0a9v28h2XLumdr264wc0R2+fRyV6PHrL10zwptzr2WSwyeYFtz6kOVEaqqKj2XKf6DKT++1/Z3nKLlJENGiTVYWrJhYAo7QNkvbann0byvm8B1AikXnoJuOYa4PHHvTpGI3sZKXe69jVpogdczsr7jGV9xuUu3A6kmjUDvvtOBuisjCGIMZAiIiIAtuU0dS3te/ddYMmZXnKp88IFqdu5TGWkrIHUqlVyKTojQ1bWrAOPTvbGjwcefVTmRPiBW4EUkReojJSm2WaUq6v1E25fB1IVFcCXX8rtMWP0+2++WYKp8eOB0aPr9h6OmC7tuzxZKOmEdGSwBlKVlfo3UceLP87Yy0i502wCcK+8r2ajCUV9fuyYG0Fnt26NOkvu5eaSRETUULVsqSdl3MlIOSrtO3oUuPNOoGnTUJx7/lmENE+0+U9dq7Tvq69kO2KE/VWATfDoZO/22+v0nnWlMnQOG02sXYs+zz4Ly9mzwK9+VW/jouATFSVtxSsrpeRLBVYFBRLghITULvNVzP5tffop8MEHMv3R2Fhm9WoJZJo3lzVdjW69VT58xXRp3+Xj1hWHlgPQEB19+fi0dq1MxExM9HjxcHcYAyl1ASs+HtbmF85kZkqg5E5GqmYg1bSpfGtnz0rFnsMOq0bV1bITebl7YaBrvCEkERHZUBmpiAjndfiuMlKqA11hIXBsxF1Sv3P5ReXl+uPWjNSiRbL1wpVd48leQ5n7rCZ7OwykFi9G+vr1CFm6tP4GRUHJYrHfAl117HO2fpPZQOqll6R7uLpOoqiyvtGjpUNcfTJd2jdmDBAdjczTWzEMy/SMlPombrzR+wteGahA6tgxCXYB97r2AXp5ZI2mqTZqduwzUv8D3OrS+NxzcvWtEa4pxUCKiIgA6IFUSorzxJCrZhPGjnkqSAAAVFfjyBEJcKKjpc8DcnOBvXvljMoL6yOpZhPqirvbjh2TuVxeaMFuxrlzwLp1ctvRhW3LypUAgOohQ+pnUBTU7LVAdzU/CjAfSOXn224B+dtXMYixrK++mM5ItWgB3H03AOAx/EUCKeM3cdNNXh9jzbePjZW3VD93d7r2AXpwZFzZoagIuO8+YPlyCcxOnpRjfdeutV+vAm63AqmQEBmguijWiDCQIiIiALaBlDOumk0YT7T27oXMf3r6aaBTJxzdLS9q0+ZysJaYCMydCzz2mPvF/05ER8uJB2AyJhozBhg2TNqH1aOvvpKuWV276lefbZSUwLJxIwBAGzy4XsdGwcleRspZ63PFTCClaXoTN2Mzt+3bZU5gdDQwfLj7Y/YWj9qfT5+OCks4hmIF2pxYK8eyAwckda8a6viIxVL7uOBO1z5An/L53Xd6dv6996RT+Y03Au+8I/e1a6cf0+29j1tr7Y4YIdtvvnGv7jCIMJAiIiIAcmKTlQXcdpvz57kq7TMGMHv3AggPl1nk+/Yh5oM3ABjK+uLjZULV00/XaexGplugA7KwJgDs2+e1cbjjf/+TrcML2xs3wlJRgUuJiYYfGpHn1AmyMZhQ82icdcszE0gVFemtzI2B1BdfyDYnB4iJcWu4XmW6tA8AMjPxdcs7sBdZiEGJ1CcDwB//qB8MfahmIOVuRqp7dzn0njqlN7S5nNxGaan01wHsl/UBJkv7unaVnae0VH+TRoKBFBERAZCr0Xv3Ag8+6Px5pkv7QkOt/7WzFz6Pn+FTZKecqrW+lLd41HDCD4FUebk+f8RhmdPlDNnZzp3r3IiDCNAzzsaSuxMnZOtsIVwzf1fG4Ml4W5X69u/v+mv4gunSvsteaz0LXbAb53sPA/70J6mNe+QR7w/QDmMgFRsrwZE7IiP19cY3bJCs1KpV8nlysv68mo0mFFOBlMWiz3FtZOV9DKSIiMgU06V9APDLXwKdOyP20ml8inH48wcZUl/y+edeH59HgVRWlmxtJnX51sqVMk8lJQXo08fBky4HUmc6d663cVFwS0uTbV6efp+6rR6zxxuBlDsBmy95VNoH4ExFU1QjVOZIWSzA0KFeH5sjxkDKbPWzsbxvzx7JTkVHA99+qwfUjlZ9MBVIAXp5X83uIkGOgRQREZliprTv8OHLJfPh4cCaNXi75QycRTOEVZVLDZ7diUF101AyUqqsb/RoJ8uwVFdDCwvD2Tqur0WkqGDJmJFyJ5BSJbPnztmsr21XoAZSKiNVVCSdut2lpv3YLMhbT4yHSHfnRynGQEplowYMkLW9168HPv5Yj39qMh1IDRsmHQx//LHe55r6E9eRIiIiU1ytI2UMpDRN5mVnZwNITMQTlTMxFQ9hx5+/wBW3D3LeJsxDdQqkjh8HSkrcmsCxbp1enRgWBkyY4H5c6Hbjr8WLUXnhAi58/bV7X5jIBU8zUsa1hM6dk45yjhiDp4ICWWIoJERf+sDRWlW+ZgxEzp93/j0YBUogZTYjpTLdmzfrP/NrrpFtmzaGtfzsMNW1D5DJW/ffL/8gevQwN9AGjIEUERGZYiYjBUh5X3a2nIzICVYTJNw7AXBnkUcPeBRIJSXJ5epz54D9+x1PHLhM04CxY/W1XQBZo/PLL917u+3bpVNadLQbXd9jYup/wR0KWqmpslXB08WLeit0Z4FUWJj+J3L6tPMgxPh3UVUlzR2iovT38VcgFRYm5/uFha6DQSN/BlKtWumLKJvNSHXsKMfroiJg/ny5TwVSrpjOSAHAq6+aeHJwYGkfERGZ4iqQUgGMqkZT86TUwpBxcXqJjS+oQMr0klBPPy2t2J2dTV527px+sjh2rGwPHHD/rdTaUYMHO0l+mak9InJTzYyU2sbEuG5C5+5FCmNGSn2u3qdJE/c7z/mCJw0n/BlIhYXpi3WbDaRCQvSsVEWFVFj36+fea021P7enutpx2UIQYSBFRESmGEv71PokiqbpAcygQbKtGUi1bevbBnQetT8HgMmTpRW7G5epVTvh5GTgmWfktrFUypU9e2Sbne3gCZomDTB695YMGZGXqEDq7FmgrMy2rM/V32VdAil/l/UpnrRA92cgBQBXXCFbT5baMzaT6NvX/bbzHmWklB07ZDLWxIm1/0kEGQZSRERkirpqXVWlrxWjXLyoL7MycKBsVSO83FzZ+no5JI9K+0xSQWHr1vqJaWGhTK9yxw8/yLZTJwdPOHJE3mT7drcyZETuSkyUtWQBaTjhzvwopS6BlL8bTShmM1Kaph/noqJ8MyZXOnaUrbuliEbGQMrdsj6gjoFUZSWwdSvw2WfAyy978AUaDgZSRERkSmysfrtmeZ/KRkVG6vON9+6VkxEVSDmb4OwNHgdSxcXAihV6Oz0nVEaqTRspU1JXed3NSqmMlMNA6ttvZdujh+0PnKiOLBZ9npSvAykVNOXnB05GymwL9PJyPanir4zU734nH3fdZf61fgmkevYEXnlFbj/yiN4yMAgxkCIiIlNCQ/XAoWYgpU6wkpL0RnhqcrqxtM+XjHOkqqtNvHDPHlkf5u67XT5VBVKtW8uJqToJVVfdnSkulkYTgJNAauVK2V51lesvSGSScZ6ULwMp1bPFmJHydyBltrRPlfUB/i3tmzXLsyanLVtKQ5usLODqq91/nQqkSktrVx645b77gNtuk9KFceP0i0NBhoEUERGZpq5o1wwcVEYqKUmCrVat5PO9e4GDB+W2rwMpNUeqqsrkRGkV+Z08qbcXc8BY2gfYbyntiJoz1qKFPtZaVLvza691/QWJTPJlIFVSovcY6N5dtg25tE8FUiEh0qyhIVq2TI47ZpLbcXH6nDmPGk5YLMCbb0o0ffKkXBSaOFHqv4OIXwOpVatWYfTo0UhPT4fFYsGCBQscPveee+6BxWLBKypVeFlZWRmmTJmC5s2bIzY2FjfddBOOHTvm24ETETVyKoBQmRlFBVLqhEvV9o8ZA2zZIrd9HUhFRurzuEyV98XH65MQXDR4MJb2AeYCKTU/qnNnJ1/8wAFJ/ZmpxSFykzcCqeXLgfHj9f1ZUdmoqChZ+FXd11BL+4yNJnzZJCfQhITo3RU9Ku8D5Gra8uVSk2ixyHHN3W4XDYRfA6mLFy+ie/fumDNnjtPnLViwABs2bEC6nb++qVOnYv78+Zg3bx7WrFmD4uJijBo1ClVVVb4aNhFRo6cyTUeO2N5vLO0D9NI1tY7MffcBXbv6fnzq/U23QFdZqX37nD7NWNoH6CeH7gRSLudHqWxU377+7RNNQcu4lpQngdTq1cDw4cC//gU8+6ztc1QglZIiH+q+QMtImS3t81dZnz/VuQU6IAfjv/8dWL9eMlRBFo36dUHeESNGYMSIEU6fc/z4cUyePBmLFy/GjTfeaPPYhQsXMHfuXHz44YcYNmwYAOAf//gHMjMzsWzZMlx//fU+GzsRUWPmKiOlAplp06SSo08f4NZbPWvf64nmzaX8znTDiQ4dZGVdJ4FUUZF+EuZJaZ8KpBxmpNq2BSZMkNbnRD5Q14yUcW7kokUyFzHk8qV5R4GU+lv0d0bK09K+xhpIHT5ch4yUkbHrBSDH2QEDGnxg5ddAypXq6mrcfvvtePjhh9HVziXMzZs3o6KiAjk5Odb70tPTkZ2djbVr1zoMpMrKylBWVmb9vPByLXxFRQUq/LwAonp/f4+D/Iv7AQGBvR9kZFgAhOHQoWpUVOgVAKdOhQAIRbNmVaioqEbLlsAbb+ivq69vJSkpFEAITp6sREWF++uYhFxxBUIBVO/ZgyoHg5Wqv3A0a6YhOroSFRVAixby8zh+3PbnYc/u3WEALGjf3sHYrrpKbzJh+L8UiPsB1R9v7gdqfz18WMOZM3Ii27x5hcu/z5YtgZCQMISGAs8/X40nnwxBQYEF331XiV69ZF/Oy5Ov3aJFNRITqwCEW8v63H0fX4qLk/GdPauhoqLS5fOLi+X5kZHuPd/X6vN4EB8vx9HTp80dR10JefxxhL7wAirfeQfabbd57et6k7s/34AOpJ577jmEhYXhgQcesPt4fn4+IiIi0ExdXrgsJSUF+fn5Dr/uM888g6eeeqrW/UuWLEFMgNRuLl261N9DoADA/YCAwNwP8vJaABiI3bsvYuHC5db7d+7sBSADBQW7sXDhQb+Nr7S0J4BMrFmzB82bH3D7denFxegD4PzGjVi9cKHd52zcmAKgPxISLmDhQumud/So/Dz27SvGwoXfAADS1q1DWUICzhpST1VVFuzbNwqABXl5y7Fw4aXab+BAIO4HVP+8sR8cOBAPYAh++EEDYEFYWDU2bFjoVnLgj39MRNOmFcjMLELXrn2wfn06XnttH8aPlwXjVq/OAtAZ5eVHsGXLTgCjra9t2rQMX3+9qM7jr4v9++V7z8srxcKFS1w+f9s2+duurCzEwoUrfD08t9XH8aC0tC+ANKxZ8z1iYw+7fL67Oh49ik4Aiv/0J6xs1iwgs1Ilbi4KGLCB1ObNm/Hqq69iy5YtsJj8AWua5vQ1jz76KKZNm2b9vLCwEJmZmcjJyUFTP9ejV1RUYOnSpRg+fDjCG2p7GKoz7gcEBPZ+0KEDMGMGcPZsE4wYMdL6f3DOnFAAwKBBnTFypKNJQL63fHkIVq4EmjfvjJEjO7r/wu7dUdWmDZp264aR/fvbfcrhw1LD1K1bU4wcORKAzBmbORMoLo7DyJEjYfnwQ4Q99xy0qChUbtlinXX/449AZWUIYmI03HHHUGs5lNX27dIarHNn68lFIO8HVH+8uR+cOAE89BBQVSU7YFqaBTfeONKt1440PO3kSQvWrwcOHOiIkSNlH1+yRL5mz56ZGDu2JeLjNVy4IPty69YR1r8Zfzl4UL73S5ei3BpLVZWMPTk5zu9jB+r3ePDvf4fiu++AzMxuGDnSi5Nb+/WDNn8+Eg4exI2pqdB69fLe1/aSQhedW5WADaRWr16NgoICtFIzmgFUVVVh+vTpeOWVV3Do0CGkpqaivLwc586ds8lKFRQUYODAgQ6/dmRkJCIjI2vdHx4eHjD/pAJpLOQ/3A8ICMz94IorZFtSYkFhYbh17oSaO5SSEubXVsHJybI9dy4U4eGh7r+wTRvg/vudPkU1hm3bNgTh4XLSqOZKnT1rgbZ7P8KnTAEAWEpLET55svQftlhw4HJyrGNHCyIj7fyA/vhHWRB41ixZgdMgEPcDqn/e2A9atpQ4XS00m5Zm8ehrjhol240bQ3D+fAhatABOnZL70tPlby8lRW9WkJHh2ft4kzo2XLpkQVVVOKKibB+vqABuuUXmdK1cqZcjx8Tof++BoD6OB6rDYVGRyeOoK6mpwM9+Bnz0EcLeeQdwcNHKn9z92QbOHlHD7bffjh07dmDbtm3Wj/T0dDz88MNYvHgxAKBXr14IDw+3SW/m5eXh+++/dxpIERFR3URF6RPJjQ0narY/9xd3Fw71hFpDSrU+B2QCe2QkEI0SYPw4oKQEpT36o7ppvKyCebmTrGoVbbdjX2UlsGKF3OZCvORDYWF6QAG412jCnvR04MorJSC7fGpm02zCuFXP97f4eL2SzF7DiRkzgM8/B9atkwxyY282AdSxa58jauHzjz92uW5fIPNrRqq4uBj7DWt15ObmYtu2bUhMTESrVq2QVGOlwvDwcKSmpqLj5YVJ4uPj8etf/xrTp09HUlISEhMT8dBDD6Fbt27WLn5EROQbrVvLSdORI4CqzKjZ/txfPG5/Dki0s3atRDuDBtV6uGbrc0BOzFJTgcmHn0TE3u9R1SIFXffOR4tW0Vg/U29V6LT1+aZNckKRkAD07OnBwIncl5qqBz2eBlKAlPpt2wYsXAjcdlvtQEq1Wgf83/ockO6CCQkSRJ07Z/u9r1hh28795EkGUoCXuvbVdPXVciDcswf45z+Be+7xwZv4nl8zUps2bUKPHj3Qo0cPAMC0adPQo0cPPPnkk25/jZdffhljx47FuHHjMGjQIMTExODzzz9HaKgXU5BERFRLzRboZWX6ovX+DqTqlJF6/33gN7+Rf+52qIyUMZAC5ISsBU6hPDYBG8bNwsGSVGzYE28tdQJcLMa76PIk/OHDZTFeIh8yBhB1DaQAyUhVVgZ+Rgqw3wL97FkJBDVDczoGUrL1SSBlsehZKQfH2obArxmpIUOGQNPcb6d4SP33MoiKisLs2bMxe/ZsL46MiIhcqRlIqexPaGj9rRflSJ0CKZUuUlGPwaVLQEGB3DaW9gFykjgJ76P4WQ17ftD/t/2wtRQtCr+AtuE7/PDD8zZvYUMFUjfc4MGgiczxViDVrx+sc6Oee04/6Q7kQCoxUZpO7NkjSefqauBXvwKOH5dGOh07Al98wUDKp4EUANxxh0S148b56A18L2DnSBERUWBTvYBqBlKJiajdja6eGZtfVDlf1qk2lS6yE0gdOSLbJk30q9qKOhk9kWfB6m/1H8CPO8uAW2+F5cUXkFy4D+HhcqJm48wZ4Lvv5DYXk6d64K1AKixMAihA5hcB0nhS/X0YA6lAKO0DJOkLSD+XXbuAF16QHi8REcC8eXoznZMngdJSuV2zKUVj4PNAKikJmDQJCJClhzzBQIqIiDyiMlIquAiU+VHGMVRXe3ASoNJFeXm1ZlkbG03UXGUjLVWyUHv3Ajt36vdvy40HBg8GAIzCF8jOlhM2G0uXSk1Rt26Bc7ZJQc1bgRQg58LDhukXLZKT9b+PQMxIzZwpf5JFRUBODvDYY3L/nDkyPVGNubFnpFRlgc8CKaOqKt90B/IxBlJEROQRR6V9/u7YB8gVcXUSYPp/c3y8fsZXIytlr9GEcuP6P2Af2iPj87+hulq/f9cuWPtEj8bnuPJKO+85Zgzw1VfAn/5kcrBEnvFmIGWxAH//u55YMHYEVEFJaKjt/f4UEQH85z+SeTpxQi64TJwoUyMBBlKKzzNSyrffAl26SH1lA8NAioiIPKJK+06fliYTKpAKhIwUUMd5Ug7K+xw1mgCAtNM70B4HUFleZfMldu8GMHo0AOBqrEbfrPO1XxwdLXOjbrrJg8ESmaeCJ4vFOwFO27Z6x7vsbP3+Ll3kvYYN83/Jr1FSkrQ5b9lSVht4/fXaWTQGUrItKdHX0/KJ5GRg/36ZmLZ1qw/fyPsCaJcmIqKGJCEBiIuT20ePBlZpH1DHFugOAim1oG67drVfknDsewDA95CzSHV1u6AAOB3fDvvDOiEclRhcutiDARF5V6dOkkHq2VPmOXnDlCmy/tJrr+n3xcXJBYivvvLOe3hTly5Abi6wapXtNB0GUqJpU/22T9aSUjp0ACZMkKg2L8+Hb+R9DKSIiMgjFotteV9QZaTuvlvmLT30kM3d+/bJtn37Gs8vLkbk8VwAwC50BSA9I1RnvzVrgM8qJSvV7ocvbF/73nvAI4/IYjxE9UR1rlu50rtft39/PZOhRETUnlMYKMLDa49NBVIFBZKNARpnIBUWpl8s83l536uvypUq1U+/gWAgRUREHjN27gukOVJAHQOpbt2kFslQ86RpUn0CyAVUG7t3AwDykYLTaIFmzSSp1aWLPPzxx8DnkEAqIv+I/rqKCml59sILsggwUT1KSQFiY/09isCj/uzLy4H8fLndGAMpoB7nSTVvDkRG+vhNvI+BFBEReUxlpJYt0+OAoMhI2VFQIF2+LBaZD2Jj1y4AwL5IKesbOFDmg3SV5BQ+/xxYhwG47/oaKYBXX5XFbFq0AH7xC+8MlIjqJCpKb1aj5kU2xvbnQD0GUg0UAykiIvKYCqQ+/VSyNdHRskBnIKhzIPXvf0tf5Fwp2VPZqFat7JxUfS/zo44lSCB11VVyt8pIlZYCVQhD+iBDBHbiBPDUU3L7uedq10MRkd8Yy/uAxpuRqtcW6A0QAykiIvKYscRt3DjpzWDs2OVPdQ6kZs0CnnlGZs9DD6RqzY8CZJJ0795odl0vtGkjPwtAD6QUa+vz48flNcXFMqlk4kQPB0lEvmBc/wpovIEUM1LOealPCxERNUajRkl1Ws+eehYmUNQ5kOrdW4KoDRuAX/zC2mii1vwoAJg2DZg2DTcAyDXcrZr/KT16QCZbXV5XCgDw178GVl9oImIgdZkKpHzata8B45GbiIg8FhEBPPBA4AVRQB3bnwPAgAGydScj5UBcnN6QIylJklCwWIC33gIyM4Enn5QolIgCCgMpwYyUc8xIERFRUKpzRkoFUlu3ApcuYd8+OZOqlZG6dAkIDZWo0o4uXYAjR6Ssz9pmuXdvuZOIAhIDKcFAyjlmpIiIKCipQOrcOaCy0oMv0Lq1nE1VVkLbtNlxRmrOHOkhPWWK3S/Tt69sBw70YAxE5BcMpAQDKecYSBERUVBKTJStpkkwZZrFYs1KXVy2DoWFctcVV9R43tdfS6TmoObvkUeA998Hfv97D8ZARH7BQEqoQMrjEukgx0CKiIiCUlgY0KyZ3K5reV/Jd9LePDOzRuvzsjJg1Sq5PWyY3S8RGwvccQcQE+PhGIio3tUMpBrrOlLq+tDlFR6oBgZSREQUtOo8T2rSJODgQXw1/j0AdpJO69bJHKnU1Nq9zomowUpOtv28sWakevaUTPzRo0B+vr9HE3gYSBERUdCqSyB18SKw61Qy0LYt9h+QLhG1Gk0sWybbYcMMnSSIqKEzZqRCQ4HwcP+NxZ/i4vRrRBs3+ncsgYiBFBERBa26tEC//35ZXPjVV520PjcGUkQUNGJj5QNovNkopU8f2TKQqo2BFBERBa26ZKS2bpXtl9O+xm2f3Yw/4GnbjNT58/qZxXXX1WWYRBSAVFaqsQdSqvPod9/5dxyBiIEUEREFLWeB1KlTwKxZsrVHzQdIqi7AjeXzMRYL0L6dpj/BYpF01X33ARkZ3h04EfkdAymhAqmNG6ULqiMffgg8/3z9jClQMJAiIqKg5SyQeuklYPp0iYVqqqjQA6zjV1yDSoSiJ7ai4+sP6mcS8fHA5MnA66/7ZvBE5FcMpES3brLe+NmzwMGD9p9TWQncdRfwf/8H5ObW7/j8iYEUEREFLWeB1I4dsj12rPZjJ0/KNiwM+ODrlvhD8pvy+d9mA3ffLRGYmjhFREGJgZSIiAB69JDbjuZJHTsmq0EAjevQyECKiIiClrNAau9ex4/l5ck2JQVo0wb4c96vgbffljvffltqAv/5T6+Pl4gChwqkGusaUkaq4YSjeVLGTFVjykiF+XsAREREvuIokCot1f/Z2wuk1PyotDTZhoQA+PWvpQ/yk0/KQr2DBvlkzEQUGJiR0hnnSdljDKQclf8FIwZSREQUtBy1P9+3T5/qZK81uspIpabWeGDSJPkgoqA3ZAiQkAAMH+7vkfifykht3izzocJqRBDGLBQzUkREREFAZaTOn5cGEmpRzT179Oc4K+1TGSkiany6dJELLSGcCIOsLKBpU6CwENi9G/jJT2wfb6ylfdw1iIgoaDVrJl3KAek4pRgDKRVkGdUs7SOixolBlAgJAXr3ltv2yvsYSBEREQWZ0FAgMVFuGzNPxkAKsA2yACelfUREjVTPnrJVi5UbGQOp06eB4uL6GZO/MZAiIqKgZq/hhOrYp9Qs72NpHxGRLRVIbdlie39RkX4MVY05GktWioEUEREFtZqBlKbpGamICNnWbDjB0j4iIltqLant24GqKv1+FTQlJcm8MuN9wY6BFBERBbWagdTx48DFi9J1qnt328cACbQYSBER2erQAYiNBUpKgB9/1O9XZX1XXAG0bSu3GUgREREFgZot0FU2ql07PVAyBlJnzwLl5XJbrSNDRNTYhYYCV14pt43lfQykiIiIglTNjJQKpDp1sj9/SmWjEhOByMj6GSMRUUNgb56UCpratm18gRTXkSIioqDmLJCqrrZ9DGCjCSIiR9Q8KWPnPmNGKjNTbjOQIiIiCgI1AynVsa9jR+DUKbltbDbB1udERPYZM1KaJuv0GQOpjAy5nZurPx7MWNpHRERBzdPSPmakiIhsdeki3U4vXJBgqbpazz5dcQXQurXcLi6u3Q01GDGQIiKioGYMloqKgGPH5POOHe0HUiztIyKyLzwc6NZNbm/ZIsfLsjJpRJGZCURFAenp8nhjKO9jIEVEREHNGCzNmye327SRZhIMpIiIzFHlfVu36sFS69aypATQuBpOMJAiIqKgptqfFxUBzzwjtx94wPYxe6V9nCNFRFSbCqRWrABWr5bbV1yhP64CKTV3Kpix2QQREQW1hAQgJESv5U9MBO66Sx5TGanCQqCiQspWmJEiInKsVy/Zrl0rH4AePBlvMyNFRETUwIWE6JknQLJRTZrIbRVkAfrEaAZSRESO9e4N/N//SUAVHS2d+a6/Xn+8UyfZfvQRsHixf8ZYXxhIERFR0FOZp9hYYMoU/f7QUMlQAVLeV1Ii2SmApX1ERPZYLMCzzwKbNkl3vsJC4JZb9MdvvhkYNgy4eBEYNQp4/33/jdXXGEgREVHQS0mR7T336IGTYmw4oeZHRUcDTZvW3/iIiBqikBA9w69ERQFffgn88pdAZSUwaRLw3Xd+GZ7PcY4UEREFvSeeANq3Bx5/vPZjxoYT4eFyOy0t+BeSJCLylYgI4IMPgPPnJaj66iugb19/j8r7GEgREVHQu+46+bBHZaTOnJGGEwDnRxER1VVICDBypARSqilFsGEgRUREjZqxtG/zZrndu7f/xkNEFCwGDZLt+vVAVZXMSw0mnCNFRESNmgqkTp3SO0wZO1AREZFnsrNlDlVhIbB7t79H430MpIiIqFFTgdS33wJHjgCRkcDgwf4dExFRMAgNBfr3l9vBWN7HQIqIiBo11Wxi0ybZXn01EBPjv/EQEQWTgQNl++23/h2HLzCQIiKiRk1lpBSW9REReY8KpJiRIiIiCjIMpIiIfKdfP1lO4sAB4ORJf4/Gu/waSK1atQqjR49Geno6LBYLFixYYPP4zJkz0alTJ8TGxqJZs2YYNmwYNmzYYPOcsrIyTJkyBc2bN0dsbCxuuukmHDt2rB6/CyIiasiMgVR6ukyOJiIi70hIALp2ldvr1vl1KF7n10Dq4sWL6N69O+bMmWP38aysLMyZMwc7d+7EmjVr0KZNG+Tk5ODUqVPW50ydOhXz58/HvHnzsGbNGhQXF2PUqFGoqqqqr2+DiIgaMDVHCgBycrgQLxGRt6k26MFW3ufXdaRGjBiBESNGOHz8F7/4hc3ns2bNwty5c7Fjxw5cd911uHDhAubOnYsPP/wQw4YNAwD84x//QGZmJpYtW4brHdRnlJWVoayszPp5YWEhAKCiogIVajVGP1Hv7+9xkH9xPyCA+0F9iY0FQkLCUF1twXXXVaKiQvP3kGxwPyCA+wGJhrof9O1rwZtvhuHbb6tRUWE/2bF0qQV9+2qIj6/nwdnh7s+3wSzIW15ejr///e+Ij49H9+7dAQCbN29GRUUFcnJyrM9LT09HdnY21q5d6zCQeuaZZ/DUU0/Vun/JkiWICZBWTUuXLvX3ECgAcD8ggPtBffjJTwbg+PEmsFi+wcKFlf4ejl3cDwjgfkCioe0HJSVNAFyHLVuqsXDhQpvHqqqAefM64dNPO6Jfvzz8/vff+b0yoKSkxK3nBXwg9cUXX2DChAkoKSlBWloali5diuaXC9rz8/MRERGBZs2a2bwmJSUF+fn5Dr/mo48+imnTplk/LywsRGZmJnJyctC0aVPffCNuqqiowNKlSzF8+HCEh4f7dSzkP9wPCOB+UJ9GjAAqK4Hw8BzXT65n3A8I4H5AoqHuB8XFwJQpQGlpGK6+eiTi4uT+ggLgjjtCsXy5zDbq1SsZOTkj4e9vTVWruRLwgdTQoUOxbds2nD59Gm+99RbGjRuHDRs2IDk52eFrNE2DxUkoGxkZicjIyFr3h4eHB8xOGUhjIf/hfkAA94P6EhHh7xE4x/2AAO4HJBraftCsGdC0KVBYCBQUhCMxUe7/6U+BjRulxPrtt4EJE0IBhPp1rADc/tkGfPvz2NhYtG/fHv3798fcuXMRFhaGuXPnAgBSU1NRXl6Oc+fO2bymoKAAKSkp/hguERERERHV0LKlbI8fl21xsQRRgHTzmzDBP+Oqi4APpGrSNM3aKKJXr14IDw+3qRPNy8vD999/j4Fq9S8iIiIiIvKr9HTZnjgh26NHZZuQAHTr5pch1ZlfS/uKi4uxf/9+6+e5ubnYtm0bEhMTkZSUhD//+c+46aabkJaWhjNnzuD111/HsWPH8POf/xwAEB8fj1//+teYPn06kpKSkJiYiIceegjdunWzdvEjIiIiIiL/qpmROnJEtpmZ/hmPN/g1kNq0aROGDh1q/Vw1gJg4cSLeeOMN7NmzB++//z5Onz6NpKQk9OnTB6tXr0ZXtaoXgJdffhlhYWEYN24cLl26hOuuuw7vvfceQkP9X19JRERERESOA6lWrfwzHm/wayA1ZMgQaJrj9To+++wzl18jKioKs2fPxuzZs705NCIiIiIi8hJV2qcCKVXa15ADqQY3R4qIiIiIiBoWlZFSc6SCISPFQIqIiIiIiHwqGOdIMZAiIiIiIiKfUqV9eXlAVRUzUkRERERERC6lpgIhIRJEnTzJOVJEREREREQuhYUBKSlye9s2oLxcAiuVqWqIGEgREREREZHPqXlS69bJNj0dCA/333jqioEUERERERH5nMo+rV8v24bcaAJgIEVERERERPVAZaQ2bJBtQ54fBTCQIiIiIiKieqACqaIi2TKQIiIiIiIicqFmYwkGUkRERERERC6ojJTCQIqIiIiIiMiFmoEUm00QERERERG5wNI+IiIiIiIikxISgOhouR0TAyQm+nU4dcZAioiIiIiIfM5i0cv7WrWSzxsyBlJERERERFQvVHlfQ58fBTCQIiIiIiKiemLMSDV0DKSIiIiIiKhe9Owp2969/TsObwjz9wCIiIiIiKhx+N3vgBtuALp08fdI6o6BFBERERER1YvQUCA729+j8A6W9hEREREREZnEQIqIiIiIiMgkBlJEREREREQmMZAiIiIiIiIyiYEUERERERGRSQykiIiIiIiITGIgRUREREREZBIDKSIiIiIiIpMYSBEREREREZnEQIqIiIiIiMgkBlJEREREREQmMZAiIiIiIiIyiYEUERERERGRSQykiIiIiIiITArz9wACgaZpAIDCwkI/jwSoqKhASUkJCgsLER4e7u/hkJ9wPyCA+wEJ7gcEcD8gwf2gfqiYQMUIjjCQAlBUVAQAyMzM9PNIiIiIiIgoEBQVFSE+Pt7h4xbNVajVCFRXV+PEiROIi4uDxWLx61gKCwuRmZmJo0ePomnTpn4dC/kP9wMCuB+Q4H5AAPcDEtwP6oemaSgqKkJ6ejpCQhzPhGJGCkBISAgyMjL8PQwbTZs25R8IcT8gANwPSHA/IID7AQnuB77nLBOlsNkEERERERGRSQykiIiIiIiITGIgFWAiIyMxY8YMREZG+nso5EfcDwjgfkCC+wEB3A9IcD8ILGw2QUREREREZBIzUkRERERERCYxkCIiIiIiIjKJgRQREREREZFJDKSIiIiIiIhMYiAVYF5//XW0bdsWUVFR6NWrF1avXu3vIZGPzJw5ExaLxeYjNTXV+rimaZg5cybS09MRHR2NIUOGYNeuXX4cMXnDqlWrMHr0aKSnp8NisWDBggU2j7vzey8rK8OUKVPQvHlzxMbG4qabbsKxY8fq8bugunK1H0yaNKnW8aF///42z+F+0PA988wz6NOnD+Li4pCcnIyxY8di7969Ns/hMSH4ubMf8JgQmBhIBZBPPvkEU6dOxeOPP46tW7fi6quvxogRI3DkyBF/D418pGvXrsjLy7N+7Ny50/rY888/j1mzZmHOnDnYuHEjUlNTMXz4cBQVFflxxFRXFy9eRPfu3TFnzhy7j7vze586dSrmz5+PefPmYc2aNSguLsaoUaNQVVVVX98G1ZGr/QAAbrjhBpvjw8KFC20e537Q8K1cuRK//e1vsX79eixduhSVlZXIycnBxYsXrc/hMSH4ubMfADwmBCSNAkbfvn21e++91+a+Tp06ab///e/9NCLypRkzZmjdu3e3+1h1dbWWmpqqPfvss9b7SktLtfj4eO2NN96opxGSrwHQ5s+fb/3cnd/7+fPntfDwcG3evHnW5xw/flwLCQnRFi1aVG9jJ++puR9omqZNnDhRGzNmjMPXcD8ITgUFBRoAbeXKlZqm8ZjQWNXcDzSNx4RAxYxUgCgvL8fmzZuRk5Njc39OTg7Wrl3rp1GRr+3btw/p6elo27YtJkyYgIMHDwIAcnNzkZ+fb7M/REZGYvDgwdwfgpg7v/fNmzejoqLC5jnp6enIzs7mvhFkVqxYgeTkZGRlZeGuu+5CQUGB9THuB8HpwoULAIDExEQAPCY0VjX3A4XHhMDDQCpAnD59GlVVVUhJSbG5PyUlBfn5+X4aFflSv3798MEHH2Dx4sV46623kJ+fj4EDB+LMmTPW3zn3h8bFnd97fn4+IiIi0KxZM4fPoYZvxIgR+Oijj7B8+XK89NJL2LhxI6699lqUlZUB4H4QjDRNw7Rp03DVVVchOzsbAI8JjZG9/QDgMSFQhfl7AGTLYrHYfK5pWq37KDiMGDHCertbt24YMGAA2rVrh/fff986gZT7Q+Pkye+d+0ZwGT9+vPV2dnY2evfujdatW+PLL7/EzTff7PB13A8arsmTJ2PHjh1Ys2ZNrcd4TGg8HO0HPCYEJmakAkTz5s0RGhpa66pBQUFBrStRFJxiY2PRrVs37Nu3z9q9j/tD4+LO7z01NRXl5eU4d+6cw+dQ8ElLS0Pr1q2xb98+ANwPgs2UKVPwv//9D9988w0yMjKs9/OY0Lg42g/s4TEhMDCQChARERHo1asXli5danP/0qVLMXDgQD+NiupTWVkZfvjhB6SlpaFt27ZITU212R/Ky8uxcuVK7g9BzJ3fe69evRAeHm7znLy8PHz//ffcN4LYmTNncPToUaSlpQHgfhAsNE3D5MmT8dlnn2H58uVo27atzeM8JjQOrvYDe3hMCBD+6XFB9sybN08LDw/X5s6dq+3evVubOnWqFhsbqx06dMjfQyMfmD59urZixQrt4MGD2vr167VRo0ZpcXFx1t/3s88+q8XHx2ufffaZtnPnTu3WW2/V0tLStMLCQj+PnOqiqKhI27p1q7Z161YNgDZr1ixt69at2uHDhzVNc+/3fu+992oZGRnasmXLtC1btmjXXnut1r17d62ystJf3xaZ5Gw/KCoq0qZPn66tXbtWy83N1b755httwIABWsuWLbkfBJn77rtPi4+P11asWKHl5eVZP0pKSqzP4TEh+LnaD3hMCFwMpALMX//6V61169ZaRESE1rNnT5vWlxRcxo8fr6WlpWnh4eFaenq6dvPNN2u7du2yPl5dXa3NmDFDS01N1SIjI7VrrrlG27lzpx9HTN7wzTffaABqfUycOFHTNPd+75cuXdImT56sJSYmatHR0dqoUaO0I0eO+OG7IU852w9KSkq0nJwcrUWLFlp4eLjWqlUrbeLEibV+x9wPGj57+wAA7d1337U+h8eE4OdqP+AxIXBZNE3T6i//RURERERE1PBxjhQREREREZFJDKSIiIiIiIhMYiBFRERERERkEgMpIiIiIiIikxhIERERERERmcRAioiIiIiIyCQGUkRERERERCYxkCIiIiIiIjKJgRQREQWkmTNn4sorr/T3MIiIiOxiIEVERPXOYrE4/Zg0aRIeeughfP31134Z33/+8x/069cP8fHxiIuLQ9euXTF9+nTr4wzyiIgozN8DICKixicvL896+5NPPsGTTz6JvXv3Wu+Ljo5GkyZN0KRJk3of27JlyzBhwgT85S9/wU033QSLxYLdu3f7LagjIqLAxIwUERHVu9TUVOtHfHw8LBZLrftqZn0mTZqEsWPH4i9/+QtSUlKQkJCAp556CpWVlXj44YeRmJiIjIwMvPPOOzbvdfz4cYwfPx7NmjVDUlISxowZg0OHDjkc2xdffIGrrroKDz/8MDp27IisrCyMHTsWs2fPBgC89957eOqpp7B9+3ZrBu29994DAFy4cAF33303kpOT0bRpU1x77bXYvn279Wur7+nNN99EZmYmYmJi8POf/xznz5+3PmfFihXo27cvYmNjkZCQgEGDBuHw4cN1/pkTEZF3MZAiIqIGY/ny5Thx4gRWrVqFWbNmYebMmRg1ahSaNWuGDRs24N5778W9996Lo0ePAgBKSkowdOhQNGnSBKtWrcKaNWvQpEkT3HDDDSgvL7f7Hqmpqdi1axe+//57u4+PHz8e06dPR9euXZGXl4e8vDyMHz8emqbhxhtvRH5+PhYuXIjNmzejZ8+euO6663D27Fnr6/fv349//etf+Pzzz7Fo0SJs27YNv/3tbwEAlZWVGDt2LAYPHowdO3Zg3bp1uPvuu2GxWLz8kyQiorpiIEVERA1GYmIiXnvtNXTs2BF33nknOnbsiJKSEjz22GPo0KEDHn30UURERODbb78FAMybNw8hISF4++230a1bN3Tu3Bnvvvsujhw5ghUrVth9jylTpqBPnz7o1q0b2rRpgwkTJuCdd95BWVkZAL3sMCwszJpBi46OxjfffIOdO3fi008/Re/evdGhQwe8+OKLSEhIwL///W/r1y8tLcX777+PK6+8Etdccw1mz56NefPmIT8/H4WFhbhw4QJGjRqFdu3aoXPnzpg4cSJatWrl858tERGZw0CKiIgajK5duyIkRP/XlZKSgm7dulk/Dw0NRVJSEgoKCgAAmzdvxv79+xEXF2edc5WYmIjS0lIcOHDA7nvExsbiyy+/xP79+/HEE0+gSZMmmD59Ovr27YuSkhKHY9u8eTOKi4uRlJRkfa8mTZogNzfX5r1atWqFjIwM6+cDBgxAdXU19u7di8TEREyaNAnXX389Ro8ejVdffdVmPhkREQUONpsgIqIGIzw83OZzi8Vi977q6moAQHV1NXr16oWPPvqo1tdq0aKF0/dq164d2rVrh9/85jd4/PHHkZWVhU8++QS/+tWv7D6/uroaaWlpdjNdCQkJDt9Hle2p7bvvvosHHngAixYtwieffIInnngCS5cuRf/+/Z2Ol4iI6hcDKSIiClo9e/bEJ598Ym3+4Kk2bdogJiYGFy9eBABERESgqqqq1nvl5+cjLCwMbdq0cfi1jhw5ghMnTiA9PR0AsG7dOoSEhCArK8v6nB49eqBHjx549NFHMWDAAHz88ccMpIiIAgxL+4iIKGj98pe/RPPmzTFmzBisXr0aubm5WLlyJR588EEcO3bM7mtmzpyJRx55BCtWrEBubi62bt2KO++8ExUVFRg+fDgACaxyc3Oxbds2nD59GmVlZRg2bBgGDBiAsWPHYvHixTh06BDWrl2LJ554Aps2bbJ+/aioKEycOBHbt2/H6tWr8cADD2DcuHFITU1Fbm4uHn30Uaxbtw6HDx/GkiVL8OOPP6Jz58718vMiIiL3MZAiIqKgFRMTg1WrVqFVq1a4+eab0blzZ9x55524dOmSwwzV4MGDcfDgQdxxxx3o1KkTRowYgfz8fCxZsgQdO3YEANxyyy244YYbMHToULRo0QL//Oc/YbFYsHDhQlxzzTW48847kZWVhQkTJuDQoUNISUmxfv327dvj5ptvxsiRI5GTk4Ps7Gy8/vrr1vHu2bMHt9xyC7KysnD33Xdj8uTJuOeee3z/wyIiIlMsmqZp/h4EERFRYzBz5kwsWLAA27Zt8/dQiIiojpiRIiIiIiIiMomBFBERERERkUks7SMiIiIiIjKJGSkiIiIiIiKTGEgRERERERGZxECKiIiIiIjIJAZSREREREREJjGQIiIiIiIiMomBFBERERERkUkMpIiIiIiIiExiIEVERERERGTS/wNyhr4nz539YgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'BiLSTM - ADAM Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0a893f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "802b88df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1719.5455\n",
      "Epoch 1: val_loss improved from inf to 9644.55078, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 7s 42ms/step - loss: 1681.9575 - val_loss: 9644.5508\n",
      "Epoch 2/1000\n",
      "12/37 [========>.....................] - ETA: 0s - loss: 599.2544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/37 [=========================>....] - ETA: 0s - loss: 896.4873\n",
      "Epoch 2: val_loss improved from 9644.55078 to 1224.89978, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 871.9130 - val_loss: 1224.8998\n",
      "Epoch 3/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 105.0621\n",
      "Epoch 3: val_loss improved from 1224.89978 to 194.53154, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 105.8359 - val_loss: 194.5315\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 24.6715\n",
      "Epoch 4: val_loss did not improve from 194.53154\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 24.6715 - val_loss: 564.9063\n",
      "Epoch 5/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 21.6789\n",
      "Epoch 5: val_loss improved from 194.53154 to 119.08791, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 20.9187 - val_loss: 119.0879\n",
      "Epoch 6/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 15.3903\n",
      "Epoch 6: val_loss improved from 119.08791 to 109.31612, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 15.3203 - val_loss: 109.3161\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 26.9183\n",
      "Epoch 7: val_loss did not improve from 109.31612\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 26.9183 - val_loss: 129.7028\n",
      "Epoch 8/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 14.2570\n",
      "Epoch 8: val_loss did not improve from 109.31612\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 14.1801 - val_loss: 150.9488\n",
      "Epoch 9/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.1835\n",
      "Epoch 9: val_loss did not improve from 109.31612\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 14.8356 - val_loss: 109.8794\n",
      "Epoch 10/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 22.1446\n",
      "Epoch 10: val_loss improved from 109.31612 to 99.16425, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 21.4439 - val_loss: 99.1642\n",
      "Epoch 11/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.1479\n",
      "Epoch 11: val_loss improved from 99.16425 to 65.05972, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.2633 - val_loss: 65.0597\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 16.1850\n",
      "Epoch 12: val_loss did not improve from 65.05972\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 16.1850 - val_loss: 117.3290\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.8838\n",
      "Epoch 13: val_loss did not improve from 65.05972\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 8.8838 - val_loss: 74.3005\n",
      "Epoch 14/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.7037\n",
      "Epoch 14: val_loss improved from 65.05972 to 60.68811, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.8688 - val_loss: 60.6881\n",
      "Epoch 15/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 15.7407\n",
      "Epoch 15: val_loss did not improve from 60.68811\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 15.3475 - val_loss: 67.5702\n",
      "Epoch 16/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.7738\n",
      "Epoch 16: val_loss improved from 60.68811 to 54.14044, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.8223 - val_loss: 54.1404\n",
      "Epoch 17/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6549\n",
      "Epoch 17: val_loss did not improve from 54.14044\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.6321 - val_loss: 81.1606\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.8221\n",
      "Epoch 18: val_loss improved from 54.14044 to 51.45515, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.8221 - val_loss: 51.4552\n",
      "Epoch 19/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.4866\n",
      "Epoch 19: val_loss improved from 51.45515 to 50.51738, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 9.5319 - val_loss: 50.5174\n",
      "Epoch 20/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.8437\n",
      "Epoch 20: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.1088 - val_loss: 60.4138\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.1963\n",
      "Epoch 21: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 12.1963 - val_loss: 53.0793\n",
      "Epoch 22/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1237\n",
      "Epoch 22: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.0633 - val_loss: 64.9812\n",
      "Epoch 23/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.2375\n",
      "Epoch 23: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.1989 - val_loss: 72.7146\n",
      "Epoch 24/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.2284\n",
      "Epoch 24: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.0015 - val_loss: 61.4063\n",
      "Epoch 25/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.7967\n",
      "Epoch 25: val_loss did not improve from 50.51738\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.8162 - val_loss: 61.6972\n",
      "Epoch 26/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.5639\n",
      "Epoch 26: val_loss improved from 50.51738 to 49.14584, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.5270 - val_loss: 49.1458\n",
      "Epoch 27/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.8697\n",
      "Epoch 27: val_loss did not improve from 49.14584\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.5838 - val_loss: 55.8334\n",
      "Epoch 28/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.0299\n",
      "Epoch 28: val_loss improved from 49.14584 to 43.07130, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9681 - val_loss: 43.0713\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.9221\n",
      "Epoch 29: val_loss did not improve from 43.07130\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.9221 - val_loss: 45.5146\n",
      "Epoch 30/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.9077\n",
      "Epoch 30: val_loss did not improve from 43.07130\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.6490 - val_loss: 45.9611\n",
      "Epoch 31/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1893\n",
      "Epoch 31: val_loss did not improve from 43.07130\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.1676 - val_loss: 47.0620\n",
      "Epoch 32/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.3584\n",
      "Epoch 32: val_loss improved from 43.07130 to 39.12922, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.4512 - val_loss: 39.1292\n",
      "Epoch 33/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.5314\n",
      "Epoch 33: val_loss did not improve from 39.12922\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.4459 - val_loss: 45.5583\n",
      "Epoch 34/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3492\n",
      "Epoch 34: val_loss did not improve from 39.12922\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2726 - val_loss: 46.9262\n",
      "Epoch 35/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.1430\n",
      "Epoch 35: val_loss improved from 39.12922 to 34.65300, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.1208 - val_loss: 34.6530\n",
      "Epoch 36/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3409\n",
      "Epoch 36: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3120 - val_loss: 39.8575\n",
      "Epoch 37/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3254\n",
      "Epoch 37: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.2556 - val_loss: 37.8809\n",
      "Epoch 38/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2565\n",
      "Epoch 38: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.1819 - val_loss: 60.2723\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.1949\n",
      "Epoch 39: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.1949 - val_loss: 38.8226\n",
      "Epoch 40/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.0641\n",
      "Epoch 40: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.8387 - val_loss: 47.3726\n",
      "Epoch 41/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.0476\n",
      "Epoch 41: val_loss did not improve from 34.65300\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 7.0040 - val_loss: 52.1409\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5144\n",
      "Epoch 42: val_loss improved from 34.65300 to 33.26770, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.7488 - val_loss: 33.2677\n",
      "Epoch 43/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1422\n",
      "Epoch 43: val_loss did not improve from 33.26770\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.0450 - val_loss: 39.1148\n",
      "Epoch 44/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.9465\n",
      "Epoch 44: val_loss improved from 33.26770 to 31.96272, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.8463 - val_loss: 31.9627\n",
      "Epoch 45/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7724\n",
      "Epoch 45: val_loss improved from 31.96272 to 28.76061, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6706 - val_loss: 28.7606\n",
      "Epoch 46/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.2974\n",
      "Epoch 46: val_loss improved from 28.76061 to 28.73831, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3289 - val_loss: 28.7383\n",
      "Epoch 47/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8379\n",
      "Epoch 47: val_loss did not improve from 28.73831\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8816 - val_loss: 38.4717\n",
      "Epoch 48/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6812\n",
      "Epoch 48: val_loss improved from 28.73831 to 27.68817, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7139 - val_loss: 27.6882\n",
      "Epoch 49/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3486\n",
      "Epoch 49: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.1853 - val_loss: 31.3921\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4501\n",
      "Epoch 50: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4501 - val_loss: 30.9338\n",
      "Epoch 51/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8820\n",
      "Epoch 51: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.8708 - val_loss: 33.9582\n",
      "Epoch 52/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1328\n",
      "Epoch 52: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.1090 - val_loss: 31.2276\n",
      "Epoch 53/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7927\n",
      "Epoch 53: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7147 - val_loss: 33.4125\n",
      "Epoch 54/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4554\n",
      "Epoch 54: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.4979 - val_loss: 88.7240\n",
      "Epoch 55/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4837\n",
      "Epoch 55: val_loss did not improve from 27.68817\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3784 - val_loss: 30.9147\n",
      "Epoch 56/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7513\n",
      "Epoch 56: val_loss improved from 27.68817 to 26.38718, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.6973 - val_loss: 26.3872\n",
      "Epoch 57/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6552\n",
      "Epoch 57: val_loss did not improve from 26.38718\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6777 - val_loss: 33.4489\n",
      "Epoch 58/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.2128\n",
      "Epoch 58: val_loss did not improve from 26.38718\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.0759 - val_loss: 41.0260\n",
      "Epoch 59/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0457\n",
      "Epoch 59: val_loss did not improve from 26.38718\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.9086 - val_loss: 37.5333\n",
      "Epoch 60/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5489\n",
      "Epoch 60: val_loss did not improve from 26.38718\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4907 - val_loss: 37.9629\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8831\n",
      "Epoch 61: val_loss improved from 26.38718 to 24.85663, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8831 - val_loss: 24.8566\n",
      "Epoch 62/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1464\n",
      "Epoch 62: val_loss did not improve from 24.85663\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0621 - val_loss: 30.2480\n",
      "Epoch 63/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5744\n",
      "Epoch 63: val_loss did not improve from 24.85663\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.6212 - val_loss: 28.3982\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4640\n",
      "Epoch 64: val_loss improved from 24.85663 to 24.08845, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4640 - val_loss: 24.0884\n",
      "Epoch 65/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4043\n",
      "Epoch 65: val_loss did not improve from 24.08845\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3112 - val_loss: 25.2149\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1352\n",
      "Epoch 66: val_loss did not improve from 24.08845\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.0333 - val_loss: 24.5636\n",
      "Epoch 67/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7516\n",
      "Epoch 67: val_loss did not improve from 24.08845\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7769 - val_loss: 37.6031\n",
      "Epoch 68/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.6439\n",
      "Epoch 68: val_loss did not improve from 24.08845\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.4984 - val_loss: 24.3656\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2913\n",
      "Epoch 69: val_loss did not improve from 24.08845\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2913 - val_loss: 30.5995\n",
      "Epoch 70/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0812\n",
      "Epoch 70: val_loss improved from 24.08845 to 22.49330, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.0899 - val_loss: 22.4933\n",
      "Epoch 71/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3837\n",
      "Epoch 71: val_loss improved from 22.49330 to 22.34951, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.4141 - val_loss: 22.3495\n",
      "Epoch 72/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8475\n",
      "Epoch 72: val_loss did not improve from 22.34951\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 3.8095 - val_loss: 32.4540\n",
      "Epoch 73/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8849\n",
      "Epoch 73: val_loss did not improve from 22.34951\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.9114 - val_loss: 33.0303\n",
      "Epoch 74/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4190\n",
      "Epoch 74: val_loss did not improve from 22.34951\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.4027 - val_loss: 26.0883\n",
      "Epoch 75/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2992\n",
      "Epoch 75: val_loss improved from 22.34951 to 21.41508, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.2685 - val_loss: 21.4151\n",
      "Epoch 76/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2147\n",
      "Epoch 76: val_loss did not improve from 21.41508\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 4.2116 - val_loss: 31.3442\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4087\n",
      "Epoch 77: val_loss did not improve from 21.41508\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.4087 - val_loss: 24.2079\n",
      "Epoch 78/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3918\n",
      "Epoch 78: val_loss did not improve from 21.41508\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.3822 - val_loss: 37.2733\n",
      "Epoch 79/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2091\n",
      "Epoch 79: val_loss did not improve from 21.41508\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.1981 - val_loss: 23.3599\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1739\n",
      "Epoch 80: val_loss did not improve from 21.41508\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.1739 - val_loss: 22.6226\n",
      "Epoch 81/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1131\n",
      "Epoch 81: val_loss improved from 21.41508 to 20.36701, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.1846 - val_loss: 20.3670\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6314\n",
      "Epoch 82: val_loss did not improve from 20.36701\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.6314 - val_loss: 22.8155\n",
      "Epoch 83/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8801\n",
      "Epoch 83: val_loss did not improve from 20.36701\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.9079 - val_loss: 40.6247\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2475\n",
      "Epoch 84: val_loss did not improve from 20.36701\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 3.2475 - val_loss: 25.6813\n",
      "Epoch 85/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5576\n",
      "Epoch 85: val_loss did not improve from 20.36701\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5730 - val_loss: 23.9117\n",
      "Epoch 86/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6946\n",
      "Epoch 86: val_loss did not improve from 20.36701\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6409 - val_loss: 25.8101\n",
      "Epoch 87/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5307\n",
      "Epoch 87: val_loss improved from 20.36701 to 20.12612, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.5428 - val_loss: 20.1261\n",
      "Epoch 88/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5662\n",
      "Epoch 88: val_loss did not improve from 20.12612\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5190 - val_loss: 24.1802\n",
      "Epoch 89/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6683\n",
      "Epoch 89: val_loss did not improve from 20.12612\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6434 - val_loss: 20.1372\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4938\n",
      "Epoch 90: val_loss did not improve from 20.12612\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.4938 - val_loss: 21.0265\n",
      "Epoch 91/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4106\n",
      "Epoch 91: val_loss improved from 20.12612 to 19.82774, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4269 - val_loss: 19.8277\n",
      "Epoch 92/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4760\n",
      "Epoch 92: val_loss did not improve from 19.82774\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3892 - val_loss: 21.8541\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8358\n",
      "Epoch 93: val_loss did not improve from 19.82774\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.8358 - val_loss: 22.4303\n",
      "Epoch 94/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4012\n",
      "Epoch 94: val_loss improved from 19.82774 to 19.47273, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3398 - val_loss: 19.4727\n",
      "Epoch 95/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5398\n",
      "Epoch 95: val_loss improved from 19.47273 to 19.34275, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3841 - val_loss: 19.3428\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0265\n",
      "Epoch 96: val_loss did not improve from 19.34275\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0265 - val_loss: 19.4528\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7025\n",
      "Epoch 97: val_loss did not improve from 19.34275\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.7025 - val_loss: 23.9576\n",
      "Epoch 98/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0622\n",
      "Epoch 98: val_loss improved from 19.34275 to 19.05351, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.0553 - val_loss: 19.0535\n",
      "Epoch 99/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0518\n",
      "Epoch 99: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0290 - val_loss: 36.3354\n",
      "Epoch 100/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1529\n",
      "Epoch 100: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1873 - val_loss: 26.4165\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8268\n",
      "Epoch 101: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.8268 - val_loss: 22.2489\n",
      "Epoch 102/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5158\n",
      "Epoch 102: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5631 - val_loss: 19.2931\n",
      "Epoch 103/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1811\n",
      "Epoch 103: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.1515 - val_loss: 21.9608\n",
      "Epoch 104/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3316\n",
      "Epoch 104: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.3435 - val_loss: 23.7425\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.4726\n",
      "Epoch 105: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.4726 - val_loss: 21.2922\n",
      "Epoch 106/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4064\n",
      "Epoch 106: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.4416 - val_loss: 34.1500\n",
      "Epoch 107/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2931\n",
      "Epoch 107: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7286 - val_loss: 80.1894\n",
      "Epoch 108/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3819\n",
      "Epoch 108: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4094 - val_loss: 22.2363\n",
      "Epoch 109/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0536\n",
      "Epoch 109: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0519 - val_loss: 20.0907\n",
      "Epoch 110/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.9667\n",
      "Epoch 110: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7988 - val_loss: 22.0303\n",
      "Epoch 111/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8883\n",
      "Epoch 111: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.8692 - val_loss: 35.8475\n",
      "Epoch 112/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0947\n",
      "Epoch 112: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1228 - val_loss: 19.8857\n",
      "Epoch 113/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6711\n",
      "Epoch 113: val_loss did not improve from 19.05351\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.9104 - val_loss: 48.1733\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4657\n",
      "Epoch 114: val_loss improved from 19.05351 to 18.22205, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.4657 - val_loss: 18.2220\n",
      "Epoch 115/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2580\n",
      "Epoch 115: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2940 - val_loss: 19.8864\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3123\n",
      "Epoch 116: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3371 - val_loss: 18.7004\n",
      "Epoch 117/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2087\n",
      "Epoch 117: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1907 - val_loss: 19.6517\n",
      "Epoch 118/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4616\n",
      "Epoch 118: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3900 - val_loss: 29.1773\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1674\n",
      "Epoch 119: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1674 - val_loss: 28.8467\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1816\n",
      "Epoch 120: val_loss did not improve from 18.22205\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1816 - val_loss: 19.6899\n",
      "Epoch 121/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0991\n",
      "Epoch 121: val_loss improved from 18.22205 to 17.80275, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0900 - val_loss: 17.8027\n",
      "Epoch 122/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0848\n",
      "Epoch 122: val_loss improved from 17.80275 to 17.42329, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1614 - val_loss: 17.4233\n",
      "Epoch 123/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2697\n",
      "Epoch 123: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2435 - val_loss: 18.2783\n",
      "Epoch 124/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3177\n",
      "Epoch 124: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3582 - val_loss: 17.6710\n",
      "Epoch 125/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9907\n",
      "Epoch 125: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0646 - val_loss: 20.0238\n",
      "Epoch 126/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9473\n",
      "Epoch 126: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9476 - val_loss: 18.7325\n",
      "Epoch 127/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2778\n",
      "Epoch 127: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2732 - val_loss: 20.2997\n",
      "Epoch 128/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9784\n",
      "Epoch 128: val_loss did not improve from 17.42329\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9745 - val_loss: 25.3751\n",
      "Epoch 129/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3488\n",
      "Epoch 129: val_loss improved from 17.42329 to 17.20952, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3705 - val_loss: 17.2095\n",
      "Epoch 130/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1378\n",
      "Epoch 130: val_loss did not improve from 17.20952\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1706 - val_loss: 19.9801\n",
      "Epoch 131/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1572\n",
      "Epoch 131: val_loss did not improve from 17.20952\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0912 - val_loss: 31.6677\n",
      "Epoch 132/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7063\n",
      "Epoch 132: val_loss did not improve from 17.20952\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6932 - val_loss: 21.0373\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3262\n",
      "Epoch 133: val_loss improved from 17.20952 to 16.96190, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.3262 - val_loss: 16.9619\n",
      "Epoch 134/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4116\n",
      "Epoch 134: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3927 - val_loss: 17.9921\n",
      "Epoch 135/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8466\n",
      "Epoch 135: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9346 - val_loss: 19.2453\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1486\n",
      "Epoch 136: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1486 - val_loss: 24.2108\n",
      "Epoch 137/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0634\n",
      "Epoch 137: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0677 - val_loss: 31.8978\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3171\n",
      "Epoch 138: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3171 - val_loss: 17.4940\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5584\n",
      "Epoch 139: val_loss did not improve from 16.96190\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5584 - val_loss: 18.1567\n",
      "Epoch 140/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0837\n",
      "Epoch 140: val_loss improved from 16.96190 to 16.95377, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1458 - val_loss: 16.9538\n",
      "Epoch 141/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3371\n",
      "Epoch 141: val_loss improved from 16.95377 to 16.86650, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2722 - val_loss: 16.8665\n",
      "Epoch 142/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4658\n",
      "Epoch 142: val_loss did not improve from 16.86650\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4908 - val_loss: 19.4008\n",
      "Epoch 143/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2436\n",
      "Epoch 143: val_loss did not improve from 16.86650\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2228 - val_loss: 17.8978\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0077\n",
      "Epoch 144: val_loss improved from 16.86650 to 16.65214, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0077 - val_loss: 16.6521\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1697\n",
      "Epoch 145: val_loss did not improve from 16.65214\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1697 - val_loss: 18.7732\n",
      "Epoch 146/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5074\n",
      "Epoch 146: val_loss improved from 16.65214 to 16.64144, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.4423 - val_loss: 16.6414\n",
      "Epoch 147/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1608\n",
      "Epoch 147: val_loss did not improve from 16.64144\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1697 - val_loss: 26.1956\n",
      "Epoch 148/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2999\n",
      "Epoch 148: val_loss did not improve from 16.64144\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3414 - val_loss: 17.3249\n",
      "Epoch 149/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9847\n",
      "Epoch 149: val_loss did not improve from 16.64144\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9488 - val_loss: 23.6096\n",
      "Epoch 150/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9028\n",
      "Epoch 150: val_loss improved from 16.64144 to 16.52996, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0211 - val_loss: 16.5300\n",
      "Epoch 151/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5882\n",
      "Epoch 151: val_loss did not improve from 16.52996\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5068 - val_loss: 19.6713\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9558\n",
      "Epoch 152: val_loss improved from 16.52996 to 16.44833, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2.9558 - val_loss: 16.4483\n",
      "Epoch 153/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2450\n",
      "Epoch 153: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2576 - val_loss: 17.6164\n",
      "Epoch 154/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3452\n",
      "Epoch 154: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3336 - val_loss: 31.4910\n",
      "Epoch 155/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3849\n",
      "Epoch 155: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2853 - val_loss: 17.4052\n",
      "Epoch 156/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2440\n",
      "Epoch 156: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1987 - val_loss: 17.6185\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8947\n",
      "Epoch 157: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.8947 - val_loss: 16.4589\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2596\n",
      "Epoch 158: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2596 - val_loss: 17.0349\n",
      "Epoch 159/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9382\n",
      "Epoch 159: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9882 - val_loss: 18.7184\n",
      "Epoch 160/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0777\n",
      "Epoch 160: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0654 - val_loss: 16.8407\n",
      "Epoch 161/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0092\n",
      "Epoch 161: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1598 - val_loss: 18.2239\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8472\n",
      "Epoch 162: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8472 - val_loss: 19.1381\n",
      "Epoch 163/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2693\n",
      "Epoch 163: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2917 - val_loss: 18.7683\n",
      "Epoch 164/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2501\n",
      "Epoch 164: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1983 - val_loss: 16.6781\n",
      "Epoch 165/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8201\n",
      "Epoch 165: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8520 - val_loss: 16.7038\n",
      "Epoch 166/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0127\n",
      "Epoch 166: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0429 - val_loss: 24.9525\n",
      "Epoch 167/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0332\n",
      "Epoch 167: val_loss did not improve from 16.44833\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9865 - val_loss: 16.5173\n",
      "Epoch 168/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8265\n",
      "Epoch 168: val_loss improved from 16.44833 to 16.30353, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8513 - val_loss: 16.3035\n",
      "Epoch 169/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9086\n",
      "Epoch 169: val_loss did not improve from 16.30353\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8763 - val_loss: 17.7686\n",
      "Epoch 170/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8134\n",
      "Epoch 170: val_loss did not improve from 16.30353\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.7982 - val_loss: 16.6833\n",
      "Epoch 171/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9476\n",
      "Epoch 171: val_loss improved from 16.30353 to 16.17566, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.9461 - val_loss: 16.1757\n",
      "Epoch 172/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1068\n",
      "Epoch 172: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0901 - val_loss: 16.2711\n",
      "Epoch 173/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8907\n",
      "Epoch 173: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9347 - val_loss: 17.1915\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1363\n",
      "Epoch 174: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1363 - val_loss: 18.4823\n",
      "Epoch 175/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1015\n",
      "Epoch 175: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9796 - val_loss: 17.6141\n",
      "Epoch 176/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4035\n",
      "Epoch 176: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3914 - val_loss: 16.4894\n",
      "Epoch 177/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9839\n",
      "Epoch 177: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9788 - val_loss: 16.6848\n",
      "Epoch 178/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0509\n",
      "Epoch 178: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0454 - val_loss: 19.6711\n",
      "Epoch 179/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0876\n",
      "Epoch 179: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0938 - val_loss: 17.7793\n",
      "Epoch 180/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1080\n",
      "Epoch 180: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0449 - val_loss: 16.2905\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9519\n",
      "Epoch 181: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9519 - val_loss: 22.2517\n",
      "Epoch 182/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1374\n",
      "Epoch 182: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0793 - val_loss: 17.0921\n",
      "Epoch 183/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2341\n",
      "Epoch 183: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1955 - val_loss: 17.5808\n",
      "Epoch 184/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0517\n",
      "Epoch 184: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0324 - val_loss: 16.2133\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1744\n",
      "Epoch 185: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1744 - val_loss: 18.2486\n",
      "Epoch 186/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0870\n",
      "Epoch 186: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1128 - val_loss: 16.2504\n",
      "Epoch 187/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2315\n",
      "Epoch 187: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2708 - val_loss: 17.5122\n",
      "Epoch 188/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9252\n",
      "Epoch 188: val_loss did not improve from 16.17566\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9791 - val_loss: 17.0625\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8107\n",
      "Epoch 189: val_loss improved from 16.17566 to 16.12204, saving model to Best_BiLSTM_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.8107 - val_loss: 16.1220\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5641\n",
      "Epoch 190: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.5641 - val_loss: 22.8782\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0678\n",
      "Epoch 191: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.0678 - val_loss: 37.0495\n",
      "Epoch 192/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0763\n",
      "Epoch 192: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0484 - val_loss: 23.4627\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1636\n",
      "Epoch 193: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.1636 - val_loss: 22.5682\n",
      "Epoch 194/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1999\n",
      "Epoch 194: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1705 - val_loss: 25.9981\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1715\n",
      "Epoch 195: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1715 - val_loss: 23.4431\n",
      "Epoch 196/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1865\n",
      "Epoch 196: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2374 - val_loss: 25.9130\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1630\n",
      "Epoch 197: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1630 - val_loss: 33.8444\n",
      "Epoch 198/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4754\n",
      "Epoch 198: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.3376 - val_loss: 27.3082\n",
      "Epoch 199/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0275\n",
      "Epoch 199: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1788 - val_loss: 20.2851\n",
      "Epoch 200/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3863\n",
      "Epoch 200: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3669 - val_loss: 21.0866\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9114\n",
      "Epoch 201: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9114 - val_loss: 18.7683\n",
      "Epoch 202/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2712\n",
      "Epoch 202: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2316 - val_loss: 23.0113\n",
      "Epoch 203/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1019\n",
      "Epoch 203: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0521 - val_loss: 22.1319\n",
      "Epoch 204/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5678\n",
      "Epoch 204: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.4672 - val_loss: 24.5335\n",
      "Epoch 205/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0460\n",
      "Epoch 205: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9945 - val_loss: 23.6336\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0142\n",
      "Epoch 206: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0142 - val_loss: 25.8840\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4910\n",
      "Epoch 207: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4910 - val_loss: 22.1988\n",
      "Epoch 208/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9875\n",
      "Epoch 208: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9592 - val_loss: 20.8740\n",
      "Epoch 209/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1051\n",
      "Epoch 209: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0912 - val_loss: 19.4541\n",
      "Epoch 210/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9720\n",
      "Epoch 210: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9760 - val_loss: 28.8322\n",
      "Epoch 211/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1616\n",
      "Epoch 211: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1404 - val_loss: 24.1652\n",
      "Epoch 212/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0239\n",
      "Epoch 212: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0007 - val_loss: 18.4623\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9413\n",
      "Epoch 213: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9413 - val_loss: 18.7609\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9148\n",
      "Epoch 214: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9148 - val_loss: 17.9476\n",
      "Epoch 215/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5570\n",
      "Epoch 215: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.4767 - val_loss: 20.6450\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9375\n",
      "Epoch 216: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9375 - val_loss: 18.6806\n",
      "Epoch 217/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4173\n",
      "Epoch 217: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4285 - val_loss: 24.3951\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1385\n",
      "Epoch 218: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.1385 - val_loss: 18.9135\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7579\n",
      "Epoch 219: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.7579 - val_loss: 27.1942\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0973\n",
      "Epoch 220: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0973 - val_loss: 17.9927\n",
      "Epoch 221/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0874\n",
      "Epoch 221: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1179 - val_loss: 18.6798\n",
      "Epoch 222/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2278\n",
      "Epoch 222: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2205 - val_loss: 17.8615\n",
      "Epoch 223/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1045\n",
      "Epoch 223: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0799 - val_loss: 19.0170\n",
      "Epoch 224/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2096\n",
      "Epoch 224: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1319 - val_loss: 19.9923\n",
      "Epoch 225/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8981\n",
      "Epoch 225: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9729 - val_loss: 17.9356\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0860\n",
      "Epoch 226: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0860 - val_loss: 18.1054\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9104\n",
      "Epoch 227: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.9104 - val_loss: 20.6355\n",
      "Epoch 228/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1514\n",
      "Epoch 228: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0429 - val_loss: 20.7660\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2779\n",
      "Epoch 229: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2779 - val_loss: 18.3618\n",
      "Epoch 230/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4855\n",
      "Epoch 230: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4015 - val_loss: 18.5703\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9187\n",
      "Epoch 231: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9187 - val_loss: 29.5807\n",
      "Epoch 232/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2614\n",
      "Epoch 232: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2686 - val_loss: 29.2729\n",
      "Epoch 233/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3481\n",
      "Epoch 233: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3655 - val_loss: 19.6745\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5870\n",
      "Epoch 234: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5870 - val_loss: 21.1432\n",
      "Epoch 235/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8496\n",
      "Epoch 235: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8088 - val_loss: 22.0524\n",
      "Epoch 236/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8570\n",
      "Epoch 236: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8582 - val_loss: 25.3163\n",
      "Epoch 237/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9935\n",
      "Epoch 237: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9908 - val_loss: 18.1267\n",
      "Epoch 238/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1919\n",
      "Epoch 238: val_loss did not improve from 16.12204\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.1165 - val_loss: 21.4012\n",
      "Epoch 239/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9376\n",
      "Epoch 239: val_loss did not improve from 16.12204\n",
      "Restoring model weights from the end of the best epoch: 189.\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9387 - val_loss: 22.4442\n",
      "Epoch 239: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "bi_lstm_sgd_model = TimeSeriesModel(model_type='bi_lstm', optimizer = 'sgd')\n",
    "# Train the model\n",
    "bi_lstm_sgd_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_BiLSTM_Model_SGD_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f97fc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = bi_lstm_sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4dd9cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.161842439390544\n",
      "R2 Score: 0.9062903037916432\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56999d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'BiLSTM - SGD Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12b2b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5274.6021\n",
      "Epoch 1: val_loss improved from inf to 19810.49023, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 7s 45ms/step - loss: 5274.6021 - val_loss: 19810.4902\n",
      "Epoch 2/1000\n",
      "11/37 [=======>......................] - ETA: 0s - loss: 4172.1870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 4219.6299\n",
      "Epoch 2: val_loss improved from 19810.49023 to 18251.96680, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4219.6299 - val_loss: 18251.9668\n",
      "Epoch 3/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3679.8037\n",
      "Epoch 3: val_loss improved from 18251.96680 to 16890.71289, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3686.0288 - val_loss: 16890.7129\n",
      "Epoch 4/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3232.6641\n",
      "Epoch 4: val_loss improved from 16890.71289 to 15685.41895, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3229.3525 - val_loss: 15685.4189\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2853.0110\n",
      "Epoch 5: val_loss improved from 15685.41895 to 14555.42676, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2853.0110 - val_loss: 14555.4268\n",
      "Epoch 6/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2526.8853\n",
      "Epoch 6: val_loss improved from 14555.42676 to 13487.84961, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2520.8093 - val_loss: 13487.8496\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2234.7668\n",
      "Epoch 7: val_loss improved from 13487.84961 to 12461.97656, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 2234.7668 - val_loss: 12461.9766\n",
      "Epoch 8/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1994.0463\n",
      "Epoch 8: val_loss improved from 12461.97656 to 11497.64746, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2000.2982 - val_loss: 11497.6475\n",
      "Epoch 9/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1759.9838\n",
      "Epoch 9: val_loss improved from 11497.64746 to 10532.67480, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1749.7009 - val_loss: 10532.6748\n",
      "Epoch 10/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1557.5872\n",
      "Epoch 10: val_loss improved from 10532.67480 to 9638.37793, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1534.7092 - val_loss: 9638.3779\n",
      "Epoch 11/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1333.7798\n",
      "Epoch 11: val_loss improved from 9638.37793 to 8777.88574, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1337.6173 - val_loss: 8777.8857\n",
      "Epoch 12/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1158.8889\n",
      "Epoch 12: val_loss improved from 8777.88574 to 7969.47510, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1164.3990 - val_loss: 7969.4751\n",
      "Epoch 13/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1001.9448\n",
      "Epoch 13: val_loss improved from 7969.47510 to 7207.04199, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1006.6185 - val_loss: 7207.0420\n",
      "Epoch 14/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 858.7028\n",
      "Epoch 14: val_loss improved from 7207.04199 to 6470.27490, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 861.2969 - val_loss: 6470.2749\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 745.7377\n",
      "Epoch 15: val_loss improved from 6470.27490 to 5793.31641, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 745.7377 - val_loss: 5793.3164\n",
      "Epoch 16/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 602.9150\n",
      "Epoch 16: val_loss improved from 5793.31641 to 5140.14307, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 616.0569 - val_loss: 5140.1431\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 515.2744\n",
      "Epoch 17: val_loss improved from 5140.14307 to 4560.27441, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 515.2744 - val_loss: 4560.2744\n",
      "Epoch 18/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 427.3607\n",
      "Epoch 18: val_loss improved from 4560.27441 to 3992.74341, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 429.6157 - val_loss: 3992.7434\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 344.1829\n",
      "Epoch 19: val_loss improved from 3992.74341 to 3483.13574, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 344.1829 - val_loss: 3483.1357\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 276.2805\n",
      "Epoch 20: val_loss improved from 3483.13574 to 3011.57812, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 276.2805 - val_loss: 3011.5781\n",
      "Epoch 21/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 217.8576\n",
      "Epoch 21: val_loss improved from 3011.57812 to 2576.60522, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 216.5486 - val_loss: 2576.6052\n",
      "Epoch 22/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 161.1132\n",
      "Epoch 22: val_loss improved from 2576.60522 to 2183.19604, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 162.6468 - val_loss: 2183.1960\n",
      "Epoch 23/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 126.0107\n",
      "Epoch 23: val_loss improved from 2183.19604 to 1834.65723, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 125.2721 - val_loss: 1834.6572\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 96.5843\n",
      "Epoch 24: val_loss improved from 1834.65723 to 1546.74463, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 96.5843 - val_loss: 1546.7446\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 72.3989\n",
      "Epoch 25: val_loss improved from 1546.74463 to 1313.74512, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 72.3989 - val_loss: 1313.7451\n",
      "Epoch 26/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 56.0494\n",
      "Epoch 26: val_loss improved from 1313.74512 to 1112.87109, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 58.4340 - val_loss: 1112.8711\n",
      "Epoch 27/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 48.3504\n",
      "Epoch 27: val_loss improved from 1112.87109 to 953.85205, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 47.6879 - val_loss: 953.8521\n",
      "Epoch 28/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 44.1227\n",
      "Epoch 28: val_loss improved from 953.85205 to 824.61432, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 43.0587 - val_loss: 824.6143\n",
      "Epoch 29/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 35.9201\n",
      "Epoch 29: val_loss improved from 824.61432 to 724.61371, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 35.0748 - val_loss: 724.6137\n",
      "Epoch 30/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 36.2597\n",
      "Epoch 30: val_loss improved from 724.61371 to 668.15833, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 35.9209 - val_loss: 668.1583\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 30.8147\n",
      "Epoch 31: val_loss improved from 668.15833 to 598.26404, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 30.8147 - val_loss: 598.2640\n",
      "Epoch 32/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 31.6870\n",
      "Epoch 32: val_loss improved from 598.26404 to 576.95398, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 31.3486 - val_loss: 576.9540\n",
      "Epoch 33/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 29.6264\n",
      "Epoch 33: val_loss did not improve from 576.95398\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 29.4397 - val_loss: 675.6146\n",
      "Epoch 34/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 25.0167\n",
      "Epoch 34: val_loss improved from 576.95398 to 496.16949, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 24.7854 - val_loss: 496.1695\n",
      "Epoch 35/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 22.7770\n",
      "Epoch 35: val_loss improved from 496.16949 to 457.28586, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 23.0817 - val_loss: 457.2859\n",
      "Epoch 36/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 22.4299\n",
      "Epoch 36: val_loss improved from 457.28586 to 429.07550, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 22.1111 - val_loss: 429.0755\n",
      "Epoch 37/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 22.3510\n",
      "Epoch 37: val_loss improved from 429.07550 to 411.56870, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 22.0905 - val_loss: 411.5687\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 24.1790\n",
      "Epoch 38: val_loss did not improve from 411.56870\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 24.1790 - val_loss: 434.6166\n",
      "Epoch 39/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 18.9917\n",
      "Epoch 39: val_loss improved from 411.56870 to 386.57059, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 18.8472 - val_loss: 386.5706\n",
      "Epoch 40/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 20.2689\n",
      "Epoch 40: val_loss did not improve from 386.57059\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 19.6264 - val_loss: 396.6837\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 17.4948\n",
      "Epoch 41: val_loss improved from 386.57059 to 349.72018, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 17.4948 - val_loss: 349.7202\n",
      "Epoch 42/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 18.3767\n",
      "Epoch 42: val_loss improved from 349.72018 to 341.86374, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 18.1944 - val_loss: 341.8637\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 16.3132\n",
      "Epoch 43: val_loss did not improve from 341.86374\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 16.3132 - val_loss: 351.3363\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 15.5912\n",
      "Epoch 44: val_loss did not improve from 341.86374\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 15.5912 - val_loss: 349.7368\n",
      "Epoch 45/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.7093\n",
      "Epoch 45: val_loss improved from 341.86374 to 291.75146, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 16.4013 - val_loss: 291.7515\n",
      "Epoch 46/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.3956\n",
      "Epoch 46: val_loss improved from 291.75146 to 290.94553, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 17.1887 - val_loss: 290.9455\n",
      "Epoch 47/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12.5127\n",
      "Epoch 47: val_loss improved from 290.94553 to 282.77451, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 12.5840 - val_loss: 282.7745\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.4707\n",
      "Epoch 48: val_loss did not improve from 282.77451\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 14.4707 - val_loss: 598.7430\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 14.7160\n",
      "Epoch 49: val_loss improved from 282.77451 to 261.68170, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 14.7160 - val_loss: 261.6817\n",
      "Epoch 50/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.3660\n",
      "Epoch 50: val_loss did not improve from 261.68170\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 13.2878 - val_loss: 262.7085\n",
      "Epoch 51/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.0017\n",
      "Epoch 51: val_loss did not improve from 261.68170\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 13.5258 - val_loss: 297.9827\n",
      "Epoch 52/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.4987\n",
      "Epoch 52: val_loss did not improve from 261.68170\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 13.5488 - val_loss: 278.9180\n",
      "Epoch 53/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.8818\n",
      "Epoch 53: val_loss improved from 261.68170 to 249.60449, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 11.6221 - val_loss: 249.6045\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 13.7320\n",
      "Epoch 54: val_loss improved from 249.60449 to 246.00610, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 13.7320 - val_loss: 246.0061\n",
      "Epoch 55/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 12.9586\n",
      "Epoch 55: val_loss improved from 246.00610 to 243.00774, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 12.4596 - val_loss: 243.0077\n",
      "Epoch 56/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.1040\n",
      "Epoch 56: val_loss improved from 243.00774 to 234.15819, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 11.7360 - val_loss: 234.1582\n",
      "Epoch 57/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10.7462\n",
      "Epoch 57: val_loss improved from 234.15819 to 233.65256, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 11.3046 - val_loss: 233.6526\n",
      "Epoch 58/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 12.2745\n",
      "Epoch 58: val_loss did not improve from 233.65256\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 12.0304 - val_loss: 290.6946\n",
      "Epoch 59/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 12.1886\n",
      "Epoch 59: val_loss did not improve from 233.65256\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 12.2655 - val_loss: 233.6923\n",
      "Epoch 60/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.2259\n",
      "Epoch 60: val_loss did not improve from 233.65256\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.1389 - val_loss: 245.1071\n",
      "Epoch 61/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11.1700\n",
      "Epoch 61: val_loss improved from 233.65256 to 226.98088, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 10.9563 - val_loss: 226.9809\n",
      "Epoch 62/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 10.8298\n",
      "Epoch 62: val_loss improved from 226.98088 to 223.64781, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 10.6955 - val_loss: 223.6478\n",
      "Epoch 63/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 10.7344\n",
      "Epoch 63: val_loss did not improve from 223.64781\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 10.4641 - val_loss: 226.6052\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7016 \n",
      "Epoch 64: val_loss did not improve from 223.64781\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.7016 - val_loss: 230.1413\n",
      "Epoch 65/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 25.2576\n",
      "Epoch 65: val_loss did not improve from 223.64781\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 24.3288 - val_loss: 228.1518\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.2111\n",
      "Epoch 66: val_loss did not improve from 223.64781\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 9.2111 - val_loss: 228.5427\n",
      "Epoch 67/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10.4100\n",
      "Epoch 67: val_loss improved from 223.64781 to 221.51567, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 10.1112 - val_loss: 221.5157\n",
      "Epoch 68/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.9391\n",
      "Epoch 68: val_loss did not improve from 221.51567\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 8.8783 - val_loss: 240.1761\n",
      "Epoch 69/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.7058\n",
      "Epoch 69: val_loss did not improve from 221.51567\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 9.5551 - val_loss: 242.5000\n",
      "Epoch 70/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 27.5026\n",
      "Epoch 70: val_loss did not improve from 221.51567\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 26.1657 - val_loss: 268.4392\n",
      "Epoch 71/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.5538\n",
      "Epoch 71: val_loss did not improve from 221.51567\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 8.1834 - val_loss: 254.6714\n",
      "Epoch 72/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.2654\n",
      "Epoch 72: val_loss did not improve from 221.51567\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.8968 - val_loss: 239.7411\n",
      "Epoch 73/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.2550\n",
      "Epoch 73: val_loss improved from 221.51567 to 201.64322, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 8.4391 - val_loss: 201.6432\n",
      "Epoch 74/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 8.7124\n",
      "Epoch 74: val_loss did not improve from 201.64322\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 9.1642 - val_loss: 251.0773\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.5891\n",
      "Epoch 75: val_loss improved from 201.64322 to 192.60815, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 8.5891 - val_loss: 192.6082\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.8467\n",
      "Epoch 76: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 8.8467 - val_loss: 243.0281\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.6682\n",
      "Epoch 77: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 8.6682 - val_loss: 219.3881\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.0023\n",
      "Epoch 78: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 8.0023 - val_loss: 219.7369\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.0212\n",
      "Epoch 79: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 8.0212 - val_loss: 249.9492\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.9523\n",
      "Epoch 80: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 7.9523 - val_loss: 223.6893\n",
      "Epoch 81/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.2455\n",
      "Epoch 81: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 7.1562 - val_loss: 203.8011\n",
      "Epoch 82/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.2628\n",
      "Epoch 82: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.4457 - val_loss: 192.9177\n",
      "Epoch 83/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.1396\n",
      "Epoch 83: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 8.3344 - val_loss: 194.3442\n",
      "Epoch 84/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.0878\n",
      "Epoch 84: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 15.5655 - val_loss: 206.3072\n",
      "Epoch 85/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.7686\n",
      "Epoch 85: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.8311 - val_loss: 205.0119\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.2386\n",
      "Epoch 86: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.2386 - val_loss: 204.6369\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.4346\n",
      "Epoch 87: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 7.4346 - val_loss: 220.7272\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.5402\n",
      "Epoch 88: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 6.5402 - val_loss: 208.5645\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.8614\n",
      "Epoch 89: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.8614 - val_loss: 225.9357\n",
      "Epoch 90/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.8830\n",
      "Epoch 90: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.0563 - val_loss: 227.9307\n",
      "Epoch 91/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.1715\n",
      "Epoch 91: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 7.1134 - val_loss: 235.9144\n",
      "Epoch 92/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.3482\n",
      "Epoch 92: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.2424 - val_loss: 250.7360\n",
      "Epoch 93/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.0435\n",
      "Epoch 93: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.9294 - val_loss: 212.8638\n",
      "Epoch 94/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.6731\n",
      "Epoch 94: val_loss did not improve from 192.60815\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.6690 - val_loss: 208.4092\n",
      "Epoch 95/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.0774\n",
      "Epoch 95: val_loss improved from 192.60815 to 170.03871, saving model to Best_BiLSTM_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 7.1184 - val_loss: 170.0387\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.2824\n",
      "Epoch 96: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.2824 - val_loss: 173.9240\n",
      "Epoch 97/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.7850\n",
      "Epoch 97: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 6.7490 - val_loss: 195.7262\n",
      "Epoch 98/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.2571\n",
      "Epoch 98: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 6.4229 - val_loss: 193.0606\n",
      "Epoch 99/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.6609\n",
      "Epoch 99: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 6.6449 - val_loss: 209.5420\n",
      "Epoch 100/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.9600\n",
      "Epoch 100: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 7.2478 - val_loss: 204.7762\n",
      "Epoch 101/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.0330\n",
      "Epoch 101: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.9559 - val_loss: 198.8685\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.4055\n",
      "Epoch 102: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.4055 - val_loss: 199.9714\n",
      "Epoch 103/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.3832\n",
      "Epoch 103: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 6.3092 - val_loss: 195.7269\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.0680\n",
      "Epoch 104: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 6.0680 - val_loss: 234.2563\n",
      "Epoch 105/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.7445\n",
      "Epoch 105: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 6.7007 - val_loss: 210.6858\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.6560\n",
      "Epoch 106: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.6560 - val_loss: 222.6116\n",
      "Epoch 107/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.5848\n",
      "Epoch 107: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 6.5998 - val_loss: 218.7717\n",
      "Epoch 108/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.9667\n",
      "Epoch 108: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 6.1156 - val_loss: 213.4647\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.7729\n",
      "Epoch 109: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.7729 - val_loss: 549.6285\n",
      "Epoch 110/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6255\n",
      "Epoch 110: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 6.3858 - val_loss: 258.3610\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.6133\n",
      "Epoch 111: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.6133 - val_loss: 213.2088\n",
      "Epoch 112/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.7790\n",
      "Epoch 112: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.7757 - val_loss: 181.6075\n",
      "Epoch 113/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.9618\n",
      "Epoch 113: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9294 - val_loss: 211.5660\n",
      "Epoch 114/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.6040\n",
      "Epoch 114: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 5.5665 - val_loss: 384.5628\n",
      "Epoch 115/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.6026\n",
      "Epoch 115: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.5688 - val_loss: 741.4085\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.8451\n",
      "Epoch 116: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.7981 - val_loss: 226.0779\n",
      "Epoch 117/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3242\n",
      "Epoch 117: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.2592 - val_loss: 278.6327\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4123\n",
      "Epoch 118: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.4123 - val_loss: 209.3172\n",
      "Epoch 119/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.6893\n",
      "Epoch 119: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.6060 - val_loss: 448.7550\n",
      "Epoch 120/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.5331\n",
      "Epoch 120: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.4897 - val_loss: 659.1767\n",
      "Epoch 121/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.7942\n",
      "Epoch 121: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 5.8111 - val_loss: 316.0567\n",
      "Epoch 122/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4211\n",
      "Epoch 122: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.3799 - val_loss: 249.0644\n",
      "Epoch 123/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2870\n",
      "Epoch 123: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3605 - val_loss: 374.6097\n",
      "Epoch 124/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3345\n",
      "Epoch 124: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3895 - val_loss: 534.0701\n",
      "Epoch 125/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.0900\n",
      "Epoch 125: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.1334 - val_loss: 404.9525\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.0707\n",
      "Epoch 126: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.0707 - val_loss: 224.6067\n",
      "Epoch 127/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.5938\n",
      "Epoch 127: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.6228 - val_loss: 386.5879\n",
      "Epoch 128/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.2681\n",
      "Epoch 128: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.2863 - val_loss: 529.2840\n",
      "Epoch 129/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2635\n",
      "Epoch 129: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.2197 - val_loss: 553.5372\n",
      "Epoch 130/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.6242\n",
      "Epoch 130: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.5590 - val_loss: 811.2432\n",
      "Epoch 131/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2653\n",
      "Epoch 131: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3844 - val_loss: 191.9086\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1422\n",
      "Epoch 132: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.1422 - val_loss: 723.8134\n",
      "Epoch 133/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8291\n",
      "Epoch 133: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.8783 - val_loss: 319.6517\n",
      "Epoch 134/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.4087\n",
      "Epoch 134: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.3730 - val_loss: 262.9657\n",
      "Epoch 135/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.9503\n",
      "Epoch 135: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9096 - val_loss: 657.6884\n",
      "Epoch 136/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.9782\n",
      "Epoch 136: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.1714 - val_loss: 634.8368\n",
      "Epoch 137/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0273\n",
      "Epoch 137: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.0823 - val_loss: 1097.4392\n",
      "Epoch 138/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.4482\n",
      "Epoch 138: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.5074 - val_loss: 867.0168\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.8699\n",
      "Epoch 139: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.8699 - val_loss: 175.2863\n",
      "Epoch 140/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6251\n",
      "Epoch 140: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7940 - val_loss: 178.5838\n",
      "Epoch 141/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0728\n",
      "Epoch 141: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.0812 - val_loss: 171.3943\n",
      "Epoch 142/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9012\n",
      "Epoch 142: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.0114 - val_loss: 196.5312\n",
      "Epoch 143/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5771\n",
      "Epoch 143: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.5619 - val_loss: 176.9168\n",
      "Epoch 144/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0698\n",
      "Epoch 144: val_loss did not improve from 170.03871\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.1488 - val_loss: 187.2519\n",
      "Epoch 145/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.9154\n",
      "Epoch 145: val_loss did not improve from 170.03871\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 4.8558 - val_loss: 317.5692\n",
      "Epoch 145: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "bi_lstm_rmsprop_model = TimeSeriesModel(model_type='bi_lstm', optimizer = RMSprop(learning_rate=0.001))\n",
    "# Train the model\n",
    "bi_lstm_rmsprop_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_BiLSTM_Model_RMSprop_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d727aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = bi_lstm_rmsprop_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d1804bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 13.583313460969167\n",
      "R2 Score: 0.001783585770587126\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f49cdbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'BiLSTM - RMSprop Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30150030",
   "metadata": {},
   "outputs": [],
   "source": [
    " # GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "383da222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a7b0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6302.6206\n",
      "Epoch 1: val_loss improved from inf to 21872.72070, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 5s 38ms/step - loss: 6267.0181 - val_loss: 21872.7207\n",
      "Epoch 2/1000\n",
      "11/37 [=======>......................] - ETA: 0s - loss: 4984.3457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/37 [=========================>....] - ETA: 0s - loss: 5090.0625\n",
      "Epoch 2: val_loss improved from 21872.72070 to 20496.82812, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5062.5835 - val_loss: 20496.8281\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4636.6060\n",
      "Epoch 3: val_loss improved from 20496.82812 to 19638.78906, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4636.6060 - val_loss: 19638.7891\n",
      "Epoch 4/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4295.7656\n",
      "Epoch 4: val_loss improved from 19638.78906 to 18907.04688, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4323.2646 - val_loss: 18907.0469\n",
      "Epoch 5/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4046.1238\n",
      "Epoch 5: val_loss improved from 18907.04688 to 18231.39258, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4051.4851 - val_loss: 18231.3926\n",
      "Epoch 6/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3810.5215\n",
      "Epoch 6: val_loss improved from 18231.39258 to 17598.22070, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3806.6230 - val_loss: 17598.2207\n",
      "Epoch 7/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3589.2742\n",
      "Epoch 7: val_loss improved from 17598.22070 to 17007.63672, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3582.8896 - val_loss: 17007.6367\n",
      "Epoch 8/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3442.2051\n",
      "Epoch 8: val_loss improved from 17007.63672 to 16439.72070, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3379.3513 - val_loss: 16439.7207\n",
      "Epoch 9/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3193.8684\n",
      "Epoch 9: val_loss improved from 16439.72070 to 15909.68750, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3190.3342 - val_loss: 15909.6875\n",
      "Epoch 10/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3045.9182\n",
      "Epoch 10: val_loss improved from 15909.68750 to 15398.43848, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3017.8311 - val_loss: 15398.4385\n",
      "Epoch 11/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2839.4177\n",
      "Epoch 11: val_loss improved from 15398.43848 to 14917.23535, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2858.2190 - val_loss: 14917.2354\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2712.2222\n",
      "Epoch 12: val_loss improved from 14917.23535 to 14454.49316, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2712.2222 - val_loss: 14454.4932\n",
      "Epoch 13/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2559.4089\n",
      "Epoch 13: val_loss improved from 14454.49316 to 14011.72168, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2578.2104 - val_loss: 14011.7217\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2454.2651\n",
      "Epoch 14: val_loss improved from 14011.72168 to 13599.02344, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2454.2651 - val_loss: 13599.0234\n",
      "Epoch 15/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2352.4666\n",
      "Epoch 15: val_loss improved from 13599.02344 to 13197.63574, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2341.9409 - val_loss: 13197.6357\n",
      "Epoch 16/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2201.6733\n",
      "Epoch 16: val_loss improved from 13197.63574 to 12822.45605, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2238.3582 - val_loss: 12822.4561\n",
      "Epoch 17/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2143.8333\n",
      "Epoch 17: val_loss improved from 12822.45605 to 12454.77441, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2145.0085 - val_loss: 12454.7744\n",
      "Epoch 18/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2041.9299\n",
      "Epoch 18: val_loss improved from 12454.77441 to 12116.53613, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2058.6809 - val_loss: 12116.5361\n",
      "Epoch 19/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1971.1477\n",
      "Epoch 19: val_loss improved from 12116.53613 to 11784.33496, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1981.8402 - val_loss: 11784.3350\n",
      "Epoch 20/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1877.9475\n",
      "Epoch 20: val_loss improved from 11784.33496 to 11475.96387, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1911.1747 - val_loss: 11475.9639\n",
      "Epoch 21/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1839.0621\n",
      "Epoch 21: val_loss improved from 11475.96387 to 11185.74023, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1847.6227 - val_loss: 11185.7402\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1790.5460\n",
      "Epoch 22: val_loss improved from 11185.74023 to 10911.36719, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1790.5460 - val_loss: 10911.3672\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1738.9999\n",
      "Epoch 23: val_loss improved from 10911.36719 to 10653.00781, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1738.9999 - val_loss: 10653.0078\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1693.3429\n",
      "Epoch 24: val_loss improved from 10653.00781 to 10398.54590, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1693.3429 - val_loss: 10398.5459\n",
      "Epoch 25/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1669.3870\n",
      "Epoch 25: val_loss improved from 10398.54590 to 10164.03418, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1652.0549 - val_loss: 10164.0342\n",
      "Epoch 26/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1575.3782\n",
      "Epoch 26: val_loss improved from 10164.03418 to 9947.05371, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1615.3551 - val_loss: 9947.0537\n",
      "Epoch 27/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1608.2632\n",
      "Epoch 27: val_loss improved from 9947.05371 to 9731.24707, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1583.3677 - val_loss: 9731.2471\n",
      "Epoch 28/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1557.5166\n",
      "Epoch 28: val_loss improved from 9731.24707 to 9539.64258, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1554.4583 - val_loss: 9539.6426\n",
      "Epoch 29/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1535.6431\n",
      "Epoch 29: val_loss improved from 9539.64258 to 9355.44824, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1529.5050 - val_loss: 9355.4482\n",
      "Epoch 30/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1508.6073\n",
      "Epoch 30: val_loss improved from 9355.44824 to 9185.03027, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1507.2822 - val_loss: 9185.0303\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1487.7979\n",
      "Epoch 31: val_loss improved from 9185.03027 to 9030.12305, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1487.7979 - val_loss: 9030.1230\n",
      "Epoch 32/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1472.6510\n",
      "Epoch 32: val_loss improved from 9030.12305 to 8877.52441, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1471.0830 - val_loss: 8877.5244\n",
      "Epoch 33/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1455.9613\n",
      "Epoch 33: val_loss improved from 8877.52441 to 8731.71387, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1456.5759 - val_loss: 8731.7139\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1443.6150\n",
      "Epoch 34: val_loss improved from 8731.71387 to 8605.87207, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1443.6150 - val_loss: 8605.8721\n",
      "Epoch 35/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1435.4716\n",
      "Epoch 35: val_loss improved from 8605.87207 to 8474.19336, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1433.0908 - val_loss: 8474.1934\n",
      "Epoch 36/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1424.0123\n",
      "Epoch 36: val_loss improved from 8474.19336 to 8364.17383, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1423.4161 - val_loss: 8364.1738\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1415.4692\n",
      "Epoch 37: val_loss improved from 8364.17383 to 8262.25977, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1415.4692 - val_loss: 8262.2598\n",
      "Epoch 38/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1425.1437\n",
      "Epoch 38: val_loss improved from 8262.25977 to 8160.69873, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1408.9143 - val_loss: 8160.6987\n",
      "Epoch 39/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1413.9897\n",
      "Epoch 39: val_loss improved from 8160.69873 to 8074.12109, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1402.9623 - val_loss: 8074.1211\n",
      "Epoch 40/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1392.3016\n",
      "Epoch 40: val_loss improved from 8074.12109 to 7992.07471, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1398.1166 - val_loss: 7992.0747\n",
      "Epoch 41/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1391.6069\n",
      "Epoch 41: val_loss improved from 7992.07471 to 7909.29395, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 1394.3208 - val_loss: 7909.2939\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1390.6567\n",
      "Epoch 42: val_loss improved from 7909.29395 to 7850.07617, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 1390.6567 - val_loss: 7850.0762\n",
      "Epoch 43/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1405.9985\n",
      "Epoch 43: val_loss improved from 7850.07617 to 7779.96924, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1387.8732 - val_loss: 7779.9692\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1385.5742\n",
      "Epoch 44: val_loss improved from 7779.96924 to 7718.28711, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1385.5742 - val_loss: 7718.2871\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1383.7914\n",
      "Epoch 45: val_loss improved from 7718.28711 to 7657.31104, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1383.7914 - val_loss: 7657.3110\n",
      "Epoch 46/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1378.1206\n",
      "Epoch 46: val_loss improved from 7657.31104 to 7620.67139, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1382.0028 - val_loss: 7620.6714\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1380.9979\n",
      "Epoch 47: val_loss improved from 7620.67139 to 7567.58105, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1380.9979 - val_loss: 7567.5811\n",
      "Epoch 48/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1369.0203\n",
      "Epoch 48: val_loss improved from 7567.58105 to 7543.30957, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1379.8119 - val_loss: 7543.3096\n",
      "Epoch 49/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1373.7084\n",
      "Epoch 49: val_loss improved from 7543.30957 to 7497.20605, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1379.0541 - val_loss: 7497.2061\n",
      "Epoch 50/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1377.3295\n",
      "Epoch 50: val_loss improved from 7497.20605 to 7468.23340, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1378.2812 - val_loss: 7468.2334\n",
      "Epoch 51/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1368.5090\n",
      "Epoch 51: val_loss improved from 7468.23340 to 7439.94287, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1377.7074 - val_loss: 7439.9429\n",
      "Epoch 52/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1380.4388\n",
      "Epoch 52: val_loss improved from 7439.94287 to 7402.92041, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1377.3357 - val_loss: 7402.9204\n",
      "Epoch 53/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1367.2007\n",
      "Epoch 53: val_loss improved from 7402.92041 to 7391.74414, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1376.8666 - val_loss: 7391.7441\n",
      "Epoch 54/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1356.0200\n",
      "Epoch 54: val_loss improved from 7391.74414 to 7376.16309, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1376.6083 - val_loss: 7376.1631\n",
      "Epoch 55/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1396.4103\n",
      "Epoch 55: val_loss did not improve from 7376.16309\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1373.0288 - val_loss: 7394.8120\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1361.0131\n",
      "Epoch 56: val_loss did not improve from 7376.16309\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1361.0131 - val_loss: 7384.2583\n",
      "Epoch 57/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1333.1279\n",
      "Epoch 57: val_loss did not improve from 7376.16309\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1334.3185 - val_loss: 7381.5273\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1227.0231\n",
      "Epoch 58: val_loss improved from 7376.16309 to 7241.54541, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1227.0231 - val_loss: 7241.5454\n",
      "Epoch 59/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1017.0305\n",
      "Epoch 59: val_loss improved from 7241.54541 to 6920.12646, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 993.8271 - val_loss: 6920.1265\n",
      "Epoch 60/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1405.7693\n",
      "Epoch 60: val_loss did not improve from 6920.12646\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1408.1084 - val_loss: 7162.9858\n",
      "Epoch 61/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1161.6411\n",
      "Epoch 61: val_loss improved from 6920.12646 to 6741.13330, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1158.9508 - val_loss: 6741.1333\n",
      "Epoch 62/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 872.8507\n",
      "Epoch 62: val_loss improved from 6741.13330 to 6206.83740, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 872.7365 - val_loss: 6206.8374\n",
      "Epoch 63/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 715.4031\n",
      "Epoch 63: val_loss improved from 6206.83740 to 5908.19727, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 730.5162 - val_loss: 5908.1973\n",
      "Epoch 64/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 660.3091\n",
      "Epoch 64: val_loss improved from 5908.19727 to 5626.12646, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 675.4958 - val_loss: 5626.1265\n",
      "Epoch 65/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 621.5926\n",
      "Epoch 65: val_loss improved from 5626.12646 to 5351.05029, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 625.7911 - val_loss: 5351.0503\n",
      "Epoch 66/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 594.5745\n",
      "Epoch 66: val_loss improved from 5351.05029 to 5099.35059, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 581.3018 - val_loss: 5099.3506\n",
      "Epoch 67/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 540.5720\n",
      "Epoch 67: val_loss improved from 5099.35059 to 4871.78857, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 539.9368 - val_loss: 4871.7886\n",
      "Epoch 68/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 519.0354\n",
      "Epoch 68: val_loss improved from 4871.78857 to 4632.02979, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 503.4991 - val_loss: 4632.0298\n",
      "Epoch 69/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 467.4427\n",
      "Epoch 69: val_loss improved from 4632.02979 to 4433.81348, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 466.5197 - val_loss: 4433.8135\n",
      "Epoch 70/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 431.2693\n",
      "Epoch 70: val_loss improved from 4433.81348 to 4235.25391, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 432.9199 - val_loss: 4235.2539\n",
      "Epoch 71/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 414.8665\n",
      "Epoch 71: val_loss improved from 4235.25391 to 4044.15015, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 401.6626 - val_loss: 4044.1501\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 373.1223\n",
      "Epoch 72: val_loss improved from 4044.15015 to 3860.68579, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 373.1223 - val_loss: 3860.6858\n",
      "Epoch 73/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 341.9522\n",
      "Epoch 73: val_loss improved from 3860.68579 to 3689.99219, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 347.1328 - val_loss: 3689.9922\n",
      "Epoch 74/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 318.9783\n",
      "Epoch 74: val_loss improved from 3689.99219 to 3527.80298, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 321.1462 - val_loss: 3527.8030\n",
      "Epoch 75/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 303.0395\n",
      "Epoch 75: val_loss improved from 3527.80298 to 3370.12329, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 298.4043 - val_loss: 3370.1233\n",
      "Epoch 76/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 280.0288\n",
      "Epoch 76: val_loss improved from 3370.12329 to 3228.85498, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 277.8106 - val_loss: 3228.8550\n",
      "Epoch 77/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 257.0187\n",
      "Epoch 77: val_loss improved from 3228.85498 to 3092.56714, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 258.0041 - val_loss: 3092.5671\n",
      "Epoch 78/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 239.9579\n",
      "Epoch 78: val_loss improved from 3092.56714 to 2961.74585, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 238.8932 - val_loss: 2961.7458\n",
      "Epoch 79/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 222.7842\n",
      "Epoch 79: val_loss improved from 2961.74585 to 2839.15698, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 222.1929 - val_loss: 2839.1570\n",
      "Epoch 80/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 197.3289\n",
      "Epoch 80: val_loss improved from 2839.15698 to 2727.69336, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 206.3974 - val_loss: 2727.6934\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 192.1450\n",
      "Epoch 81: val_loss improved from 2727.69336 to 2613.42358, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 192.1450 - val_loss: 2613.4236\n",
      "Epoch 82/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 174.5215\n",
      "Epoch 82: val_loss improved from 2613.42358 to 2514.75122, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 179.0239 - val_loss: 2514.7512\n",
      "Epoch 83/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 165.5958\n",
      "Epoch 83: val_loss improved from 2514.75122 to 2412.23462, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 166.9030 - val_loss: 2412.2346\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 155.3418\n",
      "Epoch 84: val_loss improved from 2412.23462 to 2319.67090, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 155.3418 - val_loss: 2319.6709\n",
      "Epoch 85/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 148.2158\n",
      "Epoch 85: val_loss improved from 2319.67090 to 2227.59082, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 145.0360 - val_loss: 2227.5908\n",
      "Epoch 86/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 132.3035\n",
      "Epoch 86: val_loss improved from 2227.59082 to 2143.78149, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 135.1907 - val_loss: 2143.7815\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 134.3808\n",
      "Epoch 87: val_loss improved from 2143.78149 to 2060.53320, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 134.3808 - val_loss: 2060.5332\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 117.7827\n",
      "Epoch 88: val_loss improved from 2060.53320 to 1984.47864, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 117.7827 - val_loss: 1984.4786\n",
      "Epoch 89/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 109.4586\n",
      "Epoch 89: val_loss improved from 1984.47864 to 1913.25623, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 108.5749 - val_loss: 1913.2562\n",
      "Epoch 90/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 106.7586\n",
      "Epoch 90: val_loss improved from 1913.25623 to 1846.30273, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 105.3981 - val_loss: 1846.3027\n",
      "Epoch 91/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 99.9576\n",
      "Epoch 91: val_loss improved from 1846.30273 to 1789.12878, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 98.3032 - val_loss: 1789.1288\n",
      "Epoch 92/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 96.3811\n",
      "Epoch 92: val_loss improved from 1789.12878 to 1722.15674, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 95.9305 - val_loss: 1722.1567\n",
      "Epoch 93/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 88.5077\n",
      "Epoch 93: val_loss improved from 1722.15674 to 1666.16992, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 86.6449 - val_loss: 1666.1699\n",
      "Epoch 94/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 79.0498\n",
      "Epoch 94: val_loss improved from 1666.16992 to 1614.24084, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 79.7963 - val_loss: 1614.2408\n",
      "Epoch 95/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 75.6059\n",
      "Epoch 95: val_loss improved from 1614.24084 to 1557.13965, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 74.6312 - val_loss: 1557.1396\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 74.4894\n",
      "Epoch 96: val_loss improved from 1557.13965 to 1510.72180, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 74.4894 - val_loss: 1510.7218\n",
      "Epoch 97/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 67.2377\n",
      "Epoch 97: val_loss improved from 1510.72180 to 1470.06287, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 69.0506 - val_loss: 1470.0629\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 63.7810\n",
      "Epoch 98: val_loss improved from 1470.06287 to 1420.37292, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 63.7810 - val_loss: 1420.3729\n",
      "Epoch 99/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 61.2248\n",
      "Epoch 99: val_loss improved from 1420.37292 to 1381.95959, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 61.6637 - val_loss: 1381.9596\n",
      "Epoch 100/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 57.6350\n",
      "Epoch 100: val_loss improved from 1381.95959 to 1338.96533, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 57.7271 - val_loss: 1338.9653\n",
      "Epoch 101/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 56.0817\n",
      "Epoch 101: val_loss improved from 1338.96533 to 1300.38953, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 55.7031 - val_loss: 1300.3895\n",
      "Epoch 102/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 53.3026\n",
      "Epoch 102: val_loss improved from 1300.38953 to 1265.24902, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 52.5394 - val_loss: 1265.2490\n",
      "Epoch 103/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 50.5285\n",
      "Epoch 103: val_loss improved from 1265.24902 to 1235.22656, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 50.7681 - val_loss: 1235.2266\n",
      "Epoch 104/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 48.9104\n",
      "Epoch 104: val_loss improved from 1235.22656 to 1202.09277, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 48.8161 - val_loss: 1202.0928\n",
      "Epoch 105/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 47.7388\n",
      "Epoch 105: val_loss improved from 1202.09277 to 1171.53772, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 47.0385 - val_loss: 1171.5377\n",
      "Epoch 106/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 44.5410\n",
      "Epoch 106: val_loss improved from 1171.53772 to 1143.99390, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 45.6665 - val_loss: 1143.9939\n",
      "Epoch 107/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 43.4212\n",
      "Epoch 107: val_loss improved from 1143.99390 to 1119.04004, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 43.9226 - val_loss: 1119.0400\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 42.5730\n",
      "Epoch 108: val_loss improved from 1119.04004 to 1094.80090, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 42.5730 - val_loss: 1094.8009\n",
      "Epoch 109/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 39.4925\n",
      "Epoch 109: val_loss improved from 1094.80090 to 1071.17920, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 41.5729 - val_loss: 1071.1792\n",
      "Epoch 110/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 40.3220\n",
      "Epoch 110: val_loss improved from 1071.17920 to 1050.62402, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 41.1188 - val_loss: 1050.6240\n",
      "Epoch 111/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 39.5343\n",
      "Epoch 111: val_loss improved from 1050.62402 to 1029.11731, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 40.1063 - val_loss: 1029.1173\n",
      "Epoch 112/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 41.0404\n",
      "Epoch 112: val_loss improved from 1029.11731 to 1011.72162, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 38.9746 - val_loss: 1011.7216\n",
      "Epoch 113/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 36.3430\n",
      "Epoch 113: val_loss improved from 1011.72162 to 1008.65399, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 37.3544 - val_loss: 1008.6540\n",
      "Epoch 114/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 34.4842\n",
      "Epoch 114: val_loss improved from 1008.65399 to 971.07593, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 34.0406 - val_loss: 971.0759\n",
      "Epoch 115/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 31.5851\n",
      "Epoch 115: val_loss improved from 971.07593 to 948.64490, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 31.9549 - val_loss: 948.6449\n",
      "Epoch 116/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 32.4442\n",
      "Epoch 116: val_loss improved from 948.64490 to 913.89423, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 32.0195 - val_loss: 913.8942\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 30.8084\n",
      "Epoch 117: val_loss improved from 913.89423 to 899.09149, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 30.8084 - val_loss: 899.0915\n",
      "Epoch 118/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 27.3602\n",
      "Epoch 118: val_loss improved from 899.09149 to 875.70490, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 28.3466 - val_loss: 875.7049\n",
      "Epoch 119/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 27.1532\n",
      "Epoch 119: val_loss improved from 875.70490 to 852.62042, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 27.1369 - val_loss: 852.6204\n",
      "Epoch 120/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 27.1578\n",
      "Epoch 120: val_loss improved from 852.62042 to 835.20105, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 26.5349 - val_loss: 835.2010\n",
      "Epoch 121/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 26.0266\n",
      "Epoch 121: val_loss improved from 835.20105 to 814.42914, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 25.7451 - val_loss: 814.4291\n",
      "Epoch 122/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 24.7078\n",
      "Epoch 122: val_loss improved from 814.42914 to 795.38477, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 24.8176 - val_loss: 795.3848\n",
      "Epoch 123/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 23.4502\n",
      "Epoch 123: val_loss improved from 795.38477 to 777.76068, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 23.8535 - val_loss: 777.7607\n",
      "Epoch 124/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 23.4969\n",
      "Epoch 124: val_loss improved from 777.76068 to 761.96558, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 23.6039 - val_loss: 761.9656\n",
      "Epoch 125/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 20.9163\n",
      "Epoch 125: val_loss improved from 761.96558 to 741.84857, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 21.8175 - val_loss: 741.8486\n",
      "Epoch 126/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 21.4544\n",
      "Epoch 126: val_loss improved from 741.84857 to 731.53290, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 21.7952 - val_loss: 731.5329\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 20.7381\n",
      "Epoch 127: val_loss improved from 731.53290 to 710.82166, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 20.7381 - val_loss: 710.8217\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 20.0613\n",
      "Epoch 128: val_loss improved from 710.82166 to 697.59766, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 20.0613 - val_loss: 697.5977\n",
      "Epoch 129/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 19.2562\n",
      "Epoch 129: val_loss improved from 697.59766 to 681.75732, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 19.3731 - val_loss: 681.7573\n",
      "Epoch 130/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 19.1810\n",
      "Epoch 130: val_loss improved from 681.75732 to 668.46582, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 19.0523 - val_loss: 668.4658\n",
      "Epoch 131/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 18.8852\n",
      "Epoch 131: val_loss improved from 668.46582 to 655.38129, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 18.8309 - val_loss: 655.3813\n",
      "Epoch 132/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 18.1389\n",
      "Epoch 132: val_loss improved from 655.38129 to 639.23291, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 17.6615 - val_loss: 639.2329\n",
      "Epoch 133/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 17.5397\n",
      "Epoch 133: val_loss improved from 639.23291 to 624.62549, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 17.2770 - val_loss: 624.6255\n",
      "Epoch 134/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 16.7698\n",
      "Epoch 134: val_loss improved from 624.62549 to 611.61609, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 16.3893 - val_loss: 611.6161\n",
      "Epoch 135/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 16.3587\n",
      "Epoch 135: val_loss improved from 611.61609 to 598.33484, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 16.1155 - val_loss: 598.3348\n",
      "Epoch 136/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 16.2148\n",
      "Epoch 136: val_loss improved from 598.33484 to 584.15271, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 16.2255 - val_loss: 584.1527\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 15.4181\n",
      "Epoch 137: val_loss improved from 584.15271 to 576.75562, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 15.4181 - val_loss: 576.7556\n",
      "Epoch 138/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.8754\n",
      "Epoch 138: val_loss improved from 576.75562 to 565.03870, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 14.7878 - val_loss: 565.0387\n",
      "Epoch 139/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14.3208\n",
      "Epoch 139: val_loss improved from 565.03870 to 550.20947, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 14.2200 - val_loss: 550.2095\n",
      "Epoch 140/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 14.0362\n",
      "Epoch 140: val_loss improved from 550.20947 to 541.26373, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 13.9734 - val_loss: 541.2637\n",
      "Epoch 141/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 13.9269\n",
      "Epoch 141: val_loss improved from 541.26373 to 528.05505, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 13.5210 - val_loss: 528.0551\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.9793\n",
      "Epoch 142: val_loss improved from 528.05505 to 516.96893, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 12.9793 - val_loss: 516.9689\n",
      "Epoch 143/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 12.3180\n",
      "Epoch 143: val_loss improved from 516.96893 to 505.08228, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 12.3286 - val_loss: 505.0823\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.3148\n",
      "Epoch 144: val_loss improved from 505.08228 to 493.29254, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 12.3148 - val_loss: 493.2925\n",
      "Epoch 145/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13.0864\n",
      "Epoch 145: val_loss improved from 493.29254 to 485.01019, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 12.7808 - val_loss: 485.0102\n",
      "Epoch 146/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11.9113\n",
      "Epoch 146: val_loss improved from 485.01019 to 472.13937, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 11.7775 - val_loss: 472.1394\n",
      "Epoch 147/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11.4868\n",
      "Epoch 147: val_loss improved from 472.13937 to 464.22650, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 11.3346 - val_loss: 464.2265\n",
      "Epoch 148/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11.1653\n",
      "Epoch 148: val_loss improved from 464.22650 to 453.27167, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.0399 - val_loss: 453.2717\n",
      "Epoch 149/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10.6903\n",
      "Epoch 149: val_loss improved from 453.27167 to 451.44183, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.5853 - val_loss: 451.4418\n",
      "Epoch 150/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 10.2416\n",
      "Epoch 150: val_loss improved from 451.44183 to 436.71838, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.1695 - val_loss: 436.7184\n",
      "Epoch 151/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 10.3209\n",
      "Epoch 151: val_loss improved from 436.71838 to 428.59174, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.9813 - val_loss: 428.5917\n",
      "Epoch 152/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.6824\n",
      "Epoch 152: val_loss improved from 428.59174 to 417.71896, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.5080 - val_loss: 417.7190\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.0420\n",
      "Epoch 153: val_loss improved from 417.71896 to 409.25009, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 9.0420 - val_loss: 409.2501\n",
      "Epoch 154/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 9.0728\n",
      "Epoch 154: val_loss improved from 409.25009 to 402.76370, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.9760 - val_loss: 402.7637\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.5595\n",
      "Epoch 155: val_loss improved from 402.76370 to 392.56308, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.5595 - val_loss: 392.5631\n",
      "Epoch 156/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 9.0951\n",
      "Epoch 156: val_loss improved from 392.56308 to 384.75153, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 8.8359 - val_loss: 384.7515\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.3405\n",
      "Epoch 157: val_loss improved from 384.75153 to 375.60254, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 8.3405 - val_loss: 375.6025\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.3834\n",
      "Epoch 158: val_loss improved from 375.60254 to 368.64117, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 8.3834 - val_loss: 368.6412\n",
      "Epoch 159/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.8329\n",
      "Epoch 159: val_loss improved from 368.64117 to 361.62888, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 7.8527 - val_loss: 361.6289\n",
      "Epoch 160/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 8.0091\n",
      "Epoch 160: val_loss improved from 361.62888 to 352.40814, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 7.5726 - val_loss: 352.4081\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 7.1695\n",
      "Epoch 161: val_loss improved from 352.40814 to 346.59589, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 7.1695 - val_loss: 346.5959\n",
      "Epoch 162/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 7.1576\n",
      "Epoch 162: val_loss did not improve from 346.59589\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.1121 - val_loss: 350.6465\n",
      "Epoch 163/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.8464\n",
      "Epoch 163: val_loss improved from 346.59589 to 337.84235, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.8068 - val_loss: 337.8423\n",
      "Epoch 164/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.8094\n",
      "Epoch 164: val_loss improved from 337.84235 to 330.16034, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.7561 - val_loss: 330.1603\n",
      "Epoch 165/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.6371\n",
      "Epoch 165: val_loss improved from 330.16034 to 322.78586, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.6136 - val_loss: 322.7859\n",
      "Epoch 166/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.9059\n",
      "Epoch 166: val_loss improved from 322.78586 to 319.03030, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 6.8106 - val_loss: 319.0303\n",
      "Epoch 167/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1562\n",
      "Epoch 167: val_loss improved from 319.03030 to 311.63892, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.2392 - val_loss: 311.6389\n",
      "Epoch 168/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 5.7678\n",
      "Epoch 168: val_loss improved from 311.63892 to 306.96820, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.9230 - val_loss: 306.9682\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.8904\n",
      "Epoch 169: val_loss improved from 306.96820 to 302.92575, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.8904 - val_loss: 302.9258\n",
      "Epoch 170/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7209\n",
      "Epoch 170: val_loss improved from 302.92575 to 301.40176, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.8781 - val_loss: 301.4018\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.9554\n",
      "Epoch 171: val_loss improved from 301.40176 to 297.17096, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.9554 - val_loss: 297.1710\n",
      "Epoch 172/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.4909\n",
      "Epoch 172: val_loss improved from 297.17096 to 288.16879, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.7221 - val_loss: 288.1688\n",
      "Epoch 173/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8857\n",
      "Epoch 173: val_loss improved from 288.16879 to 284.12695, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.9709 - val_loss: 284.1270\n",
      "Epoch 174/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.7874\n",
      "Epoch 174: val_loss improved from 284.12695 to 279.58670, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.6573 - val_loss: 279.5867\n",
      "Epoch 175/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.8803\n",
      "Epoch 175: val_loss improved from 279.58670 to 276.02426, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.8192 - val_loss: 276.0243\n",
      "Epoch 176/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.2069\n",
      "Epoch 176: val_loss improved from 276.02426 to 271.87338, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.2531 - val_loss: 271.8734\n",
      "Epoch 177/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.2239\n",
      "Epoch 177: val_loss improved from 271.87338 to 268.26160, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.2335 - val_loss: 268.2616\n",
      "Epoch 178/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1819\n",
      "Epoch 178: val_loss did not improve from 268.26160\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.4425 - val_loss: 268.5685\n",
      "Epoch 179/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8906\n",
      "Epoch 179: val_loss improved from 268.26160 to 262.70648, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.9631 - val_loss: 262.7065\n",
      "Epoch 180/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.9038\n",
      "Epoch 180: val_loss improved from 262.70648 to 258.94846, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.8699 - val_loss: 258.9485\n",
      "Epoch 181/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1122\n",
      "Epoch 181: val_loss improved from 258.94846 to 256.63828, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.9519 - val_loss: 256.6383\n",
      "Epoch 182/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.2188\n",
      "Epoch 182: val_loss did not improve from 256.63828\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.3914 - val_loss: 263.6995\n",
      "Epoch 183/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.1926\n",
      "Epoch 183: val_loss improved from 256.63828 to 250.28073, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.1053 - val_loss: 250.2807\n",
      "Epoch 184/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.5964\n",
      "Epoch 184: val_loss improved from 250.28073 to 247.99553, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.5608 - val_loss: 247.9955\n",
      "Epoch 185/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0063\n",
      "Epoch 185: val_loss improved from 247.99553 to 246.23926, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.8569 - val_loss: 246.2393\n",
      "Epoch 186/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.0345\n",
      "Epoch 186: val_loss improved from 246.23926 to 246.22847, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.9615 - val_loss: 246.2285\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.8731\n",
      "Epoch 187: val_loss improved from 246.22847 to 241.63933, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.8731 - val_loss: 241.6393\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.4898\n",
      "Epoch 188: val_loss did not improve from 241.63933\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.4898 - val_loss: 253.1040\n",
      "Epoch 189/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.2365\n",
      "Epoch 189: val_loss improved from 241.63933 to 236.49568, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.1851 - val_loss: 236.4957\n",
      "Epoch 190/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1168\n",
      "Epoch 190: val_loss improved from 236.49568 to 234.72388, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 5.1392 - val_loss: 234.7239\n",
      "Epoch 191/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.6160\n",
      "Epoch 191: val_loss improved from 234.72388 to 233.89699, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.7053 - val_loss: 233.8970\n",
      "Epoch 192/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5137\n",
      "Epoch 192: val_loss improved from 233.89699 to 231.05339, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.5044 - val_loss: 231.0534\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.7044\n",
      "Epoch 193: val_loss improved from 231.05339 to 229.43694, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7044 - val_loss: 229.4369\n",
      "Epoch 194/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.8062\n",
      "Epoch 194: val_loss improved from 229.43694 to 228.38069, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.6983 - val_loss: 228.3807\n",
      "Epoch 195/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.4454\n",
      "Epoch 195: val_loss improved from 228.38069 to 227.19171, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3804 - val_loss: 227.1917\n",
      "Epoch 196/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.6658\n",
      "Epoch 196: val_loss improved from 227.19171 to 226.25038, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.6130 - val_loss: 226.2504\n",
      "Epoch 197/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4718\n",
      "Epoch 197: val_loss improved from 226.25038 to 224.96187, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.4390 - val_loss: 224.9619\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.3338\n",
      "Epoch 198: val_loss improved from 224.96187 to 224.31076, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3338 - val_loss: 224.3108\n",
      "Epoch 199/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0574\n",
      "Epoch 199: val_loss improved from 224.31076 to 223.00804, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1818 - val_loss: 223.0080\n",
      "Epoch 200/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.4306\n",
      "Epoch 200: val_loss improved from 223.00804 to 222.24733, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.4233 - val_loss: 222.2473\n",
      "Epoch 201/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.7170\n",
      "Epoch 201: val_loss improved from 222.24733 to 221.17447, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5766 - val_loss: 221.1745\n",
      "Epoch 202/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.7829\n",
      "Epoch 202: val_loss improved from 221.17447 to 220.20248, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.6902 - val_loss: 220.2025\n",
      "Epoch 203/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5893\n",
      "Epoch 203: val_loss improved from 220.20248 to 218.87987, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.6374 - val_loss: 218.8799\n",
      "Epoch 204/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.9159\n",
      "Epoch 204: val_loss improved from 218.87987 to 217.26350, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.0506 - val_loss: 217.2635\n",
      "Epoch 205/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.3977\n",
      "Epoch 205: val_loss improved from 217.26350 to 216.08752, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3373 - val_loss: 216.0875\n",
      "Epoch 206/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.5736\n",
      "Epoch 206: val_loss did not improve from 216.08752\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4.6188 - val_loss: 216.2176\n",
      "Epoch 207/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6582\n",
      "Epoch 207: val_loss improved from 216.08752 to 214.95760, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.6161 - val_loss: 214.9576\n",
      "Epoch 208/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0739\n",
      "Epoch 208: val_loss improved from 214.95760 to 214.21571, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1655 - val_loss: 214.2157\n",
      "Epoch 209/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.3935\n",
      "Epoch 209: val_loss improved from 214.21571 to 212.42998, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3395 - val_loss: 212.4300\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1956\n",
      "Epoch 210: val_loss improved from 212.42998 to 212.41292, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1956 - val_loss: 212.4129\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1207\n",
      "Epoch 211: val_loss improved from 212.41292 to 211.39177, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1207 - val_loss: 211.3918\n",
      "Epoch 212/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.5312\n",
      "Epoch 212: val_loss did not improve from 211.39177\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5209 - val_loss: 211.5269\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5735\n",
      "Epoch 213: val_loss improved from 211.39177 to 207.60069, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.5735 - val_loss: 207.6007\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.2511\n",
      "Epoch 214: val_loss improved from 207.60069 to 206.74376, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.2511 - val_loss: 206.7438\n",
      "Epoch 215/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.5534\n",
      "Epoch 215: val_loss improved from 206.74376 to 205.98431, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3722 - val_loss: 205.9843\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.2505\n",
      "Epoch 216: val_loss did not improve from 205.98431\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2505 - val_loss: 206.3994\n",
      "Epoch 217/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.2922\n",
      "Epoch 217: val_loss improved from 205.98431 to 204.69179, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3519 - val_loss: 204.6918\n",
      "Epoch 218/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1144\n",
      "Epoch 218: val_loss improved from 204.69179 to 203.72662, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.0959 - val_loss: 203.7266\n",
      "Epoch 219/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1548\n",
      "Epoch 219: val_loss did not improve from 203.72662\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1199 - val_loss: 205.0487\n",
      "Epoch 220/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.2807\n",
      "Epoch 220: val_loss improved from 203.72662 to 202.65886, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.3418 - val_loss: 202.6589\n",
      "Epoch 221/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0450\n",
      "Epoch 221: val_loss improved from 202.65886 to 200.90833, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.0721 - val_loss: 200.9083\n",
      "Epoch 222/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8370\n",
      "Epoch 222: val_loss did not improve from 200.90833\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8801 - val_loss: 203.2418\n",
      "Epoch 223/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0860\n",
      "Epoch 223: val_loss improved from 200.90833 to 199.16469, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.0312 - val_loss: 199.1647\n",
      "Epoch 224/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9707\n",
      "Epoch 224: val_loss improved from 199.16469 to 198.20233, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9598 - val_loss: 198.2023\n",
      "Epoch 225/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.2857\n",
      "Epoch 225: val_loss improved from 198.20233 to 197.18896, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.2910 - val_loss: 197.1890\n",
      "Epoch 226/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.0955\n",
      "Epoch 226: val_loss improved from 197.18896 to 196.15970, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0849 - val_loss: 196.1597\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1697\n",
      "Epoch 227: val_loss improved from 196.15970 to 195.30858, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1697 - val_loss: 195.3086\n",
      "Epoch 228/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1547\n",
      "Epoch 228: val_loss improved from 195.30858 to 193.04156, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0618 - val_loss: 193.0416\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9435\n",
      "Epoch 229: val_loss improved from 193.04156 to 191.86674, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9435 - val_loss: 191.8667\n",
      "Epoch 230/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8303\n",
      "Epoch 230: val_loss improved from 191.86674 to 190.95831, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8640 - val_loss: 190.9583\n",
      "Epoch 231/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9278\n",
      "Epoch 231: val_loss improved from 190.95831 to 189.53178, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.9441 - val_loss: 189.5318\n",
      "Epoch 232/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.7615\n",
      "Epoch 232: val_loss did not improve from 189.53178\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8727 - val_loss: 189.7172\n",
      "Epoch 233/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0947\n",
      "Epoch 233: val_loss improved from 189.53178 to 187.71353, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9946 - val_loss: 187.7135\n",
      "Epoch 234/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9830\n",
      "Epoch 234: val_loss improved from 187.71353 to 187.08829, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8469 - val_loss: 187.0883\n",
      "Epoch 235/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4393\n",
      "Epoch 235: val_loss did not improve from 187.08829\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.4556 - val_loss: 188.1690\n",
      "Epoch 236/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9969\n",
      "Epoch 236: val_loss improved from 187.08829 to 185.09023, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9331 - val_loss: 185.0902\n",
      "Epoch 237/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.7589\n",
      "Epoch 237: val_loss did not improve from 185.09023\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.8425 - val_loss: 186.0512\n",
      "Epoch 238/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7138\n",
      "Epoch 238: val_loss improved from 185.09023 to 182.00958, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6785 - val_loss: 182.0096\n",
      "Epoch 239/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9075\n",
      "Epoch 239: val_loss did not improve from 182.00958\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.8448 - val_loss: 182.0992\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7317\n",
      "Epoch 240: val_loss improved from 182.00958 to 181.17776, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7317 - val_loss: 181.1778\n",
      "Epoch 241/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8795\n",
      "Epoch 241: val_loss improved from 181.17776 to 179.22580, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.8895 - val_loss: 179.2258\n",
      "Epoch 242/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7210\n",
      "Epoch 242: val_loss improved from 179.22580 to 178.22993, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7044 - val_loss: 178.2299\n",
      "Epoch 243/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.6455\n",
      "Epoch 243: val_loss improved from 178.22993 to 177.21132, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.7529 - val_loss: 177.2113\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7062\n",
      "Epoch 244: val_loss improved from 177.21132 to 176.57043, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7062 - val_loss: 176.5704\n",
      "Epoch 245/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8262\n",
      "Epoch 245: val_loss improved from 176.57043 to 174.67703, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7773 - val_loss: 174.6770\n",
      "Epoch 246/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8844\n",
      "Epoch 246: val_loss did not improve from 174.67703\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8704 - val_loss: 174.7496\n",
      "Epoch 247/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7854\n",
      "Epoch 247: val_loss improved from 174.67703 to 174.24072, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7218 - val_loss: 174.2407\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0981\n",
      "Epoch 248: val_loss improved from 174.24072 to 171.34718, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0981 - val_loss: 171.3472\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7801\n",
      "Epoch 249: val_loss did not improve from 171.34718\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7801 - val_loss: 171.8660\n",
      "Epoch 250/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7092\n",
      "Epoch 250: val_loss improved from 171.34718 to 170.01717, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.6733 - val_loss: 170.0172\n",
      "Epoch 251/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6732\n",
      "Epoch 251: val_loss improved from 170.01717 to 168.50781, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5918 - val_loss: 168.5078\n",
      "Epoch 252/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6593\n",
      "Epoch 252: val_loss improved from 168.50781 to 167.68428, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6424 - val_loss: 167.6843\n",
      "Epoch 253/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7013\n",
      "Epoch 253: val_loss improved from 167.68428 to 166.54059, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6423 - val_loss: 166.5406\n",
      "Epoch 254/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4766\n",
      "Epoch 254: val_loss improved from 166.54059 to 164.50952, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4870 - val_loss: 164.5095\n",
      "Epoch 255/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8170\n",
      "Epoch 255: val_loss did not improve from 164.50952\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7588 - val_loss: 165.3347\n",
      "Epoch 256/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8900\n",
      "Epoch 256: val_loss improved from 164.50952 to 164.46146, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8752 - val_loss: 164.4615\n",
      "Epoch 257/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4954\n",
      "Epoch 257: val_loss improved from 164.46146 to 162.37769, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5496 - val_loss: 162.3777\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5709\n",
      "Epoch 258: val_loss improved from 162.37769 to 161.19469, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.5709 - val_loss: 161.1947\n",
      "Epoch 259/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6287\n",
      "Epoch 259: val_loss did not improve from 161.19469\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6352 - val_loss: 161.3349\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5385\n",
      "Epoch 260: val_loss improved from 161.19469 to 160.76915, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5385 - val_loss: 160.7691\n",
      "Epoch 261/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7180\n",
      "Epoch 261: val_loss improved from 160.76915 to 157.33217, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6595 - val_loss: 157.3322\n",
      "Epoch 262/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1170\n",
      "Epoch 262: val_loss improved from 157.33217 to 156.56305, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0383 - val_loss: 156.5630\n",
      "Epoch 263/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4556\n",
      "Epoch 263: val_loss improved from 156.56305 to 156.48404, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4264 - val_loss: 156.4840\n",
      "Epoch 264/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6505\n",
      "Epoch 264: val_loss improved from 156.48404 to 156.16968, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6362 - val_loss: 156.1697\n",
      "Epoch 265/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3597\n",
      "Epoch 265: val_loss did not improve from 156.16968\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4036 - val_loss: 156.6210\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6226\n",
      "Epoch 266: val_loss improved from 156.16968 to 152.39653, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6226 - val_loss: 152.3965\n",
      "Epoch 267/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3070\n",
      "Epoch 267: val_loss improved from 152.39653 to 152.23637, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2774 - val_loss: 152.2364\n",
      "Epoch 268/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8300\n",
      "Epoch 268: val_loss did not improve from 152.23637\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8090 - val_loss: 154.2897\n",
      "Epoch 269/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5189\n",
      "Epoch 269: val_loss did not improve from 152.23637\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4934 - val_loss: 154.7713\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4440\n",
      "Epoch 270: val_loss improved from 152.23637 to 151.89633, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4440 - val_loss: 151.8963\n",
      "Epoch 271/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2643\n",
      "Epoch 271: val_loss improved from 151.89633 to 150.37640, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2910 - val_loss: 150.3764\n",
      "Epoch 272/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2644\n",
      "Epoch 272: val_loss improved from 150.37640 to 147.43924, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3575 - val_loss: 147.4392\n",
      "Epoch 273/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6916\n",
      "Epoch 273: val_loss improved from 147.43924 to 145.42995, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6027 - val_loss: 145.4299\n",
      "Epoch 274/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2701\n",
      "Epoch 274: val_loss improved from 145.42995 to 144.09966, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2893 - val_loss: 144.0997\n",
      "Epoch 275/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3533\n",
      "Epoch 275: val_loss did not improve from 144.09966\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3112 - val_loss: 146.7431\n",
      "Epoch 276/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6157\n",
      "Epoch 276: val_loss improved from 144.09966 to 143.40662, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5650 - val_loss: 143.4066\n",
      "Epoch 277/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2935\n",
      "Epoch 277: val_loss improved from 143.40662 to 142.25104, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2948 - val_loss: 142.2510\n",
      "Epoch 278/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2927\n",
      "Epoch 278: val_loss improved from 142.25104 to 142.22823, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2327 - val_loss: 142.2282\n",
      "Epoch 279/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4371\n",
      "Epoch 279: val_loss improved from 142.22823 to 141.26216, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3564 - val_loss: 141.2622\n",
      "Epoch 280/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2574\n",
      "Epoch 280: val_loss improved from 141.26216 to 139.26024, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3170 - val_loss: 139.2602\n",
      "Epoch 281/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2983\n",
      "Epoch 281: val_loss did not improve from 139.26024\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2198 - val_loss: 141.3079\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4560\n",
      "Epoch 282: val_loss improved from 139.26024 to 138.29349, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4560 - val_loss: 138.2935\n",
      "Epoch 283/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3947\n",
      "Epoch 283: val_loss improved from 138.29349 to 137.68242, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4258 - val_loss: 137.6824\n",
      "Epoch 284/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4861\n",
      "Epoch 284: val_loss did not improve from 137.68242\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5046 - val_loss: 141.8417\n",
      "Epoch 285/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3689\n",
      "Epoch 285: val_loss did not improve from 137.68242\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3645 - val_loss: 138.3488\n",
      "Epoch 286/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3942\n",
      "Epoch 286: val_loss did not improve from 137.68242\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3672 - val_loss: 137.8004\n",
      "Epoch 287/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1304\n",
      "Epoch 287: val_loss improved from 137.68242 to 134.98488, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1757 - val_loss: 134.9849\n",
      "Epoch 288/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0745\n",
      "Epoch 288: val_loss did not improve from 134.98488\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1111 - val_loss: 135.4991\n",
      "Epoch 289/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1764\n",
      "Epoch 289: val_loss improved from 134.98488 to 132.58153, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0975 - val_loss: 132.5815\n",
      "Epoch 290/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5028\n",
      "Epoch 290: val_loss did not improve from 132.58153\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5922 - val_loss: 132.8095\n",
      "Epoch 291/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4176\n",
      "Epoch 291: val_loss improved from 132.58153 to 131.92690, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3545 - val_loss: 131.9269\n",
      "Epoch 292/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2365\n",
      "Epoch 292: val_loss improved from 131.92690 to 130.13748, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2052 - val_loss: 130.1375\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2136\n",
      "Epoch 293: val_loss did not improve from 130.13748\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2136 - val_loss: 131.1356\n",
      "Epoch 294/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0037\n",
      "Epoch 294: val_loss improved from 130.13748 to 128.90163, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0233 - val_loss: 128.9016\n",
      "Epoch 295/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1411\n",
      "Epoch 295: val_loss did not improve from 128.90163\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3560 - val_loss: 135.2804\n",
      "Epoch 296/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1676\n",
      "Epoch 296: val_loss improved from 128.90163 to 126.96272, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1931 - val_loss: 126.9627\n",
      "Epoch 297/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1783\n",
      "Epoch 297: val_loss did not improve from 126.96272\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1884 - val_loss: 127.0400\n",
      "Epoch 298/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1228\n",
      "Epoch 298: val_loss did not improve from 126.96272\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0570 - val_loss: 127.3362\n",
      "Epoch 299/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9950\n",
      "Epoch 299: val_loss improved from 126.96272 to 125.24875, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0081 - val_loss: 125.2487\n",
      "Epoch 300/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9248\n",
      "Epoch 300: val_loss did not improve from 125.24875\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9492 - val_loss: 125.4067\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2495\n",
      "Epoch 301: val_loss did not improve from 125.24875\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2495 - val_loss: 127.4258\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1704\n",
      "Epoch 302: val_loss did not improve from 125.24875\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1704 - val_loss: 125.8034\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3209\n",
      "Epoch 303: val_loss improved from 125.24875 to 122.53027, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3209 - val_loss: 122.5303\n",
      "Epoch 304/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0543\n",
      "Epoch 304: val_loss improved from 122.53027 to 121.52781, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1047 - val_loss: 121.5278\n",
      "Epoch 305/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1980\n",
      "Epoch 305: val_loss did not improve from 121.52781\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1552 - val_loss: 129.1746\n",
      "Epoch 306/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6996\n",
      "Epoch 306: val_loss did not improve from 121.52781\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7424 - val_loss: 127.7635\n",
      "Epoch 307/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1870\n",
      "Epoch 307: val_loss improved from 121.52781 to 120.44401, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2214 - val_loss: 120.4440\n",
      "Epoch 308/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1381\n",
      "Epoch 308: val_loss did not improve from 120.44401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1257 - val_loss: 123.3175\n",
      "Epoch 309/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0861\n",
      "Epoch 309: val_loss improved from 120.44401 to 119.55547, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1000 - val_loss: 119.5555\n",
      "Epoch 310/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8325\n",
      "Epoch 310: val_loss improved from 119.55547 to 117.52122, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9011 - val_loss: 117.5212\n",
      "Epoch 311/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1038\n",
      "Epoch 311: val_loss did not improve from 117.52122\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0682 - val_loss: 121.2975\n",
      "Epoch 312/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0260\n",
      "Epoch 312: val_loss improved from 117.52122 to 114.91230, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0478 - val_loss: 114.9123\n",
      "Epoch 313/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1192\n",
      "Epoch 313: val_loss did not improve from 114.91230\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0928 - val_loss: 116.7129\n",
      "Epoch 314/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9878\n",
      "Epoch 314: val_loss did not improve from 114.91230\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0200 - val_loss: 115.8705\n",
      "Epoch 315/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1008\n",
      "Epoch 315: val_loss did not improve from 114.91230\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1683 - val_loss: 116.3729\n",
      "Epoch 316/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1709\n",
      "Epoch 316: val_loss improved from 114.91230 to 113.47033, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1439 - val_loss: 113.4703\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9121\n",
      "Epoch 317: val_loss improved from 113.47033 to 112.97081, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9121 - val_loss: 112.9708\n",
      "Epoch 318/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9259\n",
      "Epoch 318: val_loss improved from 112.97081 to 112.39484, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0165 - val_loss: 112.3948\n",
      "Epoch 319/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 3.0253\n",
      "Epoch 319: val_loss improved from 112.39484 to 111.45277, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0055 - val_loss: 111.4528\n",
      "Epoch 320/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8083\n",
      "Epoch 320: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8234 - val_loss: 117.0425\n",
      "Epoch 321/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0198\n",
      "Epoch 321: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0356 - val_loss: 116.8589\n",
      "Epoch 322/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9817\n",
      "Epoch 322: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9576 - val_loss: 111.7860\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4505\n",
      "Epoch 323: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4505 - val_loss: 114.4610\n",
      "Epoch 324/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0138\n",
      "Epoch 324: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9935 - val_loss: 113.2239\n",
      "Epoch 325/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8415\n",
      "Epoch 325: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8262 - val_loss: 111.5724\n",
      "Epoch 326/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0736\n",
      "Epoch 326: val_loss did not improve from 111.45277\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0546 - val_loss: 111.4648\n",
      "Epoch 327/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9835\n",
      "Epoch 327: val_loss improved from 111.45277 to 107.48943, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9552 - val_loss: 107.4894\n",
      "Epoch 328/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8434\n",
      "Epoch 328: val_loss did not improve from 107.48943\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8678 - val_loss: 110.5155\n",
      "Epoch 329/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8263\n",
      "Epoch 329: val_loss improved from 107.48943 to 107.01144, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9147 - val_loss: 107.0114\n",
      "Epoch 330/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8432\n",
      "Epoch 330: val_loss did not improve from 107.01144\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8309 - val_loss: 107.3631\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7716\n",
      "Epoch 331: val_loss did not improve from 107.01144\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7716 - val_loss: 109.0548\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8321\n",
      "Epoch 332: val_loss improved from 107.01144 to 105.93060, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8321 - val_loss: 105.9306\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9377\n",
      "Epoch 333: val_loss improved from 105.93060 to 105.37451, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9377 - val_loss: 105.3745\n",
      "Epoch 334/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9863\n",
      "Epoch 334: val_loss did not improve from 105.37451\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9392 - val_loss: 108.4637\n",
      "Epoch 335/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6758\n",
      "Epoch 335: val_loss improved from 105.37451 to 104.61018, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7153 - val_loss: 104.6102\n",
      "Epoch 336/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7233\n",
      "Epoch 336: val_loss improved from 104.61018 to 104.44474, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7336 - val_loss: 104.4447\n",
      "Epoch 337/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7377\n",
      "Epoch 337: val_loss did not improve from 104.44474\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7218 - val_loss: 104.5276\n",
      "Epoch 338/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7485\n",
      "Epoch 338: val_loss did not improve from 104.44474\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7407 - val_loss: 107.8858\n",
      "Epoch 339/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8392\n",
      "Epoch 339: val_loss did not improve from 104.44474\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8296 - val_loss: 104.8857\n",
      "Epoch 340/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9243\n",
      "Epoch 340: val_loss improved from 104.44474 to 103.40067, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8490 - val_loss: 103.4007\n",
      "Epoch 341/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6797\n",
      "Epoch 341: val_loss improved from 103.40067 to 100.78613, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6887 - val_loss: 100.7861\n",
      "Epoch 342/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7118\n",
      "Epoch 342: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7452 - val_loss: 104.9676\n",
      "Epoch 343/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7702\n",
      "Epoch 343: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8276 - val_loss: 104.5403\n",
      "Epoch 344/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9350\n",
      "Epoch 344: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9108 - val_loss: 113.0642\n",
      "Epoch 345/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7549\n",
      "Epoch 345: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8547 - val_loss: 104.1284\n",
      "Epoch 346/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6008\n",
      "Epoch 346: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7014 - val_loss: 112.4624\n",
      "Epoch 347/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1787\n",
      "Epoch 347: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1160 - val_loss: 101.9920\n",
      "Epoch 348/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7326\n",
      "Epoch 348: val_loss did not improve from 100.78613\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7418 - val_loss: 104.9565\n",
      "Epoch 349/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8642\n",
      "Epoch 349: val_loss improved from 100.78613 to 99.19240, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8441 - val_loss: 99.1924\n",
      "Epoch 350/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7703\n",
      "Epoch 350: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7508 - val_loss: 99.5137\n",
      "Epoch 351/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7127\n",
      "Epoch 351: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7873 - val_loss: 100.3398\n",
      "Epoch 352/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9565\n",
      "Epoch 352: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9264 - val_loss: 101.0366\n",
      "Epoch 353/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9211\n",
      "Epoch 353: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8666 - val_loss: 102.8079\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0748\n",
      "Epoch 354: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0748 - val_loss: 100.5415\n",
      "Epoch 355/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7346\n",
      "Epoch 355: val_loss did not improve from 99.19240\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6926 - val_loss: 102.6893\n",
      "Epoch 356/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6987\n",
      "Epoch 356: val_loss improved from 99.19240 to 96.05865, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6341 - val_loss: 96.0586\n",
      "Epoch 357/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8629\n",
      "Epoch 357: val_loss did not improve from 96.05865\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8439 - val_loss: 102.8386\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8802\n",
      "Epoch 358: val_loss did not improve from 96.05865\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8802 - val_loss: 100.6715\n",
      "Epoch 359/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6344\n",
      "Epoch 359: val_loss improved from 96.05865 to 95.26202, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6997 - val_loss: 95.2620\n",
      "Epoch 360/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8204\n",
      "Epoch 360: val_loss did not improve from 95.26202\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7847 - val_loss: 100.2219\n",
      "Epoch 361/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7291\n",
      "Epoch 361: val_loss did not improve from 95.26202\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7804 - val_loss: 96.7738\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7546\n",
      "Epoch 362: val_loss did not improve from 95.26202\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7546 - val_loss: 101.0710\n",
      "Epoch 363/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6688\n",
      "Epoch 363: val_loss did not improve from 95.26202\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7366 - val_loss: 98.1499\n",
      "Epoch 364/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6106\n",
      "Epoch 364: val_loss did not improve from 95.26202\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6669 - val_loss: 96.0592\n",
      "Epoch 365/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8287\n",
      "Epoch 365: val_loss improved from 95.26202 to 93.08380, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7794 - val_loss: 93.0838\n",
      "Epoch 366/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5913\n",
      "Epoch 366: val_loss did not improve from 93.08380\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6460 - val_loss: 95.6052\n",
      "Epoch 367/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6526\n",
      "Epoch 367: val_loss improved from 93.08380 to 92.51178, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6940 - val_loss: 92.5118\n",
      "Epoch 368/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6517\n",
      "Epoch 368: val_loss did not improve from 92.51178\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6685 - val_loss: 95.1539\n",
      "Epoch 369/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5171\n",
      "Epoch 369: val_loss improved from 92.51178 to 92.44794, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5970 - val_loss: 92.4479\n",
      "Epoch 370/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7023\n",
      "Epoch 370: val_loss did not improve from 92.44794\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7422 - val_loss: 95.3977\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7580\n",
      "Epoch 371: val_loss improved from 92.44794 to 91.40497, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7580 - val_loss: 91.4050\n",
      "Epoch 372/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6739\n",
      "Epoch 372: val_loss did not improve from 91.40497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7384 - val_loss: 93.3087\n",
      "Epoch 373/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7024\n",
      "Epoch 373: val_loss improved from 91.40497 to 90.42150, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6814 - val_loss: 90.4215\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5775\n",
      "Epoch 374: val_loss improved from 90.42150 to 88.20212, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5775 - val_loss: 88.2021\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8627\n",
      "Epoch 375: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8627 - val_loss: 94.8219\n",
      "Epoch 376/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6049\n",
      "Epoch 376: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5894 - val_loss: 88.6660\n",
      "Epoch 377/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6908\n",
      "Epoch 377: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6934 - val_loss: 89.0703\n",
      "Epoch 378/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7256\n",
      "Epoch 378: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7506 - val_loss: 89.1623\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7625\n",
      "Epoch 379: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7625 - val_loss: 88.9493\n",
      "Epoch 380/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6484\n",
      "Epoch 380: val_loss did not improve from 88.20212\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6097 - val_loss: 89.4917\n",
      "Epoch 381/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5877\n",
      "Epoch 381: val_loss improved from 88.20212 to 86.93008, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6224 - val_loss: 86.9301\n",
      "Epoch 382/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5434\n",
      "Epoch 382: val_loss did not improve from 86.93008\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6613 - val_loss: 99.9300\n",
      "Epoch 383/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4128\n",
      "Epoch 383: val_loss did not improve from 86.93008\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3362 - val_loss: 89.5094\n",
      "Epoch 384/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6805\n",
      "Epoch 384: val_loss did not improve from 86.93008\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6651 - val_loss: 95.8407\n",
      "Epoch 385/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7774\n",
      "Epoch 385: val_loss did not improve from 86.93008\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7509 - val_loss: 87.7382\n",
      "Epoch 386/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7341\n",
      "Epoch 386: val_loss did not improve from 86.93008\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7963 - val_loss: 87.4509\n",
      "Epoch 387/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7714\n",
      "Epoch 387: val_loss improved from 86.93008 to 85.86543, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7471 - val_loss: 85.8654\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6258\n",
      "Epoch 388: val_loss improved from 85.86543 to 85.61856, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6258 - val_loss: 85.6186\n",
      "Epoch 389/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8253\n",
      "Epoch 389: val_loss did not improve from 85.61856\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8003 - val_loss: 91.0015\n",
      "Epoch 390/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6973\n",
      "Epoch 390: val_loss improved from 85.61856 to 83.57510, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6292 - val_loss: 83.5751\n",
      "Epoch 391/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5289\n",
      "Epoch 391: val_loss did not improve from 83.57510\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5511 - val_loss: 84.3435\n",
      "Epoch 392/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5289\n",
      "Epoch 392: val_loss did not improve from 83.57510\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4441 - val_loss: 83.7337\n",
      "Epoch 393/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5394\n",
      "Epoch 393: val_loss did not improve from 83.57510\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6565 - val_loss: 84.4661\n",
      "Epoch 394/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4753\n",
      "Epoch 394: val_loss improved from 83.57510 to 82.48695, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.5006 - val_loss: 82.4869\n",
      "Epoch 395/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7983\n",
      "Epoch 395: val_loss did not improve from 82.48695\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9153 - val_loss: 82.6448\n",
      "Epoch 396/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7135\n",
      "Epoch 396: val_loss improved from 82.48695 to 81.90054, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7420 - val_loss: 81.9005\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5541\n",
      "Epoch 397: val_loss did not improve from 81.90054\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5541 - val_loss: 83.9444\n",
      "Epoch 398/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6979\n",
      "Epoch 398: val_loss did not improve from 81.90054\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.6975 - val_loss: 84.1947\n",
      "Epoch 399/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4138\n",
      "Epoch 399: val_loss improved from 81.90054 to 79.19347, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3981 - val_loss: 79.1935\n",
      "Epoch 400/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5771\n",
      "Epoch 400: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5357 - val_loss: 83.1745\n",
      "Epoch 401/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4794\n",
      "Epoch 401: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4807 - val_loss: 81.2570\n",
      "Epoch 402/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6025\n",
      "Epoch 402: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5934 - val_loss: 87.5787\n",
      "Epoch 403/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6142\n",
      "Epoch 403: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5520 - val_loss: 80.3260\n",
      "Epoch 404/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5577\n",
      "Epoch 404: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5306 - val_loss: 80.3762\n",
      "Epoch 405/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7888\n",
      "Epoch 405: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7982 - val_loss: 84.5278\n",
      "Epoch 406/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8148\n",
      "Epoch 406: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8290 - val_loss: 83.0708\n",
      "Epoch 407/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5621\n",
      "Epoch 407: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.6308 - val_loss: 82.9766\n",
      "Epoch 408/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5545\n",
      "Epoch 408: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5699 - val_loss: 81.3983\n",
      "Epoch 409/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5061\n",
      "Epoch 409: val_loss did not improve from 79.19347\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4778 - val_loss: 80.8891\n",
      "Epoch 410/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3743\n",
      "Epoch 410: val_loss improved from 79.19347 to 76.19436, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4401 - val_loss: 76.1944\n",
      "Epoch 411/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7058\n",
      "Epoch 411: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6318 - val_loss: 80.2734\n",
      "Epoch 412/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5118\n",
      "Epoch 412: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5151 - val_loss: 79.1450\n",
      "Epoch 413/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7445\n",
      "Epoch 413: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.6628 - val_loss: 85.4755\n",
      "Epoch 414/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6001\n",
      "Epoch 414: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6156 - val_loss: 81.6677\n",
      "Epoch 415/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4586\n",
      "Epoch 415: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5457 - val_loss: 76.3382\n",
      "Epoch 416/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5202\n",
      "Epoch 416: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5153 - val_loss: 79.3588\n",
      "Epoch 417/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3865\n",
      "Epoch 417: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4374 - val_loss: 77.5706\n",
      "Epoch 418/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5465\n",
      "Epoch 418: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5292 - val_loss: 78.0695\n",
      "Epoch 419/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4997\n",
      "Epoch 419: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4716 - val_loss: 76.5755\n",
      "Epoch 420/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5005\n",
      "Epoch 420: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3977 - val_loss: 78.0678\n",
      "Epoch 421/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4745\n",
      "Epoch 421: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4683 - val_loss: 79.3019\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5540\n",
      "Epoch 422: val_loss did not improve from 76.19436\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5540 - val_loss: 76.3794\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7768\n",
      "Epoch 423: val_loss improved from 76.19436 to 75.38861, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7768 - val_loss: 75.3886\n",
      "Epoch 424/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4992\n",
      "Epoch 424: val_loss did not improve from 75.38861\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5124 - val_loss: 82.2599\n",
      "Epoch 425/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5509\n",
      "Epoch 425: val_loss did not improve from 75.38861\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5898 - val_loss: 75.9174\n",
      "Epoch 426/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4637\n",
      "Epoch 426: val_loss improved from 75.38861 to 73.81410, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4566 - val_loss: 73.8141\n",
      "Epoch 427/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5596\n",
      "Epoch 427: val_loss did not improve from 73.81410\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5263 - val_loss: 76.5744\n",
      "Epoch 428/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5419\n",
      "Epoch 428: val_loss did not improve from 73.81410\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4933 - val_loss: 76.8484\n",
      "Epoch 429/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5217\n",
      "Epoch 429: val_loss did not improve from 73.81410\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 2.5380 - val_loss: 75.3390\n",
      "Epoch 430/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3780\n",
      "Epoch 430: val_loss did not improve from 73.81410\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.4056 - val_loss: 75.2817\n",
      "Epoch 431/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6770\n",
      "Epoch 431: val_loss did not improve from 73.81410\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7971 - val_loss: 75.5193\n",
      "Epoch 432/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6756\n",
      "Epoch 432: val_loss improved from 73.81410 to 72.49427, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6075 - val_loss: 72.4943\n",
      "Epoch 433/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8756\n",
      "Epoch 433: val_loss improved from 72.49427 to 70.68496, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8906 - val_loss: 70.6850\n",
      "Epoch 434/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5313\n",
      "Epoch 434: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5024 - val_loss: 72.0713\n",
      "Epoch 435/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4497\n",
      "Epoch 435: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4300 - val_loss: 76.0295\n",
      "Epoch 436/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5832\n",
      "Epoch 436: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5688 - val_loss: 72.6274\n",
      "Epoch 437/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6310\n",
      "Epoch 437: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.6172 - val_loss: 74.6165\n",
      "Epoch 438/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5434\n",
      "Epoch 438: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5329 - val_loss: 72.6178\n",
      "Epoch 439/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3946\n",
      "Epoch 439: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3779 - val_loss: 74.6690\n",
      "Epoch 440/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4861\n",
      "Epoch 440: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5074 - val_loss: 78.3674\n",
      "Epoch 441/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6670\n",
      "Epoch 441: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6946 - val_loss: 79.7321\n",
      "Epoch 442/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5624\n",
      "Epoch 442: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5593 - val_loss: 74.9378\n",
      "Epoch 443/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4642\n",
      "Epoch 443: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2.4517 - val_loss: 71.8317\n",
      "Epoch 444/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3831\n",
      "Epoch 444: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2.3831 - val_loss: 74.8256\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5665\n",
      "Epoch 445: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.5665 - val_loss: 76.0854\n",
      "Epoch 446/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6173\n",
      "Epoch 446: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.6006 - val_loss: 72.7708\n",
      "Epoch 447/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5696\n",
      "Epoch 447: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4948 - val_loss: 75.5153\n",
      "Epoch 448/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5162\n",
      "Epoch 448: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.5052 - val_loss: 74.9569\n",
      "Epoch 449/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6246\n",
      "Epoch 449: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5832 - val_loss: 71.6071\n",
      "Epoch 450/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5962\n",
      "Epoch 450: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6874 - val_loss: 73.9038\n",
      "Epoch 451/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6170\n",
      "Epoch 451: val_loss did not improve from 70.68496\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 2.6170 - val_loss: 73.1671\n",
      "Epoch 452/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5055\n",
      "Epoch 452: val_loss improved from 70.68496 to 66.77596, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.4390 - val_loss: 66.7760\n",
      "Epoch 453/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4297\n",
      "Epoch 453: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3731 - val_loss: 68.5870\n",
      "Epoch 454/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3171\n",
      "Epoch 454: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.3255 - val_loss: 70.3758\n",
      "Epoch 455/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3928\n",
      "Epoch 455: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3928 - val_loss: 70.8067\n",
      "Epoch 456/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4674\n",
      "Epoch 456: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4709 - val_loss: 71.0144\n",
      "Epoch 457/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5147\n",
      "Epoch 457: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5278 - val_loss: 71.0056\n",
      "Epoch 458/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4907\n",
      "Epoch 458: val_loss did not improve from 66.77596\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.5198 - val_loss: 70.9710\n",
      "Epoch 459/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3957\n",
      "Epoch 459: val_loss improved from 66.77596 to 66.48216, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3811 - val_loss: 66.4822\n",
      "Epoch 460/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4967\n",
      "Epoch 460: val_loss did not improve from 66.48216\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4967 - val_loss: 69.2977\n",
      "Epoch 461/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4673\n",
      "Epoch 461: val_loss improved from 66.48216 to 66.29348, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5271 - val_loss: 66.2935\n",
      "Epoch 462/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6257\n",
      "Epoch 462: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6476 - val_loss: 69.0994\n",
      "Epoch 463/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6084\n",
      "Epoch 463: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6272 - val_loss: 66.7669\n",
      "Epoch 464/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4223\n",
      "Epoch 464: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3427 - val_loss: 68.5607\n",
      "Epoch 465/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4280\n",
      "Epoch 465: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.3269 - val_loss: 66.6151\n",
      "Epoch 466/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3963\n",
      "Epoch 466: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4110 - val_loss: 72.8436\n",
      "Epoch 467/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5725\n",
      "Epoch 467: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.5782 - val_loss: 66.8229\n",
      "Epoch 468/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3944\n",
      "Epoch 468: val_loss did not improve from 66.29348\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3795 - val_loss: 68.2229\n",
      "Epoch 469/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3427\n",
      "Epoch 469: val_loss improved from 66.29348 to 65.11903, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.4597 - val_loss: 65.1190\n",
      "Epoch 470/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4429\n",
      "Epoch 470: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4310 - val_loss: 66.2458\n",
      "Epoch 471/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.5501\n",
      "Epoch 471: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6114 - val_loss: 67.1590\n",
      "Epoch 472/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5119\n",
      "Epoch 472: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5803 - val_loss: 77.5606\n",
      "Epoch 473/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9027\n",
      "Epoch 473: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9027 - val_loss: 65.4009\n",
      "Epoch 474/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3505\n",
      "Epoch 474: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3538 - val_loss: 65.8105\n",
      "Epoch 475/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.4622\n",
      "Epoch 475: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4622 - val_loss: 67.6292\n",
      "Epoch 476/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2947\n",
      "Epoch 476: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3211 - val_loss: 65.2156\n",
      "Epoch 477/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3343\n",
      "Epoch 477: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3343 - val_loss: 68.0385\n",
      "Epoch 478/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3382\n",
      "Epoch 478: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2760 - val_loss: 67.9770\n",
      "Epoch 479/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.2828\n",
      "Epoch 479: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2828 - val_loss: 66.2048\n",
      "Epoch 480/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5119\n",
      "Epoch 480: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5119 - val_loss: 67.2669\n",
      "Epoch 481/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.3282\n",
      "Epoch 481: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3286 - val_loss: 65.4778\n",
      "Epoch 482/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.3627\n",
      "Epoch 482: val_loss did not improve from 65.11903\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3353 - val_loss: 69.6374\n",
      "Epoch 483/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5927\n",
      "Epoch 483: val_loss improved from 65.11903 to 62.94901, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5943 - val_loss: 62.9490\n",
      "Epoch 484/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2270\n",
      "Epoch 484: val_loss did not improve from 62.94901\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2483 - val_loss: 63.6772\n",
      "Epoch 485/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2739\n",
      "Epoch 485: val_loss improved from 62.94901 to 62.93725, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.2703 - val_loss: 62.9372\n",
      "Epoch 486/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3487\n",
      "Epoch 486: val_loss improved from 62.93725 to 62.27617, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.3543 - val_loss: 62.2762\n",
      "Epoch 487/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3833\n",
      "Epoch 487: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3833 - val_loss: 65.1497\n",
      "Epoch 488/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2453\n",
      "Epoch 488: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2766 - val_loss: 62.7619\n",
      "Epoch 489/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3523\n",
      "Epoch 489: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3661 - val_loss: 66.5452\n",
      "Epoch 490/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2989\n",
      "Epoch 490: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2621 - val_loss: 64.2277\n",
      "Epoch 491/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1736\n",
      "Epoch 491: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2566 - val_loss: 63.1249\n",
      "Epoch 492/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2257\n",
      "Epoch 492: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.2752 - val_loss: 62.2873\n",
      "Epoch 493/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5569\n",
      "Epoch 493: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5655 - val_loss: 76.4360\n",
      "Epoch 494/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8898\n",
      "Epoch 494: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8698 - val_loss: 73.4990\n",
      "Epoch 495/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3503\n",
      "Epoch 495: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3503 - val_loss: 64.9417\n",
      "Epoch 496/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1789\n",
      "Epoch 496: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2228 - val_loss: 63.6681\n",
      "Epoch 497/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2526\n",
      "Epoch 497: val_loss did not improve from 62.27617\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2240 - val_loss: 66.8815\n",
      "Epoch 498/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.2879\n",
      "Epoch 498: val_loss improved from 62.27617 to 62.11329, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.2879 - val_loss: 62.1133\n",
      "Epoch 499/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.4085\n",
      "Epoch 499: val_loss did not improve from 62.11329\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4329 - val_loss: 66.6312\n",
      "Epoch 500/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3968\n",
      "Epoch 500: val_loss did not improve from 62.11329\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3968 - val_loss: 63.0909\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3189\n",
      "Epoch 501: val_loss improved from 62.11329 to 60.03619, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3189 - val_loss: 60.0362\n",
      "Epoch 502/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.4284\n",
      "Epoch 502: val_loss did not improve from 60.03619\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4534 - val_loss: 65.2390\n",
      "Epoch 503/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4222\n",
      "Epoch 503: val_loss did not improve from 60.03619\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3623 - val_loss: 63.4535\n",
      "Epoch 504/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2504\n",
      "Epoch 504: val_loss did not improve from 60.03619\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2327 - val_loss: 62.8680\n",
      "Epoch 505/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1264\n",
      "Epoch 505: val_loss improved from 60.03619 to 60.02211, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2484 - val_loss: 60.0221\n",
      "Epoch 506/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2332\n",
      "Epoch 506: val_loss did not improve from 60.02211\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2104 - val_loss: 69.6402\n",
      "Epoch 507/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.2618\n",
      "Epoch 507: val_loss did not improve from 60.02211\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2618 - val_loss: 61.6052\n",
      "Epoch 508/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2052\n",
      "Epoch 508: val_loss did not improve from 60.02211\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2251 - val_loss: 60.9883\n",
      "Epoch 509/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2473\n",
      "Epoch 509: val_loss did not improve from 60.02211\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2286 - val_loss: 62.5131\n",
      "Epoch 510/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3545\n",
      "Epoch 510: val_loss did not improve from 60.02211\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3557 - val_loss: 63.3381\n",
      "Epoch 511/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3786\n",
      "Epoch 511: val_loss improved from 60.02211 to 59.22188, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3343 - val_loss: 59.2219\n",
      "Epoch 512/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3564\n",
      "Epoch 512: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3204 - val_loss: 61.0278\n",
      "Epoch 513/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1387\n",
      "Epoch 513: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1927 - val_loss: 59.3282\n",
      "Epoch 514/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.1203\n",
      "Epoch 514: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.2198 - val_loss: 67.7951\n",
      "Epoch 515/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5142\n",
      "Epoch 515: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.4773 - val_loss: 66.3206\n",
      "Epoch 516/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2280\n",
      "Epoch 516: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2435 - val_loss: 63.4825\n",
      "Epoch 517/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3127\n",
      "Epoch 517: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3202 - val_loss: 62.3120\n",
      "Epoch 518/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3177\n",
      "Epoch 518: val_loss did not improve from 59.22188\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3617 - val_loss: 64.0300\n",
      "Epoch 519/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1898\n",
      "Epoch 519: val_loss improved from 59.22188 to 58.09216, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.1683 - val_loss: 58.0922\n",
      "Epoch 520/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.1850\n",
      "Epoch 520: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1850 - val_loss: 60.5675\n",
      "Epoch 521/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2382\n",
      "Epoch 521: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2217 - val_loss: 58.2131\n",
      "Epoch 522/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2527\n",
      "Epoch 522: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1876 - val_loss: 62.4592\n",
      "Epoch 523/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2540\n",
      "Epoch 523: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3438 - val_loss: 62.7431\n",
      "Epoch 524/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.3512\n",
      "Epoch 524: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3512 - val_loss: 67.3819\n",
      "Epoch 525/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2893\n",
      "Epoch 525: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3738 - val_loss: 68.9430\n",
      "Epoch 526/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3747\n",
      "Epoch 526: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3863 - val_loss: 64.6354\n",
      "Epoch 527/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5469\n",
      "Epoch 527: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5414 - val_loss: 67.2896\n",
      "Epoch 528/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2997\n",
      "Epoch 528: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3271 - val_loss: 62.9927\n",
      "Epoch 529/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3700\n",
      "Epoch 529: val_loss did not improve from 58.09216\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4094 - val_loss: 59.6893\n",
      "Epoch 530/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.2704\n",
      "Epoch 530: val_loss improved from 58.09216 to 57.75227, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2704 - val_loss: 57.7523\n",
      "Epoch 531/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1639\n",
      "Epoch 531: val_loss did not improve from 57.75227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1647 - val_loss: 63.0502\n",
      "Epoch 532/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.2370\n",
      "Epoch 532: val_loss did not improve from 57.75227\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2962 - val_loss: 61.0051\n",
      "Epoch 533/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2533\n",
      "Epoch 533: val_loss did not improve from 57.75227\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.2158 - val_loss: 63.9816\n",
      "Epoch 534/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2099\n",
      "Epoch 534: val_loss improved from 57.75227 to 57.20259, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.2770 - val_loss: 57.2026\n",
      "Epoch 535/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2720\n",
      "Epoch 535: val_loss did not improve from 57.20259\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2470 - val_loss: 63.6763\n",
      "Epoch 536/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.2448\n",
      "Epoch 536: val_loss did not improve from 57.20259\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1894 - val_loss: 57.9366\n",
      "Epoch 537/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2141\n",
      "Epoch 537: val_loss improved from 57.20259 to 57.02238, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.2395 - val_loss: 57.0224\n",
      "Epoch 538/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1784\n",
      "Epoch 538: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1731 - val_loss: 60.1228\n",
      "Epoch 539/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0881\n",
      "Epoch 539: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1380 - val_loss: 62.5752\n",
      "Epoch 540/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1291\n",
      "Epoch 540: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.1194 - val_loss: 62.3255\n",
      "Epoch 541/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2249\n",
      "Epoch 541: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.2552 - val_loss: 58.6653\n",
      "Epoch 542/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1105\n",
      "Epoch 542: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1216 - val_loss: 66.3339\n",
      "Epoch 543/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.4785\n",
      "Epoch 543: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.3825 - val_loss: 64.4948\n",
      "Epoch 544/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.2073\n",
      "Epoch 544: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.2503 - val_loss: 58.6173\n",
      "Epoch 545/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1122\n",
      "Epoch 545: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.0960 - val_loss: 58.3170\n",
      "Epoch 546/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.1566\n",
      "Epoch 546: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1566 - val_loss: 57.0741\n",
      "Epoch 547/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1.9763\n",
      "Epoch 547: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.1038 - val_loss: 57.6576\n",
      "Epoch 548/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1757\n",
      "Epoch 548: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1475 - val_loss: 65.5654\n",
      "Epoch 549/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5503\n",
      "Epoch 549: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.5137 - val_loss: 65.2118\n",
      "Epoch 550/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1738\n",
      "Epoch 550: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1632 - val_loss: 57.6907\n",
      "Epoch 551/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.1022\n",
      "Epoch 551: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1312 - val_loss: 60.4601\n",
      "Epoch 552/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1484\n",
      "Epoch 552: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1211 - val_loss: 63.2573\n",
      "Epoch 553/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0137\n",
      "Epoch 553: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.0270 - val_loss: 57.6078\n",
      "Epoch 554/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.1119\n",
      "Epoch 554: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.1119 - val_loss: 58.5614\n",
      "Epoch 555/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1263\n",
      "Epoch 555: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0618 - val_loss: 66.4072\n",
      "Epoch 556/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.4674\n",
      "Epoch 556: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4837 - val_loss: 63.6016\n",
      "Epoch 557/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.1921\n",
      "Epoch 557: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3127 - val_loss: 57.9912\n",
      "Epoch 558/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.3944\n",
      "Epoch 558: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.3498 - val_loss: 60.4224\n",
      "Epoch 559/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.0173\n",
      "Epoch 559: val_loss did not improve from 57.02238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.0544 - val_loss: 58.2417\n",
      "Epoch 560/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0749\n",
      "Epoch 560: val_loss improved from 57.02238 to 56.07401, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0749 - val_loss: 56.0740\n",
      "Epoch 561/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0401\n",
      "Epoch 561: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.0401 - val_loss: 57.7083\n",
      "Epoch 562/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.0755\n",
      "Epoch 562: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0594 - val_loss: 60.7288\n",
      "Epoch 563/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0381\n",
      "Epoch 563: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0381 - val_loss: 56.4413\n",
      "Epoch 564/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1533\n",
      "Epoch 564: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.1364 - val_loss: 61.8149\n",
      "Epoch 565/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.3234\n",
      "Epoch 565: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.3052 - val_loss: 64.5704\n",
      "Epoch 566/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2570\n",
      "Epoch 566: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.2946 - val_loss: 62.7378\n",
      "Epoch 567/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.2070\n",
      "Epoch 567: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.1977 - val_loss: 67.5630\n",
      "Epoch 568/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.1802\n",
      "Epoch 568: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.1802 - val_loss: 57.7148\n",
      "Epoch 569/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1407\n",
      "Epoch 569: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.1138 - val_loss: 60.9481\n",
      "Epoch 570/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.0339\n",
      "Epoch 570: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.0504 - val_loss: 66.3205\n",
      "Epoch 571/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1646\n",
      "Epoch 571: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1142 - val_loss: 64.0698\n",
      "Epoch 572/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.0847\n",
      "Epoch 572: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.0612 - val_loss: 59.7716\n",
      "Epoch 573/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.0142\n",
      "Epoch 573: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.0400 - val_loss: 60.5631\n",
      "Epoch 574/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0125\n",
      "Epoch 574: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1.9947 - val_loss: 56.7229\n",
      "Epoch 575/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9717\n",
      "Epoch 575: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9747 - val_loss: 62.1493\n",
      "Epoch 576/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9990\n",
      "Epoch 576: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1.9527 - val_loss: 62.0005\n",
      "Epoch 577/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.2197\n",
      "Epoch 577: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1650 - val_loss: 63.5179\n",
      "Epoch 578/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9326\n",
      "Epoch 578: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8913 - val_loss: 60.1150\n",
      "Epoch 579/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8951\n",
      "Epoch 579: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9323 - val_loss: 61.3568\n",
      "Epoch 580/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.0833\n",
      "Epoch 580: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.0347 - val_loss: 57.3403\n",
      "Epoch 581/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9469\n",
      "Epoch 581: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 1.9259 - val_loss: 60.2386\n",
      "Epoch 582/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.0624\n",
      "Epoch 582: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0467 - val_loss: 60.3562\n",
      "Epoch 583/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.2124\n",
      "Epoch 583: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.2660 - val_loss: 58.8182\n",
      "Epoch 584/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0054\n",
      "Epoch 584: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0054 - val_loss: 56.1863\n",
      "Epoch 585/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9380\n",
      "Epoch 585: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9427 - val_loss: 59.2690\n",
      "Epoch 586/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.9772\n",
      "Epoch 586: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9772 - val_loss: 57.8920\n",
      "Epoch 587/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0113\n",
      "Epoch 587: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0113 - val_loss: 62.2864\n",
      "Epoch 588/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.9388\n",
      "Epoch 588: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9459 - val_loss: 59.5805\n",
      "Epoch 589/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9401\n",
      "Epoch 589: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9363 - val_loss: 63.7708\n",
      "Epoch 590/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9341\n",
      "Epoch 590: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9501 - val_loss: 61.0444\n",
      "Epoch 591/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1246\n",
      "Epoch 591: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.1627 - val_loss: 63.8838\n",
      "Epoch 592/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.0294\n",
      "Epoch 592: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0294 - val_loss: 57.9296\n",
      "Epoch 593/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.9886\n",
      "Epoch 593: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0124 - val_loss: 60.8447\n",
      "Epoch 594/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.1687\n",
      "Epoch 594: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1665 - val_loss: 59.9872\n",
      "Epoch 595/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.2824\n",
      "Epoch 595: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.2328 - val_loss: 58.8846\n",
      "Epoch 596/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1037\n",
      "Epoch 596: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.1446 - val_loss: 59.3271\n",
      "Epoch 597/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8927\n",
      "Epoch 597: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8996 - val_loss: 59.7248\n",
      "Epoch 598/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8764\n",
      "Epoch 598: val_loss did not improve from 56.07401\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1.8906 - val_loss: 57.1600\n",
      "Epoch 599/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8686\n",
      "Epoch 599: val_loss improved from 56.07401 to 56.02301, saving model to Best_GRU_Model_ADAM_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1.8650 - val_loss: 56.0230\n",
      "Epoch 600/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9860\n",
      "Epoch 600: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9653 - val_loss: 57.3211\n",
      "Epoch 601/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.9984\n",
      "Epoch 601: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.0137 - val_loss: 57.8136\n",
      "Epoch 602/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8474\n",
      "Epoch 602: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8553 - val_loss: 57.6725\n",
      "Epoch 603/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9820\n",
      "Epoch 603: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9609 - val_loss: 66.0398\n",
      "Epoch 604/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.3755\n",
      "Epoch 604: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.3821 - val_loss: 75.2192\n",
      "Epoch 605/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.1728\n",
      "Epoch 605: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1477 - val_loss: 62.2527\n",
      "Epoch 606/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.0316\n",
      "Epoch 606: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.0195 - val_loss: 58.3266\n",
      "Epoch 607/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.9470\n",
      "Epoch 607: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9531 - val_loss: 61.7496\n",
      "Epoch 608/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9399\n",
      "Epoch 608: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9207 - val_loss: 57.2941\n",
      "Epoch 609/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8308\n",
      "Epoch 609: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8666 - val_loss: 58.7404\n",
      "Epoch 610/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.8339\n",
      "Epoch 610: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8339 - val_loss: 61.9628\n",
      "Epoch 611/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.7606\n",
      "Epoch 611: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.7606 - val_loss: 62.3609\n",
      "Epoch 612/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8102\n",
      "Epoch 612: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.8177 - val_loss: 64.4399\n",
      "Epoch 613/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8143\n",
      "Epoch 613: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7935 - val_loss: 59.7083\n",
      "Epoch 614/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9276\n",
      "Epoch 614: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9291 - val_loss: 62.7377\n",
      "Epoch 615/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.1265\n",
      "Epoch 615: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.1481 - val_loss: 64.6671\n",
      "Epoch 616/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0155\n",
      "Epoch 616: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.0064 - val_loss: 59.1880\n",
      "Epoch 617/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9993\n",
      "Epoch 617: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9530 - val_loss: 66.4769\n",
      "Epoch 618/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8199\n",
      "Epoch 618: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8278 - val_loss: 57.8657\n",
      "Epoch 619/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8993\n",
      "Epoch 619: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8724 - val_loss: 56.7896\n",
      "Epoch 620/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8847\n",
      "Epoch 620: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9290 - val_loss: 61.4272\n",
      "Epoch 621/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.0675\n",
      "Epoch 621: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0680 - val_loss: 64.9188\n",
      "Epoch 622/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.9830\n",
      "Epoch 622: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9990 - val_loss: 64.1711\n",
      "Epoch 623/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8694\n",
      "Epoch 623: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.8348 - val_loss: 58.0184\n",
      "Epoch 624/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8182\n",
      "Epoch 624: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.8199 - val_loss: 63.3999\n",
      "Epoch 625/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8050\n",
      "Epoch 625: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8420 - val_loss: 58.2238\n",
      "Epoch 626/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8032\n",
      "Epoch 626: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8415 - val_loss: 60.1558\n",
      "Epoch 627/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.8098\n",
      "Epoch 627: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8098 - val_loss: 60.9553\n",
      "Epoch 628/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8347\n",
      "Epoch 628: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8237 - val_loss: 64.0437\n",
      "Epoch 629/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9308\n",
      "Epoch 629: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9314 - val_loss: 63.1488\n",
      "Epoch 630/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.9627\n",
      "Epoch 630: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9511 - val_loss: 62.7771\n",
      "Epoch 631/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.8575\n",
      "Epoch 631: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8575 - val_loss: 58.8904\n",
      "Epoch 632/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8850\n",
      "Epoch 632: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8670 - val_loss: 61.6213\n",
      "Epoch 633/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8925\n",
      "Epoch 633: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8732 - val_loss: 57.9044\n",
      "Epoch 634/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8965\n",
      "Epoch 634: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.8726 - val_loss: 59.0478\n",
      "Epoch 635/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.7634\n",
      "Epoch 635: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.7795 - val_loss: 59.5579\n",
      "Epoch 636/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0462\n",
      "Epoch 636: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.0079 - val_loss: 61.1204\n",
      "Epoch 637/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9982\n",
      "Epoch 637: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9642 - val_loss: 57.8445\n",
      "Epoch 638/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.7564\n",
      "Epoch 638: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.7495 - val_loss: 58.5378\n",
      "Epoch 639/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.0300\n",
      "Epoch 639: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.0379 - val_loss: 65.5400\n",
      "Epoch 640/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8086\n",
      "Epoch 640: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 1.8063 - val_loss: 59.8640\n",
      "Epoch 641/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.7504\n",
      "Epoch 641: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7504 - val_loss: 59.7044\n",
      "Epoch 642/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8623\n",
      "Epoch 642: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8590 - val_loss: 58.8889\n",
      "Epoch 643/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.8966\n",
      "Epoch 643: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.9006 - val_loss: 59.2767\n",
      "Epoch 644/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.7250\n",
      "Epoch 644: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7250 - val_loss: 59.0178\n",
      "Epoch 645/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.7179\n",
      "Epoch 645: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7279 - val_loss: 58.0100\n",
      "Epoch 646/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.8000\n",
      "Epoch 646: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.7950 - val_loss: 64.3472\n",
      "Epoch 647/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.8379\n",
      "Epoch 647: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.8246 - val_loss: 63.5343\n",
      "Epoch 648/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.9808\n",
      "Epoch 648: val_loss did not improve from 56.02301\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1.9763 - val_loss: 67.8634\n",
      "Epoch 649/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.9467\n",
      "Epoch 649: val_loss did not improve from 56.02301\n",
      "Restoring model weights from the end of the best epoch: 599.\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9467 - val_loss: 62.4432\n",
      "Epoch 649: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "gru_adam_model = TimeSeriesModel(model_type='gru')\n",
    "# Train the model\n",
    "gru_adam_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_GRU_Model_ADAM_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef9c5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = gru_adam_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b8a2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 7.803936590095737\n",
      "R2 Score: 0.6705111482519727\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1155edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'GRU - ADAM Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3562f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "855c54bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1289.2008\n",
      "Epoch 1: val_loss improved from inf to 684.25623, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 3s 27ms/step - loss: 1228.8191 - val_loss: 684.2562\n",
      "Epoch 2/1000\n",
      "10/37 [=======>......................] - ETA: 0s - loss: 25.7564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/37 [==========================>...] - ETA: 0s - loss: 36.8369\n",
      "Epoch 2: val_loss improved from 684.25623 to 344.74915, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 34.8081 - val_loss: 344.7491\n",
      "Epoch 3/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 40.7431\n",
      "Epoch 3: val_loss did not improve from 344.74915\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 39.4545 - val_loss: 364.4130\n",
      "Epoch 4/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 36.3977\n",
      "Epoch 4: val_loss improved from 344.74915 to 259.93732, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 36.1442 - val_loss: 259.9373\n",
      "Epoch 5/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 8.8762\n",
      "Epoch 5: val_loss improved from 259.93732 to 185.14108, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.2384 - val_loss: 185.1411\n",
      "Epoch 6/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 14.3900\n",
      "Epoch 6: val_loss did not improve from 185.14108\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 14.2339 - val_loss: 197.0550\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 8.4010\n",
      "Epoch 7: val_loss improved from 185.14108 to 121.71671, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.4010 - val_loss: 121.7167\n",
      "Epoch 8/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 38.9212\n",
      "Epoch 8: val_loss did not improve from 121.71671\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 36.5786 - val_loss: 253.5911\n",
      "Epoch 9/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.6950\n",
      "Epoch 9: val_loss did not improve from 121.71671\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.5999 - val_loss: 173.9559\n",
      "Epoch 10/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 15.7748\n",
      "Epoch 10: val_loss did not improve from 121.71671\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 15.5593 - val_loss: 141.1105\n",
      "Epoch 11/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.3660\n",
      "Epoch 11: val_loss improved from 121.71671 to 109.15895, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 5.2806 - val_loss: 109.1590\n",
      "Epoch 12/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2007\n",
      "Epoch 12: val_loss improved from 109.15895 to 90.34507, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1568 - val_loss: 90.3451\n",
      "Epoch 13/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 7.6379\n",
      "Epoch 13: val_loss did not improve from 90.34507\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.2171 - val_loss: 93.8206\n",
      "Epoch 14/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0143\n",
      "Epoch 14: val_loss did not improve from 90.34507\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9741 - val_loss: 110.4650\n",
      "Epoch 15/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10.4586\n",
      "Epoch 15: val_loss did not improve from 90.34507\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 11.7219 - val_loss: 145.3212\n",
      "Epoch 16/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.9221\n",
      "Epoch 16: val_loss improved from 90.34507 to 77.17053, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 6.0465 - val_loss: 77.1705\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.8946\n",
      "Epoch 17: val_loss did not improve from 77.17053\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 11.8946 - val_loss: 124.6384\n",
      "Epoch 18/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1625\n",
      "Epoch 18: val_loss did not improve from 77.17053\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0861 - val_loss: 83.1472\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 6.8212\n",
      "Epoch 19: val_loss did not improve from 77.17053\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.8212 - val_loss: 90.7186\n",
      "Epoch 20/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1899\n",
      "Epoch 20: val_loss improved from 77.17053 to 74.60213, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4161 - val_loss: 74.6021\n",
      "Epoch 21/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.7961\n",
      "Epoch 21: val_loss improved from 74.60213 to 72.24853, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 7.8195 - val_loss: 72.2485\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1452\n",
      "Epoch 22: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.1452 - val_loss: 86.5418\n",
      "Epoch 23/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7834\n",
      "Epoch 23: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7850 - val_loss: 99.8006\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.9542\n",
      "Epoch 24: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.9542 - val_loss: 107.1566\n",
      "Epoch 25/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.7388\n",
      "Epoch 25: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 6.4537 - val_loss: 104.7766\n",
      "Epoch 26/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9724\n",
      "Epoch 26: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.9088 - val_loss: 85.8959\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1678\n",
      "Epoch 27: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.1678 - val_loss: 89.6075\n",
      "Epoch 28/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9287\n",
      "Epoch 28: val_loss did not improve from 72.24853\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8821 - val_loss: 72.6450\n",
      "Epoch 29/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.2864\n",
      "Epoch 29: val_loss improved from 72.24853 to 70.72865, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.2316 - val_loss: 70.7287\n",
      "Epoch 30/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.2490\n",
      "Epoch 30: val_loss did not improve from 70.72865\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.0331 - val_loss: 78.0973\n",
      "Epoch 31/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.8295\n",
      "Epoch 31: val_loss did not improve from 70.72865\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 4.9900 - val_loss: 105.7206\n",
      "Epoch 32/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5657\n",
      "Epoch 32: val_loss did not improve from 70.72865\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.7909 - val_loss: 85.0439\n",
      "Epoch 33/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.7510\n",
      "Epoch 33: val_loss did not improve from 70.72865\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 4.6393 - val_loss: 76.8042\n",
      "Epoch 34/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7734\n",
      "Epoch 34: val_loss did not improve from 70.72865\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7435 - val_loss: 77.4930\n",
      "Epoch 35/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4981\n",
      "Epoch 35: val_loss improved from 70.72865 to 65.83206, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5421 - val_loss: 65.8321\n",
      "Epoch 36/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0302\n",
      "Epoch 36: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9459 - val_loss: 79.1352\n",
      "Epoch 37/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4035\n",
      "Epoch 37: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 4.3768 - val_loss: 75.6858\n",
      "Epoch 38/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7532\n",
      "Epoch 38: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7545 - val_loss: 102.3599\n",
      "Epoch 39/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1586\n",
      "Epoch 39: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.9825 - val_loss: 81.0831\n",
      "Epoch 40/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1850\n",
      "Epoch 40: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.0635 - val_loss: 84.4239\n",
      "Epoch 41/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.1601\n",
      "Epoch 41: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.1440 - val_loss: 109.8971\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6431\n",
      "Epoch 42: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7464 - val_loss: 70.8520\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5693\n",
      "Epoch 43: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5693 - val_loss: 77.4875\n",
      "Epoch 44/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1900\n",
      "Epoch 44: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.2174 - val_loss: 70.5601\n",
      "Epoch 45/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8849\n",
      "Epoch 45: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7542 - val_loss: 68.5046\n",
      "Epoch 46/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.4004\n",
      "Epoch 46: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3467 - val_loss: 69.2551\n",
      "Epoch 47/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1701\n",
      "Epoch 47: val_loss did not improve from 65.83206\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1567 - val_loss: 77.5550\n",
      "Epoch 48/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7071\n",
      "Epoch 48: val_loss improved from 65.83206 to 64.87497, saving model to Best_GRU_Model_SGD_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6691 - val_loss: 64.8750\n",
      "Epoch 49/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4694\n",
      "Epoch 49: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4217 - val_loss: 78.0751\n",
      "Epoch 50/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3057\n",
      "Epoch 50: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2058 - val_loss: 75.7332\n",
      "Epoch 51/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.9840\n",
      "Epoch 51: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9536 - val_loss: 74.9497\n",
      "Epoch 52/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.2159\n",
      "Epoch 52: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.1070 - val_loss: 75.5627\n",
      "Epoch 53/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0382\n",
      "Epoch 53: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9191 - val_loss: 76.8251\n",
      "Epoch 54/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1518\n",
      "Epoch 54: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.2780 - val_loss: 138.0317\n",
      "Epoch 55/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.2671\n",
      "Epoch 55: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1120 - val_loss: 77.2353\n",
      "Epoch 56/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5649\n",
      "Epoch 56: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4444 - val_loss: 70.0812\n",
      "Epoch 57/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3449\n",
      "Epoch 57: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3803 - val_loss: 70.0885\n",
      "Epoch 58/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.6727\n",
      "Epoch 58: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5575 - val_loss: 88.0640\n",
      "Epoch 59/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5845\n",
      "Epoch 59: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.4679 - val_loss: 81.0703\n",
      "Epoch 60/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1202\n",
      "Epoch 60: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0380 - val_loss: 86.8864\n",
      "Epoch 61/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6238\n",
      "Epoch 61: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5851 - val_loss: 73.5299\n",
      "Epoch 62/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0051\n",
      "Epoch 62: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.8981 - val_loss: 78.2192\n",
      "Epoch 63/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0136\n",
      "Epoch 63: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9455 - val_loss: 70.6122\n",
      "Epoch 64/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.9819\n",
      "Epoch 64: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.8960 - val_loss: 81.4907\n",
      "Epoch 65/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.0509\n",
      "Epoch 65: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.0077 - val_loss: 78.1764\n",
      "Epoch 66/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9427\n",
      "Epoch 66: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8896 - val_loss: 73.7245\n",
      "Epoch 67/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3171\n",
      "Epoch 67: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3180 - val_loss: 81.4715\n",
      "Epoch 68/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0899\n",
      "Epoch 68: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.0070 - val_loss: 73.0922\n",
      "Epoch 69/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1289\n",
      "Epoch 69: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1042 - val_loss: 86.8565\n",
      "Epoch 70/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9769\n",
      "Epoch 70: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9456 - val_loss: 71.7628\n",
      "Epoch 71/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2165\n",
      "Epoch 71: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2600 - val_loss: 70.9134\n",
      "Epoch 72/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.7391\n",
      "Epoch 72: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7069 - val_loss: 81.5873\n",
      "Epoch 73/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9336\n",
      "Epoch 73: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9318 - val_loss: 87.7360\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4656\n",
      "Epoch 74: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4656 - val_loss: 64.9129\n",
      "Epoch 75/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3597\n",
      "Epoch 75: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3379 - val_loss: 70.2549\n",
      "Epoch 76/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7115\n",
      "Epoch 76: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8793 - val_loss: 78.6743\n",
      "Epoch 77/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6801\n",
      "Epoch 77: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.6921 - val_loss: 78.8122\n",
      "Epoch 78/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6564\n",
      "Epoch 78: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5956 - val_loss: 88.8580\n",
      "Epoch 79/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1362\n",
      "Epoch 79: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0920 - val_loss: 74.3494\n",
      "Epoch 80/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9323\n",
      "Epoch 80: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8473 - val_loss: 74.5468\n",
      "Epoch 81/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8148\n",
      "Epoch 81: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0389 - val_loss: 68.1793\n",
      "Epoch 82/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6399\n",
      "Epoch 82: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6396 - val_loss: 68.6269\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5980\n",
      "Epoch 83: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5980 - val_loss: 83.1724\n",
      "Epoch 84/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0606\n",
      "Epoch 84: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0323 - val_loss: 74.6584\n",
      "Epoch 85/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4859\n",
      "Epoch 85: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4564 - val_loss: 75.4687\n",
      "Epoch 86/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4725\n",
      "Epoch 86: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4550 - val_loss: 75.7581\n",
      "Epoch 87/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5915\n",
      "Epoch 87: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.5943 - val_loss: 73.5116\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5903\n",
      "Epoch 88: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5903 - val_loss: 83.1329\n",
      "Epoch 89/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4370\n",
      "Epoch 89: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.4181 - val_loss: 73.3543\n",
      "Epoch 90/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0237\n",
      "Epoch 90: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 4.1598 - val_loss: 69.9455\n",
      "Epoch 91/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4437\n",
      "Epoch 91: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3985 - val_loss: 72.5418\n",
      "Epoch 92/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2259\n",
      "Epoch 92: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1919 - val_loss: 82.1835\n",
      "Epoch 93/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6847\n",
      "Epoch 93: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.6424 - val_loss: 83.2757\n",
      "Epoch 94/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2158\n",
      "Epoch 94: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.2018 - val_loss: 79.0586\n",
      "Epoch 95/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3415\n",
      "Epoch 95: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2615 - val_loss: 74.8064\n",
      "Epoch 96/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9051\n",
      "Epoch 96: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.9479 - val_loss: 78.1646\n",
      "Epoch 97/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3034\n",
      "Epoch 97: val_loss did not improve from 64.87497\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3478 - val_loss: 84.9011\n",
      "Epoch 98/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0891\n",
      "Epoch 98: val_loss did not improve from 64.87497\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1082 - val_loss: 74.7269\n",
      "Epoch 98: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "gru_sgd_model = TimeSeriesModel(model_type='gru', optimizer = 'sgd')\n",
    "# Train the model\n",
    "gru_sgd_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_GRU_Model_SGD_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "609ec6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_preds = gru_sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "068c9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.40073144599924\n",
      "R2 Score: 0.6181898549353229\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9226c546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'GRU - SGD Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dcc8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24751c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5767.7549\n",
      "Epoch 1: val_loss improved from inf to 21120.31836, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 4s 34ms/step - loss: 5711.1304 - val_loss: 21120.3184\n",
      "Epoch 2/1000\n",
      " 9/37 [======>.......................] - ETA: 0s - loss: 4784.0688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 0s - loss: 4928.2749\n",
      "Epoch 2: val_loss improved from 21120.31836 to 20320.98438, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4901.2012 - val_loss: 20320.9844\n",
      "Epoch 3/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4596.4067\n",
      "Epoch 3: val_loss improved from 20320.98438 to 19639.59180, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4607.5718 - val_loss: 19639.5918\n",
      "Epoch 4/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4307.6338\n",
      "Epoch 4: val_loss improved from 19639.59180 to 18974.37305, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4336.2319 - val_loss: 18974.3730\n",
      "Epoch 5/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4122.9580\n",
      "Epoch 5: val_loss improved from 18974.37305 to 18332.02734, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4085.3384 - val_loss: 18332.0273\n",
      "Epoch 6/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3880.1787\n",
      "Epoch 6: val_loss improved from 18332.02734 to 17705.87109, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3845.6523 - val_loss: 17705.8711\n",
      "Epoch 7/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3632.4341\n",
      "Epoch 7: val_loss improved from 17705.87109 to 17085.02539, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3617.1638 - val_loss: 17085.0254\n",
      "Epoch 8/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3401.4050\n",
      "Epoch 8: val_loss improved from 17085.02539 to 16483.83398, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3400.3057 - val_loss: 16483.8340\n",
      "Epoch 9/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3211.7434\n",
      "Epoch 9: val_loss improved from 16483.83398 to 15882.58789, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3192.8953 - val_loss: 15882.5879\n",
      "Epoch 10/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3034.4011\n",
      "Epoch 10: val_loss improved from 15882.58789 to 15303.07422, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2998.3518 - val_loss: 15303.0742\n",
      "Epoch 11/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2780.5627\n",
      "Epoch 11: val_loss improved from 15303.07422 to 14728.52148, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2813.4731 - val_loss: 14728.5215\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2643.3757\n",
      "Epoch 12: val_loss improved from 14728.52148 to 14173.04102, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2643.3757 - val_loss: 14173.0410\n",
      "Epoch 13/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2485.6978\n",
      "Epoch 13: val_loss improved from 14173.04102 to 13634.57520, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2484.9297 - val_loss: 13634.5752\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2333.6567\n",
      "Epoch 14: val_loss improved from 13634.57520 to 13094.55176, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2333.6567 - val_loss: 13094.5518\n",
      "Epoch 15/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2192.8308\n",
      "Epoch 15: val_loss improved from 13094.55176 to 12580.35840, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 2195.6436 - val_loss: 12580.3584\n",
      "Epoch 16/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2048.4338\n",
      "Epoch 16: val_loss improved from 12580.35840 to 12073.20312, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2069.7715 - val_loss: 12073.2031\n",
      "Epoch 17/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1970.9973\n",
      "Epoch 17: val_loss improved from 12073.20312 to 11591.74805, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 1956.6489 - val_loss: 11591.7480\n",
      "Epoch 18/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1836.9257\n",
      "Epoch 18: val_loss improved from 11591.74805 to 11107.34082, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1851.5824 - val_loss: 11107.3408\n",
      "Epoch 19/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1750.7833\n",
      "Epoch 19: val_loss improved from 11107.34082 to 10656.49805, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 1760.4658 - val_loss: 10656.4980\n",
      "Epoch 20/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1650.6519\n",
      "Epoch 20: val_loss improved from 10656.49805 to 10212.87402, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1679.1416 - val_loss: 10212.8740\n",
      "Epoch 21/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1616.1265\n",
      "Epoch 21: val_loss improved from 10212.87402 to 9776.09570, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 1607.3672 - val_loss: 9776.0957\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1545.4675\n",
      "Epoch 22: val_loss improved from 9776.09570 to 9353.57324, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 1545.4675 - val_loss: 9353.5732\n",
      "Epoch 23/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1491.9657\n",
      "Epoch 23: val_loss improved from 9353.57324 to 8955.78027, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 1493.2324 - val_loss: 8955.7803\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1454.6781\n",
      "Epoch 24: val_loss improved from 8955.78027 to 8605.60547, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 1454.6781 - val_loss: 8605.6055\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1427.3496\n",
      "Epoch 25: val_loss improved from 8605.60547 to 8312.63086, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 34ms/step - loss: 1427.3496 - val_loss: 8312.6309\n",
      "Epoch 26/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1394.5342\n",
      "Epoch 26: val_loss improved from 8312.63086 to 8035.22168, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 1406.4269 - val_loss: 8035.2217\n",
      "Epoch 27/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1410.6364\n",
      "Epoch 27: val_loss improved from 8035.22168 to 7837.37842, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 1393.5946 - val_loss: 7837.3784\n",
      "Epoch 28/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1389.4487\n",
      "Epoch 28: val_loss improved from 7837.37842 to 7667.18604, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 1385.8599 - val_loss: 7667.1860\n",
      "Epoch 29/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1382.5891\n",
      "Epoch 29: val_loss improved from 7667.18604 to 7534.46191, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 1381.2186 - val_loss: 7534.4619\n",
      "Epoch 30/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1381.8761\n",
      "Epoch 30: val_loss improved from 7534.46191 to 7445.41699, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 1377.1515 - val_loss: 7445.4170\n",
      "Epoch 31/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1326.7954\n",
      "Epoch 31: val_loss improved from 7445.41699 to 7401.81641, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1346.9071 - val_loss: 7401.8164\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1196.4287\n",
      "Epoch 32: val_loss improved from 7401.81641 to 7173.94873, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1196.4287 - val_loss: 7173.9487\n",
      "Epoch 33/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 907.6563\n",
      "Epoch 33: val_loss improved from 7173.94873 to 6668.78955, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 907.3596 - val_loss: 6668.7896\n",
      "Epoch 34/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 818.0604\n",
      "Epoch 34: val_loss improved from 6668.78955 to 6269.04346, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 806.3365 - val_loss: 6269.0435\n",
      "Epoch 35/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 739.2177\n",
      "Epoch 35: val_loss improved from 6269.04346 to 5906.61475, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 737.3341 - val_loss: 5906.6147\n",
      "Epoch 36/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 674.6482\n",
      "Epoch 36: val_loss improved from 5906.61475 to 5552.43359, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 673.5181 - val_loss: 5552.4336\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 614.1820\n",
      "Epoch 37: val_loss improved from 5552.43359 to 5208.28369, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 614.1820 - val_loss: 5208.2837\n",
      "Epoch 38/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 563.0057\n",
      "Epoch 38: val_loss improved from 5208.28369 to 4903.83594, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 559.5720 - val_loss: 4903.8359\n",
      "Epoch 39/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 512.5805\n",
      "Epoch 39: val_loss improved from 4903.83594 to 4612.52539, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 506.3666 - val_loss: 4612.5254\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 455.5902\n",
      "Epoch 40: val_loss improved from 4612.52539 to 4304.94727, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 455.5902 - val_loss: 4304.9473\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 409.1456\n",
      "Epoch 41: val_loss improved from 4304.94727 to 4018.64697, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 409.1456 - val_loss: 4018.6470\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 350.2650\n",
      "Epoch 42: val_loss improved from 4018.64697 to 3728.74927, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 363.0551 - val_loss: 3728.7493\n",
      "Epoch 43/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 323.4808\n",
      "Epoch 43: val_loss improved from 3728.74927 to 3476.26001, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 320.6455 - val_loss: 3476.2600\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 284.5657\n",
      "Epoch 44: val_loss improved from 3476.26001 to 3225.37549, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 284.5657 - val_loss: 3225.3755\n",
      "Epoch 45/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 257.8799\n",
      "Epoch 45: val_loss improved from 3225.37549 to 2979.71533, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 248.4483 - val_loss: 2979.7153\n",
      "Epoch 46/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 218.1826\n",
      "Epoch 46: val_loss improved from 2979.71533 to 2744.74146, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 217.0176 - val_loss: 2744.7415\n",
      "Epoch 47/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 191.5071\n",
      "Epoch 47: val_loss improved from 2744.74146 to 2535.76782, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 188.0989 - val_loss: 2535.7678\n",
      "Epoch 48/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 161.9838\n",
      "Epoch 48: val_loss improved from 2535.76782 to 2318.37329, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 161.9994 - val_loss: 2318.3733\n",
      "Epoch 49/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 140.3456\n",
      "Epoch 49: val_loss improved from 2318.37329 to 2123.85400, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 139.1201 - val_loss: 2123.8540\n",
      "Epoch 50/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 120.7992\n",
      "Epoch 50: val_loss improved from 2123.85400 to 1937.94873, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 119.2248 - val_loss: 1937.9487\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 99.6788\n",
      "Epoch 51: val_loss improved from 1937.94873 to 1759.60327, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 99.6788 - val_loss: 1759.6033\n",
      "Epoch 52/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 90.0245\n",
      "Epoch 52: val_loss improved from 1759.60327 to 1604.30518, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 85.1467 - val_loss: 1604.3052\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 70.5522\n",
      "Epoch 53: val_loss improved from 1604.30518 to 1447.34619, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 70.5522 - val_loss: 1447.3462\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 60.2790\n",
      "Epoch 54: val_loss improved from 1447.34619 to 1306.47754, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 60.2790 - val_loss: 1306.4775\n",
      "Epoch 55/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 53.1975\n",
      "Epoch 55: val_loss improved from 1306.47754 to 1195.61963, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 52.3038 - val_loss: 1195.6196\n",
      "Epoch 56/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 45.9492\n",
      "Epoch 56: val_loss improved from 1195.61963 to 1089.51465, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 46.4256 - val_loss: 1089.5146\n",
      "Epoch 57/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 40.4208\n",
      "Epoch 57: val_loss improved from 1089.51465 to 1007.88171, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 41.5792 - val_loss: 1007.8817\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 39.1026\n",
      "Epoch 58: val_loss improved from 1007.88171 to 945.93988, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 39.1026 - val_loss: 945.9399\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 36.1296\n",
      "Epoch 59: val_loss improved from 945.93988 to 906.89984, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 36.1296 - val_loss: 906.8998\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 29.5871\n",
      "Epoch 60: val_loss improved from 906.89984 to 795.81335, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 29.5871 - val_loss: 795.8134\n",
      "Epoch 61/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 25.9252\n",
      "Epoch 61: val_loss improved from 795.81335 to 718.08954, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 25.2504 - val_loss: 718.0895\n",
      "Epoch 62/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 21.9398\n",
      "Epoch 62: val_loss improved from 718.08954 to 662.23822, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 21.9654 - val_loss: 662.2382\n",
      "Epoch 63/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 18.6974\n",
      "Epoch 63: val_loss improved from 662.23822 to 603.43823, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 19.8747 - val_loss: 603.4382\n",
      "Epoch 64/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 17.0517\n",
      "Epoch 64: val_loss improved from 603.43823 to 555.36694, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 17.5589 - val_loss: 555.3669\n",
      "Epoch 65/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 15.8528\n",
      "Epoch 65: val_loss improved from 555.36694 to 512.46240, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 15.4200 - val_loss: 512.4624\n",
      "Epoch 66/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 14.4512\n",
      "Epoch 66: val_loss improved from 512.46240 to 473.82379, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 14.3318 - val_loss: 473.8238\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.2666\n",
      "Epoch 67: val_loss improved from 473.82379 to 452.41541, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 12.2666 - val_loss: 452.4154\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8699\n",
      "Epoch 68: val_loss improved from 452.41541 to 393.45038, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 10.8699 - val_loss: 393.4504\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9411 \n",
      "Epoch 69: val_loss improved from 393.45038 to 366.06570, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.9411 - val_loss: 366.0657\n",
      "Epoch 70/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 9.5453\n",
      "Epoch 70: val_loss improved from 366.06570 to 334.30200, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 9.2274 - val_loss: 334.3020\n",
      "Epoch 71/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.8045\n",
      "Epoch 71: val_loss improved from 334.30200 to 316.12061, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 8.3613 - val_loss: 316.1206\n",
      "Epoch 72/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 8.0352\n",
      "Epoch 72: val_loss improved from 316.12061 to 298.50787, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 7.7726 - val_loss: 298.5079\n",
      "Epoch 73/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.3332\n",
      "Epoch 73: val_loss improved from 298.50787 to 284.53925, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 7.2468 - val_loss: 284.5392\n",
      "Epoch 74/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 7.0923\n",
      "Epoch 74: val_loss improved from 284.53925 to 266.51123, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 6.9209 - val_loss: 266.5112\n",
      "Epoch 75/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 7.5628\n",
      "Epoch 75: val_loss improved from 266.51123 to 261.72473, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 7.4815 - val_loss: 261.7247\n",
      "Epoch 76/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 6.3526\n",
      "Epoch 76: val_loss improved from 261.72473 to 251.49557, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 6.3796 - val_loss: 251.4956\n",
      "Epoch 77/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.8876\n",
      "Epoch 77: val_loss improved from 251.49557 to 245.33803, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.9301 - val_loss: 245.3380\n",
      "Epoch 78/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.1719\n",
      "Epoch 78: val_loss did not improve from 245.33803\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 6.2528 - val_loss: 275.0488\n",
      "Epoch 79/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 6.0855\n",
      "Epoch 79: val_loss improved from 245.33803 to 237.79308, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 5.9841 - val_loss: 237.7931\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.7962\n",
      "Epoch 80: val_loss improved from 237.79308 to 230.97426, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 5.7962 - val_loss: 230.9743\n",
      "Epoch 81/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.2720\n",
      "Epoch 81: val_loss improved from 230.97426 to 229.69539, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 6.1073 - val_loss: 229.6954\n",
      "Epoch 82/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.9975\n",
      "Epoch 82: val_loss improved from 229.69539 to 222.00481, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.0634 - val_loss: 222.0048\n",
      "Epoch 83/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 6.3995\n",
      "Epoch 83: val_loss improved from 222.00481 to 221.86938, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 7.0446 - val_loss: 221.8694\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.1862\n",
      "Epoch 84: val_loss improved from 221.86938 to 218.51570, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.1862 - val_loss: 218.5157\n",
      "Epoch 85/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 5.4287\n",
      "Epoch 85: val_loss improved from 218.51570 to 217.37759, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.4735 - val_loss: 217.3776\n",
      "Epoch 86/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 5.6343\n",
      "Epoch 86: val_loss improved from 217.37759 to 217.29279, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.8499 - val_loss: 217.2928\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 5.6893\n",
      "Epoch 87: val_loss improved from 217.29279 to 214.70084, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.6893 - val_loss: 214.7008\n",
      "Epoch 88/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 5.0189\n",
      "Epoch 88: val_loss did not improve from 214.70084\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 4.9495 - val_loss: 216.6578\n",
      "Epoch 89/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.8203\n",
      "Epoch 89: val_loss improved from 214.70084 to 213.20345, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.6516 - val_loss: 213.2034\n",
      "Epoch 90/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 4.8941\n",
      "Epoch 90: val_loss improved from 213.20345 to 210.58818, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 5.2509 - val_loss: 210.5882\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.8933\n",
      "Epoch 91: val_loss improved from 210.58818 to 209.40094, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.8933 - val_loss: 209.4009\n",
      "Epoch 92/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 5.2464\n",
      "Epoch 92: val_loss improved from 209.40094 to 207.04053, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 5.4331 - val_loss: 207.0405\n",
      "Epoch 93/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.9715\n",
      "Epoch 93: val_loss improved from 207.04053 to 204.57451, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.9403 - val_loss: 204.5745\n",
      "Epoch 94/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 5.2504\n",
      "Epoch 94: val_loss improved from 204.57451 to 202.05177, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 5.1116 - val_loss: 202.0518\n",
      "Epoch 95/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 5.4172\n",
      "Epoch 95: val_loss improved from 202.05177 to 199.09508, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 5.3469 - val_loss: 199.0951\n",
      "Epoch 96/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.6855\n",
      "Epoch 96: val_loss improved from 199.09508 to 198.64641, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.6907 - val_loss: 198.6464\n",
      "Epoch 97/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.8822\n",
      "Epoch 97: val_loss improved from 198.64641 to 195.09509, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.8132 - val_loss: 195.0951\n",
      "Epoch 98/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.7583\n",
      "Epoch 98: val_loss did not improve from 195.09509\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7285 - val_loss: 195.8891\n",
      "Epoch 99/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5254\n",
      "Epoch 99: val_loss did not improve from 195.09509\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.5150 - val_loss: 212.4291\n",
      "Epoch 100/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 5.1994\n",
      "Epoch 100: val_loss did not improve from 195.09509\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 5.1567 - val_loss: 195.9369\n",
      "Epoch 101/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.7567\n",
      "Epoch 101: val_loss improved from 195.09509 to 189.25270, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.6903 - val_loss: 189.2527\n",
      "Epoch 102/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.5199\n",
      "Epoch 102: val_loss improved from 189.25270 to 185.15036, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 4.5371 - val_loss: 185.1504\n",
      "Epoch 103/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.6451\n",
      "Epoch 103: val_loss improved from 185.15036 to 182.52446, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.5764 - val_loss: 182.5245\n",
      "Epoch 104/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4752\n",
      "Epoch 104: val_loss did not improve from 182.52446\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 4.5661 - val_loss: 206.0447\n",
      "Epoch 105/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 5.0164\n",
      "Epoch 105: val_loss did not improve from 182.52446\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 4.9502 - val_loss: 193.6571\n",
      "Epoch 106/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.6589\n",
      "Epoch 106: val_loss did not improve from 182.52446\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 4.7238 - val_loss: 185.3531\n",
      "Epoch 107/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.8469\n",
      "Epoch 107: val_loss improved from 182.52446 to 179.24052, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 4.8442 - val_loss: 179.2405\n",
      "Epoch 108/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5589\n",
      "Epoch 108: val_loss improved from 179.24052 to 176.13718, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 4.6507 - val_loss: 176.1372\n",
      "Epoch 109/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4014\n",
      "Epoch 109: val_loss improved from 176.13718 to 173.63359, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.3603 - val_loss: 173.6336\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.5120\n",
      "Epoch 110: val_loss did not improve from 173.63359\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.5120 - val_loss: 173.8419\n",
      "Epoch 111/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3774\n",
      "Epoch 111: val_loss did not improve from 173.63359\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3228 - val_loss: 175.6902\n",
      "Epoch 112/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.4324\n",
      "Epoch 112: val_loss improved from 173.63359 to 169.73311, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.4397 - val_loss: 169.7331\n",
      "Epoch 113/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.5741\n",
      "Epoch 113: val_loss did not improve from 169.73311\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.5996 - val_loss: 175.6750\n",
      "Epoch 114/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.5318\n",
      "Epoch 114: val_loss improved from 169.73311 to 166.88118, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.3920 - val_loss: 166.8812\n",
      "Epoch 115/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.4359\n",
      "Epoch 115: val_loss improved from 166.88118 to 164.62471, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.5419 - val_loss: 164.6247\n",
      "Epoch 116/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2594\n",
      "Epoch 116: val_loss did not improve from 164.62471\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.2674 - val_loss: 166.9774\n",
      "Epoch 117/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3620\n",
      "Epoch 117: val_loss improved from 164.62471 to 161.24783, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.2918 - val_loss: 161.2478\n",
      "Epoch 118/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.4686\n",
      "Epoch 118: val_loss did not improve from 161.24783\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.3380 - val_loss: 171.4767\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1942\n",
      "Epoch 119: val_loss did not improve from 161.24783\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.1942 - val_loss: 164.0557\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.2375\n",
      "Epoch 120: val_loss improved from 161.24783 to 159.22794, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2375 - val_loss: 159.2279\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9199\n",
      "Epoch 121: val_loss improved from 159.22794 to 153.57410, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.9199 - val_loss: 153.5741\n",
      "Epoch 122/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.3266\n",
      "Epoch 122: val_loss did not improve from 153.57410\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.3094 - val_loss: 154.3818\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.1870\n",
      "Epoch 123: val_loss improved from 153.57410 to 151.46822, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1870 - val_loss: 151.4682\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.0128\n",
      "Epoch 124: val_loss improved from 151.46822 to 150.86340, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0128 - val_loss: 150.8634\n",
      "Epoch 125/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 4.1712\n",
      "Epoch 125: val_loss did not improve from 150.86340\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.1586 - val_loss: 151.6604\n",
      "Epoch 126/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8996\n",
      "Epoch 126: val_loss did not improve from 150.86340\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.9271 - val_loss: 151.4658\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 4.2625\n",
      "Epoch 127: val_loss improved from 150.86340 to 150.04242, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.2625 - val_loss: 150.0424\n",
      "Epoch 128/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9971\n",
      "Epoch 128: val_loss did not improve from 150.04242\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0233 - val_loss: 158.7317\n",
      "Epoch 129/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.1540\n",
      "Epoch 129: val_loss improved from 150.04242 to 144.36967, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 4.1253 - val_loss: 144.3697\n",
      "Epoch 130/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9662\n",
      "Epoch 130: val_loss did not improve from 144.36967\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9829 - val_loss: 146.9243\n",
      "Epoch 131/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0330\n",
      "Epoch 131: val_loss did not improve from 144.36967\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0477 - val_loss: 153.7979\n",
      "Epoch 132/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9991\n",
      "Epoch 132: val_loss improved from 144.36967 to 142.29114, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.9619 - val_loss: 142.2911\n",
      "Epoch 133/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.9972\n",
      "Epoch 133: val_loss did not improve from 142.29114\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.0126 - val_loss: 143.4575\n",
      "Epoch 134/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.2344\n",
      "Epoch 134: val_loss did not improve from 142.29114\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.1893 - val_loss: 145.1003\n",
      "Epoch 135/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1615\n",
      "Epoch 135: val_loss improved from 142.29114 to 140.63449, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 4.1463 - val_loss: 140.6345\n",
      "Epoch 136/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1278\n",
      "Epoch 136: val_loss did not improve from 140.63449\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.1161 - val_loss: 155.8333\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.8586\n",
      "Epoch 137: val_loss did not improve from 140.63449\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.8586 - val_loss: 150.3395\n",
      "Epoch 138/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.1019\n",
      "Epoch 138: val_loss did not improve from 140.63449\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.2539 - val_loss: 141.9266\n",
      "Epoch 139/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.1085\n",
      "Epoch 139: val_loss improved from 140.63449 to 135.99432, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9648 - val_loss: 135.9943\n",
      "Epoch 140/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7634\n",
      "Epoch 140: val_loss did not improve from 135.99432\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.9299 - val_loss: 137.3362\n",
      "Epoch 141/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8954\n",
      "Epoch 141: val_loss did not improve from 135.99432\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9267 - val_loss: 137.6667\n",
      "Epoch 142/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9897\n",
      "Epoch 142: val_loss did not improve from 135.99432\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 4.0457 - val_loss: 138.1568\n",
      "Epoch 143/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7822\n",
      "Epoch 143: val_loss did not improve from 135.99432\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7742 - val_loss: 139.5936\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9507\n",
      "Epoch 144: val_loss improved from 135.99432 to 134.54039, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.9507 - val_loss: 134.5404\n",
      "Epoch 145/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 4.0098\n",
      "Epoch 145: val_loss did not improve from 134.54039\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.9250 - val_loss: 134.9195\n",
      "Epoch 146/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9737\n",
      "Epoch 146: val_loss improved from 134.54039 to 132.97191, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9487 - val_loss: 132.9719\n",
      "Epoch 147/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 4.0605\n",
      "Epoch 147: val_loss improved from 132.97191 to 131.68336, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 4.0221 - val_loss: 131.6834\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.9998\n",
      "Epoch 148: val_loss did not improve from 131.68336\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.9998 - val_loss: 137.1280\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6568\n",
      "Epoch 149: val_loss did not improve from 131.68336\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6568 - val_loss: 136.7071\n",
      "Epoch 150/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7139\n",
      "Epoch 150: val_loss improved from 131.68336 to 129.57372, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.7757 - val_loss: 129.5737\n",
      "Epoch 151/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 4.0493\n",
      "Epoch 151: val_loss did not improve from 129.57372\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 4.0224 - val_loss: 131.3910\n",
      "Epoch 152/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8878\n",
      "Epoch 152: val_loss improved from 129.57372 to 126.65530, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8669 - val_loss: 126.6553\n",
      "Epoch 153/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7614\n",
      "Epoch 153: val_loss improved from 126.65530 to 125.63995, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8857 - val_loss: 125.6400\n",
      "Epoch 154/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7176\n",
      "Epoch 154: val_loss did not improve from 125.63995\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7535 - val_loss: 149.6044\n",
      "Epoch 155/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.9264\n",
      "Epoch 155: val_loss did not improve from 125.63995\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.8987 - val_loss: 129.7672\n",
      "Epoch 156/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7744\n",
      "Epoch 156: val_loss did not improve from 125.63995\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7334 - val_loss: 131.3625\n",
      "Epoch 157/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.7993\n",
      "Epoch 157: val_loss did not improve from 125.63995\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7437 - val_loss: 130.1878\n",
      "Epoch 158/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.9587\n",
      "Epoch 158: val_loss improved from 125.63995 to 123.74625, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.8424 - val_loss: 123.7462\n",
      "Epoch 159/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.7233\n",
      "Epoch 159: val_loss improved from 123.74625 to 122.73972, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6920 - val_loss: 122.7397\n",
      "Epoch 160/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.8101\n",
      "Epoch 160: val_loss improved from 122.73972 to 121.71747, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6977 - val_loss: 121.7175\n",
      "Epoch 161/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8771\n",
      "Epoch 161: val_loss improved from 121.71747 to 120.50906, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.9335 - val_loss: 120.5091\n",
      "Epoch 162/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6907\n",
      "Epoch 162: val_loss did not improve from 120.50906\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5840 - val_loss: 124.0982\n",
      "Epoch 163/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8072\n",
      "Epoch 163: val_loss did not improve from 120.50906\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8068 - val_loss: 125.2986\n",
      "Epoch 164/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.8291\n",
      "Epoch 164: val_loss improved from 120.50906 to 120.10256, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7506 - val_loss: 120.1026\n",
      "Epoch 165/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7593\n",
      "Epoch 165: val_loss improved from 120.10256 to 119.99494, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7949 - val_loss: 119.9949\n",
      "Epoch 166/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7532\n",
      "Epoch 166: val_loss did not improve from 119.99494\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.7314 - val_loss: 121.5203\n",
      "Epoch 167/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4831\n",
      "Epoch 167: val_loss improved from 119.99494 to 117.95123, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5526 - val_loss: 117.9512\n",
      "Epoch 168/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7506\n",
      "Epoch 168: val_loss did not improve from 117.95123\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7683 - val_loss: 118.4987\n",
      "Epoch 169/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6584\n",
      "Epoch 169: val_loss did not improve from 117.95123\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.6088 - val_loss: 118.1836\n",
      "Epoch 170/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6716\n",
      "Epoch 170: val_loss improved from 117.95123 to 117.23122, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7750 - val_loss: 117.2312\n",
      "Epoch 171/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5147\n",
      "Epoch 171: val_loss improved from 117.23122 to 113.85913, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5504 - val_loss: 113.8591\n",
      "Epoch 172/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.8102\n",
      "Epoch 172: val_loss did not improve from 113.85913\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.8021 - val_loss: 117.2639\n",
      "Epoch 173/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6169\n",
      "Epoch 173: val_loss did not improve from 113.85913\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.6082 - val_loss: 119.7586\n",
      "Epoch 174/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7286\n",
      "Epoch 174: val_loss improved from 113.85913 to 112.93597, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.6441 - val_loss: 112.9360\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5984\n",
      "Epoch 175: val_loss did not improve from 112.93597\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5984 - val_loss: 119.5493\n",
      "Epoch 176/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.7789\n",
      "Epoch 176: val_loss did not improve from 112.93597\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.7634 - val_loss: 114.6975\n",
      "Epoch 177/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5517\n",
      "Epoch 177: val_loss improved from 112.93597 to 111.51968, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5857 - val_loss: 111.5197\n",
      "Epoch 178/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6738\n",
      "Epoch 178: val_loss did not improve from 111.51968\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.7079 - val_loss: 113.4545\n",
      "Epoch 179/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.6563\n",
      "Epoch 179: val_loss improved from 111.51968 to 110.68974, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.6578 - val_loss: 110.6897\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7109\n",
      "Epoch 180: val_loss did not improve from 110.68974\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.7109 - val_loss: 111.1803\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4618\n",
      "Epoch 181: val_loss did not improve from 110.68974\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4618 - val_loss: 120.6777\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7568\n",
      "Epoch 182: val_loss improved from 110.68974 to 109.70238, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.7568 - val_loss: 109.7024\n",
      "Epoch 183/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6641\n",
      "Epoch 183: val_loss did not improve from 109.70238\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.6350 - val_loss: 109.8944\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5538\n",
      "Epoch 184: val_loss improved from 109.70238 to 106.45878, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.5538 - val_loss: 106.4588\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.7880\n",
      "Epoch 185: val_loss did not improve from 106.45878\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.7880 - val_loss: 112.8425\n",
      "Epoch 186/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6138\n",
      "Epoch 186: val_loss did not improve from 106.45878\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5049 - val_loss: 110.2933\n",
      "Epoch 187/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5461\n",
      "Epoch 187: val_loss did not improve from 106.45878\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.6025 - val_loss: 106.4897\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.5957\n",
      "Epoch 188: val_loss did not improve from 106.45878\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5957 - val_loss: 108.9871\n",
      "Epoch 189/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2971\n",
      "Epoch 189: val_loss improved from 106.45878 to 105.91810, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4677 - val_loss: 105.9181\n",
      "Epoch 190/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5338\n",
      "Epoch 190: val_loss improved from 105.91810 to 105.78052, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5319 - val_loss: 105.7805\n",
      "Epoch 191/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4618\n",
      "Epoch 191: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5275 - val_loss: 120.5002\n",
      "Epoch 192/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4039\n",
      "Epoch 192: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.3608 - val_loss: 109.6892\n",
      "Epoch 193/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5452\n",
      "Epoch 193: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.6728 - val_loss: 109.8890\n",
      "Epoch 194/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5693\n",
      "Epoch 194: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5438 - val_loss: 113.9789\n",
      "Epoch 195/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6659\n",
      "Epoch 195: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.6317 - val_loss: 111.6156\n",
      "Epoch 196/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.6585\n",
      "Epoch 196: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.7051 - val_loss: 110.5981\n",
      "Epoch 197/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5613\n",
      "Epoch 197: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.5123 - val_loss: 124.5504\n",
      "Epoch 198/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.8172\n",
      "Epoch 198: val_loss did not improve from 105.78052\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.7609 - val_loss: 106.3814\n",
      "Epoch 199/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5120\n",
      "Epoch 199: val_loss improved from 105.78052 to 105.37511, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.7042 - val_loss: 105.3751\n",
      "Epoch 200/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2475\n",
      "Epoch 200: val_loss did not improve from 105.37511\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2749 - val_loss: 105.7787\n",
      "Epoch 201/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5884\n",
      "Epoch 201: val_loss improved from 105.37511 to 101.71385, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.5279 - val_loss: 101.7139\n",
      "Epoch 202/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5546\n",
      "Epoch 202: val_loss did not improve from 101.71385\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5173 - val_loss: 112.4669\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4288\n",
      "Epoch 203: val_loss improved from 101.71385 to 101.12035, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4288 - val_loss: 101.1204\n",
      "Epoch 204/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5471\n",
      "Epoch 204: val_loss did not improve from 101.12035\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5035 - val_loss: 116.7734\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6238\n",
      "Epoch 205: val_loss did not improve from 101.12035\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6238 - val_loss: 104.4411\n",
      "Epoch 206/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3293\n",
      "Epoch 206: val_loss did not improve from 101.12035\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2938 - val_loss: 108.1564\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.6002\n",
      "Epoch 207: val_loss did not improve from 101.12035\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.6002 - val_loss: 104.0490\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2957\n",
      "Epoch 208: val_loss improved from 101.12035 to 100.03873, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2957 - val_loss: 100.0387\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4371\n",
      "Epoch 209: val_loss improved from 100.03873 to 99.14069, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4371 - val_loss: 99.1407\n",
      "Epoch 210/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3977\n",
      "Epoch 210: val_loss did not improve from 99.14069\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4659 - val_loss: 113.6568\n",
      "Epoch 211/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.5040\n",
      "Epoch 211: val_loss did not improve from 99.14069\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4476 - val_loss: 110.4132\n",
      "Epoch 212/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5013\n",
      "Epoch 212: val_loss did not improve from 99.14069\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4554 - val_loss: 99.8016\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3077\n",
      "Epoch 213: val_loss did not improve from 99.14069\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3077 - val_loss: 99.5241\n",
      "Epoch 214/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5382\n",
      "Epoch 214: val_loss improved from 99.14069 to 94.65033, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5283 - val_loss: 94.6503\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4505\n",
      "Epoch 215: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4505 - val_loss: 95.4121\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4134\n",
      "Epoch 216: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4134 - val_loss: 98.2344\n",
      "Epoch 217/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5290\n",
      "Epoch 217: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5782 - val_loss: 103.2252\n",
      "Epoch 218/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3709\n",
      "Epoch 218: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3349 - val_loss: 98.6864\n",
      "Epoch 219/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4019\n",
      "Epoch 219: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.4059 - val_loss: 109.7045\n",
      "Epoch 220/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2418\n",
      "Epoch 220: val_loss did not improve from 94.65033\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2880 - val_loss: 94.9549\n",
      "Epoch 221/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.4048\n",
      "Epoch 221: val_loss improved from 94.65033 to 94.16319, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5316 - val_loss: 94.1632\n",
      "Epoch 222/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4757\n",
      "Epoch 222: val_loss did not improve from 94.16319\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.5140 - val_loss: 98.6490\n",
      "Epoch 223/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4059\n",
      "Epoch 223: val_loss did not improve from 94.16319\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.3266 - val_loss: 97.2123\n",
      "Epoch 224/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4537\n",
      "Epoch 224: val_loss did not improve from 94.16319\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.4165 - val_loss: 95.6734\n",
      "Epoch 225/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.4776\n",
      "Epoch 225: val_loss improved from 94.16319 to 92.95213, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4642 - val_loss: 92.9521\n",
      "Epoch 226/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.4205\n",
      "Epoch 226: val_loss improved from 92.95213 to 92.48592, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4374 - val_loss: 92.4859\n",
      "Epoch 227/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3737\n",
      "Epoch 227: val_loss did not improve from 92.48592\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 3.3613 - val_loss: 96.9417\n",
      "Epoch 228/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3706\n",
      "Epoch 228: val_loss improved from 92.48592 to 91.30096, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2703 - val_loss: 91.3010\n",
      "Epoch 229/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3195\n",
      "Epoch 229: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.4451 - val_loss: 92.9605\n",
      "Epoch 230/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.5092\n",
      "Epoch 230: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.5244 - val_loss: 93.0459\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3151\n",
      "Epoch 231: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.3151 - val_loss: 104.5768\n",
      "Epoch 232/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3789\n",
      "Epoch 232: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3919 - val_loss: 105.7504\n",
      "Epoch 233/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.5462\n",
      "Epoch 233: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.4488 - val_loss: 94.4520\n",
      "Epoch 234/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.6013\n",
      "Epoch 234: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5170 - val_loss: 97.0004\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3855\n",
      "Epoch 235: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3855 - val_loss: 103.2714\n",
      "Epoch 236/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3927\n",
      "Epoch 236: val_loss did not improve from 91.30096\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 3.3795 - val_loss: 100.0569\n",
      "Epoch 237/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3212\n",
      "Epoch 237: val_loss improved from 91.30096 to 87.36026, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 3.3418 - val_loss: 87.3603\n",
      "Epoch 238/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3713\n",
      "Epoch 238: val_loss did not improve from 87.36026\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.2756 - val_loss: 89.5472\n",
      "Epoch 239/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4405\n",
      "Epoch 239: val_loss did not improve from 87.36026\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 3.4150 - val_loss: 99.2086\n",
      "Epoch 240/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1258\n",
      "Epoch 240: val_loss did not improve from 87.36026\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 3.2172 - val_loss: 101.1627\n",
      "Epoch 241/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2753\n",
      "Epoch 241: val_loss did not improve from 87.36026\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.3167 - val_loss: 109.8386\n",
      "Epoch 242/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1773\n",
      "Epoch 242: val_loss improved from 87.36026 to 86.58932, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1444 - val_loss: 86.5893\n",
      "Epoch 243/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1701\n",
      "Epoch 243: val_loss improved from 86.58932 to 86.27450, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.3067 - val_loss: 86.2745\n",
      "Epoch 244/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0657\n",
      "Epoch 244: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1092 - val_loss: 88.6631\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.3711\n",
      "Epoch 245: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3711 - val_loss: 102.5926\n",
      "Epoch 246/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2039\n",
      "Epoch 246: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2817 - val_loss: 97.2837\n",
      "Epoch 247/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2794\n",
      "Epoch 247: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1695 - val_loss: 90.6858\n",
      "Epoch 248/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.3892\n",
      "Epoch 248: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.3607 - val_loss: 98.1534\n",
      "Epoch 249/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1703\n",
      "Epoch 249: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.2849 - val_loss: 89.2132\n",
      "Epoch 250/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3102\n",
      "Epoch 250: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.2704 - val_loss: 87.6170\n",
      "Epoch 251/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2726\n",
      "Epoch 251: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1668 - val_loss: 95.7788\n",
      "Epoch 252/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3953\n",
      "Epoch 252: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.3690 - val_loss: 101.7176\n",
      "Epoch 253/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2307\n",
      "Epoch 253: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1745 - val_loss: 93.2134\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1968\n",
      "Epoch 254: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.1968 - val_loss: 90.0963\n",
      "Epoch 255/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2753\n",
      "Epoch 255: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2315 - val_loss: 89.6734\n",
      "Epoch 256/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3819\n",
      "Epoch 256: val_loss did not improve from 86.27450\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.3291 - val_loss: 92.3317\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2277\n",
      "Epoch 257: val_loss improved from 86.27450 to 83.07194, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 3.2277 - val_loss: 83.0719\n",
      "Epoch 258/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.5926\n",
      "Epoch 258: val_loss did not improve from 83.07194\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.5579 - val_loss: 95.3692\n",
      "Epoch 259/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1470\n",
      "Epoch 259: val_loss did not improve from 83.07194\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1710 - val_loss: 94.4990\n",
      "Epoch 260/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.4387\n",
      "Epoch 260: val_loss did not improve from 83.07194\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3925 - val_loss: 90.0431\n",
      "Epoch 261/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3868\n",
      "Epoch 261: val_loss did not improve from 83.07194\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2976 - val_loss: 89.0241\n",
      "Epoch 262/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.3649\n",
      "Epoch 262: val_loss did not improve from 83.07194\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.3188 - val_loss: 93.5884\n",
      "Epoch 263/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2062\n",
      "Epoch 263: val_loss improved from 83.07194 to 82.05993, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1806 - val_loss: 82.0599\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.4773\n",
      "Epoch 264: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.4773 - val_loss: 94.5097\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2282\n",
      "Epoch 265: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2282 - val_loss: 88.9783\n",
      "Epoch 266/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1324\n",
      "Epoch 266: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1962 - val_loss: 95.0501\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2049\n",
      "Epoch 267: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2049 - val_loss: 86.9634\n",
      "Epoch 268/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1925\n",
      "Epoch 268: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2190 - val_loss: 92.8332\n",
      "Epoch 269/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1605\n",
      "Epoch 269: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.2941 - val_loss: 95.2699\n",
      "Epoch 270/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2163\n",
      "Epoch 270: val_loss did not improve from 82.05993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.3256 - val_loss: 90.0896\n",
      "Epoch 271/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0766\n",
      "Epoch 271: val_loss improved from 82.05993 to 81.46397, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1029 - val_loss: 81.4640\n",
      "Epoch 272/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1748\n",
      "Epoch 272: val_loss did not improve from 81.46397\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1622 - val_loss: 87.9814\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1593\n",
      "Epoch 273: val_loss did not improve from 81.46397\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1593 - val_loss: 95.9593\n",
      "Epoch 274/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3412\n",
      "Epoch 274: val_loss did not improve from 81.46397\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2979 - val_loss: 83.0676\n",
      "Epoch 275/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.3053\n",
      "Epoch 275: val_loss did not improve from 81.46397\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2540 - val_loss: 85.2879\n",
      "Epoch 276/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3239\n",
      "Epoch 276: val_loss did not improve from 81.46397\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2666 - val_loss: 85.7411\n",
      "Epoch 277/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0616\n",
      "Epoch 277: val_loss improved from 81.46397 to 80.95970, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.1136 - val_loss: 80.9597\n",
      "Epoch 278/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2911\n",
      "Epoch 278: val_loss did not improve from 80.95970\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2354 - val_loss: 86.4678\n",
      "Epoch 279/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1970\n",
      "Epoch 279: val_loss improved from 80.95970 to 80.61937, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1069 - val_loss: 80.6194\n",
      "Epoch 280/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1492\n",
      "Epoch 280: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1881 - val_loss: 84.5723\n",
      "Epoch 281/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.3035\n",
      "Epoch 281: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1854 - val_loss: 81.6510\n",
      "Epoch 282/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1575\n",
      "Epoch 282: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1829 - val_loss: 82.4095\n",
      "Epoch 283/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.1727\n",
      "Epoch 283: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2642 - val_loss: 81.8182\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0965\n",
      "Epoch 284: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0965 - val_loss: 87.5325\n",
      "Epoch 285/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1313\n",
      "Epoch 285: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1522 - val_loss: 83.3414\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1471\n",
      "Epoch 286: val_loss did not improve from 80.61937\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1471 - val_loss: 81.8562\n",
      "Epoch 287/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2889\n",
      "Epoch 287: val_loss improved from 80.61937 to 79.76285, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3087 - val_loss: 79.7628\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1994\n",
      "Epoch 288: val_loss did not improve from 79.76285\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1994 - val_loss: 85.2859\n",
      "Epoch 289/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2380\n",
      "Epoch 289: val_loss improved from 79.76285 to 78.20969, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0940 - val_loss: 78.2097\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0798\n",
      "Epoch 290: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0798 - val_loss: 82.0884\n",
      "Epoch 291/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.2755\n",
      "Epoch 291: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1820 - val_loss: 79.3192\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2880\n",
      "Epoch 292: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.2880 - val_loss: 83.0573\n",
      "Epoch 293/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.2008\n",
      "Epoch 293: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2263 - val_loss: 79.3126\n",
      "Epoch 294/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0019\n",
      "Epoch 294: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9931 - val_loss: 88.3221\n",
      "Epoch 295/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0780\n",
      "Epoch 295: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2043 - val_loss: 81.0999\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0875\n",
      "Epoch 296: val_loss did not improve from 78.20969\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0875 - val_loss: 80.1439\n",
      "Epoch 297/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0717\n",
      "Epoch 297: val_loss improved from 78.20969 to 75.63663, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0750 - val_loss: 75.6366\n",
      "Epoch 298/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 3.2426\n",
      "Epoch 298: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.1842 - val_loss: 81.4127\n",
      "Epoch 299/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1696\n",
      "Epoch 299: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1567 - val_loss: 76.2374\n",
      "Epoch 300/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0401\n",
      "Epoch 300: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0539 - val_loss: 76.6256\n",
      "Epoch 301/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2592\n",
      "Epoch 301: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.2034 - val_loss: 85.5976\n",
      "Epoch 302/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0146\n",
      "Epoch 302: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0151 - val_loss: 93.0496\n",
      "Epoch 303/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0337\n",
      "Epoch 303: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0358 - val_loss: 79.5991\n",
      "Epoch 304/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9888\n",
      "Epoch 304: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1461 - val_loss: 77.4771\n",
      "Epoch 305/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1433\n",
      "Epoch 305: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.1052 - val_loss: 89.9619\n",
      "Epoch 306/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1679\n",
      "Epoch 306: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.1588 - val_loss: 82.6785\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0946\n",
      "Epoch 307: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0946 - val_loss: 100.4301\n",
      "Epoch 308/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.2719\n",
      "Epoch 308: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1232 - val_loss: 80.0230\n",
      "Epoch 309/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1769\n",
      "Epoch 309: val_loss did not improve from 75.63663\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2652 - val_loss: 89.7416\n",
      "Epoch 310/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0046\n",
      "Epoch 310: val_loss improved from 75.63663 to 72.56847, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0881 - val_loss: 72.5685\n",
      "Epoch 311/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1820\n",
      "Epoch 311: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1005 - val_loss: 78.1057\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1750\n",
      "Epoch 312: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1750 - val_loss: 76.4353\n",
      "Epoch 313/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0480\n",
      "Epoch 313: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0308 - val_loss: 75.6881\n",
      "Epoch 314/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1437\n",
      "Epoch 314: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1328 - val_loss: 87.8939\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.2023\n",
      "Epoch 315: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2023 - val_loss: 77.8422\n",
      "Epoch 316/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0855\n",
      "Epoch 316: val_loss did not improve from 72.56847\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.2173 - val_loss: 77.7147\n",
      "Epoch 317/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0768\n",
      "Epoch 317: val_loss improved from 72.56847 to 70.30755, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0837 - val_loss: 70.3075\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1475\n",
      "Epoch 318: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1475 - val_loss: 71.9301\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1251\n",
      "Epoch 319: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1251 - val_loss: 76.0610\n",
      "Epoch 320/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9786\n",
      "Epoch 320: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0155 - val_loss: 73.9229\n",
      "Epoch 321/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.2246\n",
      "Epoch 321: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.2219 - val_loss: 83.6937\n",
      "Epoch 322/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9668\n",
      "Epoch 322: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9826 - val_loss: 79.5496\n",
      "Epoch 323/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9913\n",
      "Epoch 323: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9430 - val_loss: 71.4623\n",
      "Epoch 324/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1918\n",
      "Epoch 324: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1039 - val_loss: 91.5394\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0299\n",
      "Epoch 325: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0299 - val_loss: 72.3981\n",
      "Epoch 326/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1722\n",
      "Epoch 326: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1515 - val_loss: 75.2986\n",
      "Epoch 327/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9115\n",
      "Epoch 327: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0762 - val_loss: 88.9551\n",
      "Epoch 328/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8339\n",
      "Epoch 328: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0611 - val_loss: 80.8080\n",
      "Epoch 329/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9369\n",
      "Epoch 329: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9393 - val_loss: 71.5495\n",
      "Epoch 330/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1411\n",
      "Epoch 330: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1200 - val_loss: 81.7625\n",
      "Epoch 331/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1904\n",
      "Epoch 331: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.1275 - val_loss: 82.2465\n",
      "Epoch 332/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1753\n",
      "Epoch 332: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0520 - val_loss: 74.5238\n",
      "Epoch 333/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0264\n",
      "Epoch 333: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9593 - val_loss: 84.6637\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0384\n",
      "Epoch 334: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 3.0384 - val_loss: 73.1009\n",
      "Epoch 335/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9634\n",
      "Epoch 335: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.0035 - val_loss: 82.6712\n",
      "Epoch 336/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9495\n",
      "Epoch 336: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9824 - val_loss: 77.1407\n",
      "Epoch 337/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0583\n",
      "Epoch 337: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.1739 - val_loss: 70.5411\n",
      "Epoch 338/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0752\n",
      "Epoch 338: val_loss did not improve from 70.30755\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0566 - val_loss: 72.7090\n",
      "Epoch 339/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.1248\n",
      "Epoch 339: val_loss improved from 70.30755 to 69.25958, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0250 - val_loss: 69.2596\n",
      "Epoch 340/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1240\n",
      "Epoch 340: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0434 - val_loss: 76.1463\n",
      "Epoch 341/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.1371\n",
      "Epoch 341: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1102 - val_loss: 75.4863\n",
      "Epoch 342/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9048\n",
      "Epoch 342: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9271 - val_loss: 79.5230\n",
      "Epoch 343/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0922\n",
      "Epoch 343: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.1592 - val_loss: 71.4695\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0764\n",
      "Epoch 344: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0764 - val_loss: 80.1708\n",
      "Epoch 345/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9154\n",
      "Epoch 345: val_loss did not improve from 69.25958\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9931 - val_loss: 85.4440\n",
      "Epoch 346/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9746\n",
      "Epoch 346: val_loss improved from 69.25958 to 68.18107, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1397 - val_loss: 68.1811\n",
      "Epoch 347/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0922\n",
      "Epoch 347: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 3.0551 - val_loss: 69.2300\n",
      "Epoch 348/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9499\n",
      "Epoch 348: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9508 - val_loss: 78.8194\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0212\n",
      "Epoch 349: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 3.0212 - val_loss: 71.9846\n",
      "Epoch 350/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0707\n",
      "Epoch 350: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 3.0647 - val_loss: 73.3886\n",
      "Epoch 351/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8868\n",
      "Epoch 351: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 2.9553 - val_loss: 69.4678\n",
      "Epoch 352/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0665\n",
      "Epoch 352: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0482 - val_loss: 72.7121\n",
      "Epoch 353/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0105\n",
      "Epoch 353: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0010 - val_loss: 80.6440\n",
      "Epoch 354/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0889\n",
      "Epoch 354: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9989 - val_loss: 68.7350\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0414\n",
      "Epoch 355: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0414 - val_loss: 74.8310\n",
      "Epoch 356/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0914\n",
      "Epoch 356: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0638 - val_loss: 69.9482\n",
      "Epoch 357/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9887\n",
      "Epoch 357: val_loss did not improve from 68.18107\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9702 - val_loss: 73.8186\n",
      "Epoch 358/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9163\n",
      "Epoch 358: val_loss improved from 68.18107 to 63.46756, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 2.9467 - val_loss: 63.4676\n",
      "Epoch 359/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9909\n",
      "Epoch 359: val_loss did not improve from 63.46756\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0428 - val_loss: 71.5092\n",
      "Epoch 360/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8790\n",
      "Epoch 360: val_loss did not improve from 63.46756\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8509 - val_loss: 75.1322\n",
      "Epoch 361/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0074\n",
      "Epoch 361: val_loss did not improve from 63.46756\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0987 - val_loss: 73.9392\n",
      "Epoch 362/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0188\n",
      "Epoch 362: val_loss improved from 63.46756 to 62.34704, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0568 - val_loss: 62.3470\n",
      "Epoch 363/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9681\n",
      "Epoch 363: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 3.0093 - val_loss: 70.3714\n",
      "Epoch 364/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0764\n",
      "Epoch 364: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 3.0397 - val_loss: 64.2775\n",
      "Epoch 365/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9259\n",
      "Epoch 365: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8737 - val_loss: 66.4415\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9280\n",
      "Epoch 366: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.9280 - val_loss: 67.1269\n",
      "Epoch 367/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9477\n",
      "Epoch 367: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9666 - val_loss: 65.7819\n",
      "Epoch 368/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.1345\n",
      "Epoch 368: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 3.0613 - val_loss: 75.3764\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0398\n",
      "Epoch 369: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0398 - val_loss: 65.6727\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9138\n",
      "Epoch 370: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9138 - val_loss: 76.3484\n",
      "Epoch 371/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0076\n",
      "Epoch 371: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0711 - val_loss: 69.4809\n",
      "Epoch 372/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7092\n",
      "Epoch 372: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8506 - val_loss: 78.5502\n",
      "Epoch 373/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9961\n",
      "Epoch 373: val_loss did not improve from 62.34704\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0341 - val_loss: 77.4636\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0029\n",
      "Epoch 374: val_loss improved from 62.34704 to 61.24993, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.0029 - val_loss: 61.2499\n",
      "Epoch 375/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8987\n",
      "Epoch 375: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0358 - val_loss: 76.4245\n",
      "Epoch 376/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0071\n",
      "Epoch 376: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9918 - val_loss: 64.4447\n",
      "Epoch 377/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9418\n",
      "Epoch 377: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9428 - val_loss: 68.6777\n",
      "Epoch 378/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8927\n",
      "Epoch 378: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9142 - val_loss: 61.7524\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8622\n",
      "Epoch 379: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8622 - val_loss: 70.3932\n",
      "Epoch 380/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 3.0232\n",
      "Epoch 380: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.9932 - val_loss: 65.8090\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0184\n",
      "Epoch 381: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0184 - val_loss: 70.6437\n",
      "Epoch 382/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7184\n",
      "Epoch 382: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8875 - val_loss: 69.0950\n",
      "Epoch 383/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8923\n",
      "Epoch 383: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9035 - val_loss: 73.9868\n",
      "Epoch 384/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9209\n",
      "Epoch 384: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9960 - val_loss: 67.1943\n",
      "Epoch 385/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0313\n",
      "Epoch 385: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0403 - val_loss: 71.7411\n",
      "Epoch 386/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9379\n",
      "Epoch 386: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9654 - val_loss: 63.2448\n",
      "Epoch 387/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9273\n",
      "Epoch 387: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9079 - val_loss: 66.7566\n",
      "Epoch 388/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0843\n",
      "Epoch 388: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9928 - val_loss: 64.8955\n",
      "Epoch 389/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9408\n",
      "Epoch 389: val_loss did not improve from 61.24993\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8766 - val_loss: 69.3814\n",
      "Epoch 390/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9986\n",
      "Epoch 390: val_loss improved from 61.24993 to 61.08674, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9600 - val_loss: 61.0867\n",
      "Epoch 391/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0223\n",
      "Epoch 391: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9970 - val_loss: 67.0887\n",
      "Epoch 392/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9747\n",
      "Epoch 392: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8898 - val_loss: 63.5658\n",
      "Epoch 393/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8791\n",
      "Epoch 393: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9370 - val_loss: 63.2075\n",
      "Epoch 394/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8540\n",
      "Epoch 394: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8516 - val_loss: 71.3153\n",
      "Epoch 395/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9274\n",
      "Epoch 395: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.9534 - val_loss: 75.8481\n",
      "Epoch 396/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8989\n",
      "Epoch 396: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8646 - val_loss: 66.3228\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.0216\n",
      "Epoch 397: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0216 - val_loss: 71.0292\n",
      "Epoch 398/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7604\n",
      "Epoch 398: val_loss did not improve from 61.08674\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8264 - val_loss: 64.3129\n",
      "Epoch 399/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8397\n",
      "Epoch 399: val_loss improved from 61.08674 to 59.34967, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8795 - val_loss: 59.3497\n",
      "Epoch 400/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8706\n",
      "Epoch 400: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8301 - val_loss: 66.8456\n",
      "Epoch 401/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9858\n",
      "Epoch 401: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.0072 - val_loss: 62.5816\n",
      "Epoch 402/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8912\n",
      "Epoch 402: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8436 - val_loss: 69.2830\n",
      "Epoch 403/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0799\n",
      "Epoch 403: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9523 - val_loss: 61.0486\n",
      "Epoch 404/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9134\n",
      "Epoch 404: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8530 - val_loss: 62.3929\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7795\n",
      "Epoch 405: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7795 - val_loss: 64.8606\n",
      "Epoch 406/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8344\n",
      "Epoch 406: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8871 - val_loss: 63.0174\n",
      "Epoch 407/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8410\n",
      "Epoch 407: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8504 - val_loss: 60.7000\n",
      "Epoch 408/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9251\n",
      "Epoch 408: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9230 - val_loss: 63.5815\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8644\n",
      "Epoch 409: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8644 - val_loss: 79.2520\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9575\n",
      "Epoch 410: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9575 - val_loss: 65.2418\n",
      "Epoch 411/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8155\n",
      "Epoch 411: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8537 - val_loss: 65.8521\n",
      "Epoch 412/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8394\n",
      "Epoch 412: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9076 - val_loss: 63.9078\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8334\n",
      "Epoch 413: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8334 - val_loss: 70.4818\n",
      "Epoch 414/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7613\n",
      "Epoch 414: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8443 - val_loss: 64.1536\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9039\n",
      "Epoch 415: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9039 - val_loss: 61.8044\n",
      "Epoch 416/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8854\n",
      "Epoch 416: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8557 - val_loss: 67.1818\n",
      "Epoch 417/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7085\n",
      "Epoch 417: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7806 - val_loss: 64.4129\n",
      "Epoch 418/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8744\n",
      "Epoch 418: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9651 - val_loss: 63.4941\n",
      "Epoch 419/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8846\n",
      "Epoch 419: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.9161 - val_loss: 69.7253\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8910\n",
      "Epoch 420: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8910 - val_loss: 70.5491\n",
      "Epoch 421/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8351\n",
      "Epoch 421: val_loss did not improve from 59.34967\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8152 - val_loss: 65.3855\n",
      "Epoch 422/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8814\n",
      "Epoch 422: val_loss improved from 59.34967 to 58.65474, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9283 - val_loss: 58.6547\n",
      "Epoch 423/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9285\n",
      "Epoch 423: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8885 - val_loss: 69.5584\n",
      "Epoch 424/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9874\n",
      "Epoch 424: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9440 - val_loss: 62.5797\n",
      "Epoch 425/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7847\n",
      "Epoch 425: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8330 - val_loss: 60.9157\n",
      "Epoch 426/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8962\n",
      "Epoch 426: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8278 - val_loss: 69.2903\n",
      "Epoch 427/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8459\n",
      "Epoch 427: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7879 - val_loss: 66.6602\n",
      "Epoch 428/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9321\n",
      "Epoch 428: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8659 - val_loss: 59.2023\n",
      "Epoch 429/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.9453\n",
      "Epoch 429: val_loss did not improve from 58.65474\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9699 - val_loss: 62.0481\n",
      "Epoch 430/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9067\n",
      "Epoch 430: val_loss improved from 58.65474 to 58.63293, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8647 - val_loss: 58.6329\n",
      "Epoch 431/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6635\n",
      "Epoch 431: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7739 - val_loss: 86.8717\n",
      "Epoch 432/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9368\n",
      "Epoch 432: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8847 - val_loss: 67.0440\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8713\n",
      "Epoch 433: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8713 - val_loss: 75.5029\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8586\n",
      "Epoch 434: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8586 - val_loss: 59.7119\n",
      "Epoch 435/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.9283\n",
      "Epoch 435: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9283 - val_loss: 62.7570\n",
      "Epoch 436/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7728\n",
      "Epoch 436: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7998 - val_loss: 61.5117\n",
      "Epoch 437/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8980\n",
      "Epoch 437: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8782 - val_loss: 65.2954\n",
      "Epoch 438/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 3.0988\n",
      "Epoch 438: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.9598 - val_loss: 61.8582\n",
      "Epoch 439/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 3.0359\n",
      "Epoch 439: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.9808 - val_loss: 63.2153\n",
      "Epoch 440/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7859\n",
      "Epoch 440: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8169 - val_loss: 62.1330\n",
      "Epoch 441/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8241\n",
      "Epoch 441: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.8241 - val_loss: 64.0305\n",
      "Epoch 442/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7597\n",
      "Epoch 442: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8354 - val_loss: 59.9816\n",
      "Epoch 443/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9000\n",
      "Epoch 443: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 2.8717 - val_loss: 68.2682\n",
      "Epoch 444/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8244\n",
      "Epoch 444: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.7672 - val_loss: 77.5854\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8019\n",
      "Epoch 445: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8019 - val_loss: 63.2028\n",
      "Epoch 446/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0218\n",
      "Epoch 446: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8921 - val_loss: 66.1852\n",
      "Epoch 447/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 3.0445\n",
      "Epoch 447: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8839 - val_loss: 67.4695\n",
      "Epoch 448/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.9700\n",
      "Epoch 448: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8914 - val_loss: 61.9608\n",
      "Epoch 449/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7752\n",
      "Epoch 449: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7865 - val_loss: 65.5176\n",
      "Epoch 450/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8446\n",
      "Epoch 450: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8308 - val_loss: 66.4215\n",
      "Epoch 451/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8470\n",
      "Epoch 451: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8470 - val_loss: 65.5090\n",
      "Epoch 452/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.9594\n",
      "Epoch 452: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8438 - val_loss: 62.3452\n",
      "Epoch 453/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8516\n",
      "Epoch 453: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8155 - val_loss: 66.1313\n",
      "Epoch 454/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8081\n",
      "Epoch 454: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.8118 - val_loss: 62.9222\n",
      "Epoch 455/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8873\n",
      "Epoch 455: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8540 - val_loss: 60.3290\n",
      "Epoch 456/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8400\n",
      "Epoch 456: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8379 - val_loss: 65.1422\n",
      "Epoch 457/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8236\n",
      "Epoch 457: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7596 - val_loss: 63.8875\n",
      "Epoch 458/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.9026\n",
      "Epoch 458: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9286 - val_loss: 63.2486\n",
      "Epoch 459/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7717\n",
      "Epoch 459: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7567 - val_loss: 58.7888\n",
      "Epoch 460/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8946\n",
      "Epoch 460: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8946 - val_loss: 74.9134\n",
      "Epoch 461/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8897\n",
      "Epoch 461: val_loss did not improve from 58.63293\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9103 - val_loss: 61.0922\n",
      "Epoch 462/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8052\n",
      "Epoch 462: val_loss improved from 58.63293 to 58.51637, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8454 - val_loss: 58.5164\n",
      "Epoch 463/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7240\n",
      "Epoch 463: val_loss did not improve from 58.51637\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7520 - val_loss: 59.6342\n",
      "Epoch 464/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8271\n",
      "Epoch 464: val_loss did not improve from 58.51637\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7427 - val_loss: 66.2283\n",
      "Epoch 465/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8906\n",
      "Epoch 465: val_loss improved from 58.51637 to 56.98942, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8906 - val_loss: 56.9894\n",
      "Epoch 466/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8090\n",
      "Epoch 466: val_loss did not improve from 56.98942\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7230 - val_loss: 77.9595\n",
      "Epoch 467/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8356\n",
      "Epoch 467: val_loss did not improve from 56.98942\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8489 - val_loss: 57.9227\n",
      "Epoch 468/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8816\n",
      "Epoch 468: val_loss did not improve from 56.98942\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8816 - val_loss: 61.5751\n",
      "Epoch 469/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7767\n",
      "Epoch 469: val_loss did not improve from 56.98942\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7833 - val_loss: 69.4792\n",
      "Epoch 470/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6941\n",
      "Epoch 470: val_loss did not improve from 56.98942\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8005 - val_loss: 64.5425\n",
      "Epoch 471/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7607\n",
      "Epoch 471: val_loss improved from 56.98942 to 56.39576, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7988 - val_loss: 56.3958\n",
      "Epoch 472/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8110\n",
      "Epoch 472: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8725 - val_loss: 58.6102\n",
      "Epoch 473/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9171\n",
      "Epoch 473: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8771 - val_loss: 60.9304\n",
      "Epoch 474/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8673\n",
      "Epoch 474: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8673 - val_loss: 62.5452\n",
      "Epoch 475/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7369\n",
      "Epoch 475: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7697 - val_loss: 58.0929\n",
      "Epoch 476/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7636\n",
      "Epoch 476: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7842 - val_loss: 65.6016\n",
      "Epoch 477/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8468\n",
      "Epoch 477: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8430 - val_loss: 59.6006\n",
      "Epoch 478/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8587\n",
      "Epoch 478: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7883 - val_loss: 65.7823\n",
      "Epoch 479/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8934\n",
      "Epoch 479: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8304 - val_loss: 58.4775\n",
      "Epoch 480/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7208\n",
      "Epoch 480: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7208 - val_loss: 58.3162\n",
      "Epoch 481/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7945\n",
      "Epoch 481: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8213 - val_loss: 66.9271\n",
      "Epoch 482/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7935\n",
      "Epoch 482: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7935 - val_loss: 71.9498\n",
      "Epoch 483/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6508\n",
      "Epoch 483: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7672 - val_loss: 61.1158\n",
      "Epoch 484/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.9239\n",
      "Epoch 484: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.9085 - val_loss: 63.9347\n",
      "Epoch 485/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6534\n",
      "Epoch 485: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6534 - val_loss: 64.3691\n",
      "Epoch 486/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7347\n",
      "Epoch 486: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7347 - val_loss: 66.6966\n",
      "Epoch 487/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.8174\n",
      "Epoch 487: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8174 - val_loss: 59.3245\n",
      "Epoch 488/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.8194\n",
      "Epoch 488: val_loss did not improve from 56.39576\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8252 - val_loss: 65.1908\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7652\n",
      "Epoch 489: val_loss improved from 56.39576 to 56.05900, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.7652 - val_loss: 56.0590\n",
      "Epoch 490/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7884\n",
      "Epoch 490: val_loss did not improve from 56.05900\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7884 - val_loss: 59.2820\n",
      "Epoch 491/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6997\n",
      "Epoch 491: val_loss did not improve from 56.05900\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6997 - val_loss: 57.3008\n",
      "Epoch 492/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8581\n",
      "Epoch 492: val_loss did not improve from 56.05900\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.8419 - val_loss: 70.4997\n",
      "Epoch 493/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8566\n",
      "Epoch 493: val_loss did not improve from 56.05900\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7907 - val_loss: 66.3469\n",
      "Epoch 494/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8848\n",
      "Epoch 494: val_loss improved from 56.05900 to 54.80525, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.8147 - val_loss: 54.8052\n",
      "Epoch 495/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7140\n",
      "Epoch 495: val_loss did not improve from 54.80525\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6934 - val_loss: 60.3359\n",
      "Epoch 496/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7253\n",
      "Epoch 496: val_loss did not improve from 54.80525\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7925 - val_loss: 58.1252\n",
      "Epoch 497/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7450\n",
      "Epoch 497: val_loss did not improve from 54.80525\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7450 - val_loss: 64.9916\n",
      "Epoch 498/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.8268\n",
      "Epoch 498: val_loss did not improve from 54.80525\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8532 - val_loss: 76.7706\n",
      "Epoch 499/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7177\n",
      "Epoch 499: val_loss improved from 54.80525 to 54.72814, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.8534 - val_loss: 54.7281\n",
      "Epoch 500/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6991\n",
      "Epoch 500: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7254 - val_loss: 59.4122\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7768\n",
      "Epoch 501: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7768 - val_loss: 65.4422\n",
      "Epoch 502/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7985\n",
      "Epoch 502: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7309 - val_loss: 83.1795\n",
      "Epoch 503/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7744\n",
      "Epoch 503: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7744 - val_loss: 60.1642\n",
      "Epoch 504/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7676\n",
      "Epoch 504: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7751 - val_loss: 70.2637\n",
      "Epoch 505/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7231\n",
      "Epoch 505: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.9115 - val_loss: 61.9873\n",
      "Epoch 506/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7538\n",
      "Epoch 506: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7516 - val_loss: 65.4524\n",
      "Epoch 507/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7309\n",
      "Epoch 507: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7194 - val_loss: 62.5338\n",
      "Epoch 508/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8084\n",
      "Epoch 508: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7861 - val_loss: 67.7732\n",
      "Epoch 509/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7764\n",
      "Epoch 509: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7533 - val_loss: 65.7641\n",
      "Epoch 510/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8535\n",
      "Epoch 510: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8049 - val_loss: 63.9155\n",
      "Epoch 511/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7952\n",
      "Epoch 511: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7688 - val_loss: 59.0227\n",
      "Epoch 512/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8703\n",
      "Epoch 512: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7601 - val_loss: 57.6937\n",
      "Epoch 513/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7063\n",
      "Epoch 513: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7063 - val_loss: 56.1203\n",
      "Epoch 514/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7308\n",
      "Epoch 514: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.8066 - val_loss: 72.7351\n",
      "Epoch 515/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7537\n",
      "Epoch 515: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7275 - val_loss: 68.4594\n",
      "Epoch 516/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7306\n",
      "Epoch 516: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7306 - val_loss: 60.2760\n",
      "Epoch 517/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7191\n",
      "Epoch 517: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7191 - val_loss: 57.2045\n",
      "Epoch 518/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7638\n",
      "Epoch 518: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7417 - val_loss: 61.2924\n",
      "Epoch 519/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7154\n",
      "Epoch 519: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 2.7480 - val_loss: 55.8660\n",
      "Epoch 520/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8702\n",
      "Epoch 520: val_loss did not improve from 54.72814\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7409 - val_loss: 56.7508\n",
      "Epoch 521/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8843\n",
      "Epoch 521: val_loss improved from 54.72814 to 54.09692, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7652 - val_loss: 54.0969\n",
      "Epoch 522/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8829\n",
      "Epoch 522: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7644 - val_loss: 73.8646\n",
      "Epoch 523/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.7641\n",
      "Epoch 523: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7926 - val_loss: 67.7857\n",
      "Epoch 524/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6904\n",
      "Epoch 524: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7529 - val_loss: 67.9591\n",
      "Epoch 525/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7364\n",
      "Epoch 525: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7364 - val_loss: 55.9736\n",
      "Epoch 526/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7281\n",
      "Epoch 526: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6817 - val_loss: 60.1856\n",
      "Epoch 527/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7306\n",
      "Epoch 527: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7959 - val_loss: 60.2588\n",
      "Epoch 528/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6755\n",
      "Epoch 528: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6755 - val_loss: 65.5644\n",
      "Epoch 529/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7811\n",
      "Epoch 529: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7909 - val_loss: 54.6853\n",
      "Epoch 530/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7236\n",
      "Epoch 530: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7236 - val_loss: 59.4631\n",
      "Epoch 531/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.5881\n",
      "Epoch 531: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.7061 - val_loss: 76.8832\n",
      "Epoch 532/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6425\n",
      "Epoch 532: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7567 - val_loss: 60.5733\n",
      "Epoch 533/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7343\n",
      "Epoch 533: val_loss did not improve from 54.09692\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6601 - val_loss: 64.2757\n",
      "Epoch 534/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.5877\n",
      "Epoch 534: val_loss improved from 54.09692 to 50.59326, saving model to Best_GRU_Model_RMSprop_Optimizer.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6351 - val_loss: 50.5933\n",
      "Epoch 535/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7352\n",
      "Epoch 535: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6894 - val_loss: 63.5250\n",
      "Epoch 536/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8136\n",
      "Epoch 536: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7724 - val_loss: 64.1431\n",
      "Epoch 537/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.7493\n",
      "Epoch 537: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6854 - val_loss: 61.4382\n",
      "Epoch 538/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7981\n",
      "Epoch 538: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7806 - val_loss: 62.2421\n",
      "Epoch 539/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6827\n",
      "Epoch 539: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6713 - val_loss: 58.0355\n",
      "Epoch 540/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7522\n",
      "Epoch 540: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6682 - val_loss: 58.2643\n",
      "Epoch 541/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7443\n",
      "Epoch 541: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7443 - val_loss: 60.8100\n",
      "Epoch 542/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7284\n",
      "Epoch 542: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7375 - val_loss: 73.4356\n",
      "Epoch 543/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.8620\n",
      "Epoch 543: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7188 - val_loss: 56.0141\n",
      "Epoch 544/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6925\n",
      "Epoch 544: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7380 - val_loss: 62.3718\n",
      "Epoch 545/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6903\n",
      "Epoch 545: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7313 - val_loss: 55.5414\n",
      "Epoch 546/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.8547\n",
      "Epoch 546: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7403 - val_loss: 57.1348\n",
      "Epoch 547/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5209\n",
      "Epoch 547: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 2.7002 - val_loss: 57.4822\n",
      "Epoch 548/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6720\n",
      "Epoch 548: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6620 - val_loss: 62.4388\n",
      "Epoch 549/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7707\n",
      "Epoch 549: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7006 - val_loss: 63.4410\n",
      "Epoch 550/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.7674\n",
      "Epoch 550: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7335 - val_loss: 64.8499\n",
      "Epoch 551/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6079\n",
      "Epoch 551: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6900 - val_loss: 70.7944\n",
      "Epoch 552/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.8201\n",
      "Epoch 552: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7731 - val_loss: 62.4483\n",
      "Epoch 553/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.6451\n",
      "Epoch 553: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6764 - val_loss: 62.2483\n",
      "Epoch 554/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7482\n",
      "Epoch 554: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7168 - val_loss: 61.6039\n",
      "Epoch 555/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.7611\n",
      "Epoch 555: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6603 - val_loss: 62.2598\n",
      "Epoch 556/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6250\n",
      "Epoch 556: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6367 - val_loss: 68.9218\n",
      "Epoch 557/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7381\n",
      "Epoch 557: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7381 - val_loss: 56.8078\n",
      "Epoch 558/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6520\n",
      "Epoch 558: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5857 - val_loss: 59.4483\n",
      "Epoch 559/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5898\n",
      "Epoch 559: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6727 - val_loss: 56.0768\n",
      "Epoch 560/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6551\n",
      "Epoch 560: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6551 - val_loss: 61.2710\n",
      "Epoch 561/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.8704\n",
      "Epoch 561: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7975 - val_loss: 59.3258\n",
      "Epoch 562/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 2.6987\n",
      "Epoch 562: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6935 - val_loss: 63.6787\n",
      "Epoch 563/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6978\n",
      "Epoch 563: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.6553 - val_loss: 60.8864\n",
      "Epoch 564/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6748\n",
      "Epoch 564: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6748 - val_loss: 63.6437\n",
      "Epoch 565/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.7001\n",
      "Epoch 565: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6776 - val_loss: 64.2981\n",
      "Epoch 566/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6115\n",
      "Epoch 566: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6115 - val_loss: 56.3861\n",
      "Epoch 567/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7157\n",
      "Epoch 567: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.7349 - val_loss: 59.5399\n",
      "Epoch 568/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7136\n",
      "Epoch 568: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6790 - val_loss: 62.5869\n",
      "Epoch 569/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6756\n",
      "Epoch 569: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6756 - val_loss: 66.0640\n",
      "Epoch 570/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.5429\n",
      "Epoch 570: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6042 - val_loss: 59.4756\n",
      "Epoch 571/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6490\n",
      "Epoch 571: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.5822 - val_loss: 62.2513\n",
      "Epoch 572/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 2.4956\n",
      "Epoch 572: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.5817 - val_loss: 70.2140\n",
      "Epoch 573/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6607\n",
      "Epoch 573: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6534 - val_loss: 62.8341\n",
      "Epoch 574/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 2.6907\n",
      "Epoch 574: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6687 - val_loss: 57.8939\n",
      "Epoch 575/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6744\n",
      "Epoch 575: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6165 - val_loss: 51.1679\n",
      "Epoch 576/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6464\n",
      "Epoch 576: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6464 - val_loss: 58.5258\n",
      "Epoch 577/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.6705\n",
      "Epoch 577: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.5413 - val_loss: 64.9742\n",
      "Epoch 578/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 2.6654\n",
      "Epoch 578: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6158 - val_loss: 56.4972\n",
      "Epoch 579/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.6361\n",
      "Epoch 579: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6361 - val_loss: 66.6496\n",
      "Epoch 580/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.7808\n",
      "Epoch 580: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.6220 - val_loss: 55.6539\n",
      "Epoch 581/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5887\n",
      "Epoch 581: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 2.5887 - val_loss: 68.1175\n",
      "Epoch 582/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 2.5233\n",
      "Epoch 582: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5806 - val_loss: 75.7526\n",
      "Epoch 583/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 2.4944\n",
      "Epoch 583: val_loss did not improve from 50.59326\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.6753 - val_loss: 60.6724\n",
      "Epoch 584/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.5637\n",
      "Epoch 584: val_loss did not improve from 50.59326\n",
      "Restoring model weights from the end of the best epoch: 534.\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.5637 - val_loss: 60.3498\n",
      "Epoch 584: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class\n",
    "gru_rmsprop_model = TimeSeriesModel(model_type='gru', optimizer = RMSprop(learning_rate=0.001))\n",
    "# Train the model\n",
    "gru_rmsprop_model.fit(X_train, y_train, X_test, y_test, best_model_path = 'Best_GRU_Model_RMSprop_Optimizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28776edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_preds = gru_rmsprop_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1dd60383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 7.409858403454994\n",
      "R2 Score: 0.7029475907829502\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and R^2 Score\n",
    "rmse = mean_squared_error(y_test[time_steps:], y_preds[time_steps:], squared=False)\n",
    "r2 = r2_score(y_test[time_steps:], y_preds[time_steps:])\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "593e7b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(y_test, y_preds, time_steps, model_name = 'GRU - RMSprop Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71792f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
